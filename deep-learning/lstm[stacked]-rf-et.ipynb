{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eFYvjNtGGc1cjG6DwZ4JlkPSWO9-kgWH","timestamp":1743264037079},{"file_id":"15gPAmO_07XF9Wekf99lrTtNUVLC3U2-H","timestamp":1743248697535}],"collapsed_sections":["6MM-OJGXCCK2","MFeTjGxUCEpk","31Yn1i4585D5","M10Oo7qqLZgm","uUCh_YB9Vf7S","qUH36NvmtM2G","PnPul0h2lqPU","UA4RDkuZXHto"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Initial"],"metadata":{"id":"6MM-OJGXCCK2"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"Z7gOgVN8kW8r","executionInfo":{"status":"ok","timestamp":1743258474714,"user_tz":-330,"elapsed":13,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}}},"outputs":[],"source":["# Importing necessary libraries for data analysis and manipulation\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# For handling warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93jX7ecsBi-o","executionInfo":{"status":"ok","timestamp":1743258480331,"user_tz":-330,"elapsed":5614,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"10d0fcd0-34f1-44ea-d2bf-9cd8fe1bda2c"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["df_aapl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/stocks/AAPL.csv')"],"metadata":{"id":"SqkQs1FVBnLC","executionInfo":{"status":"ok","timestamp":1743258480335,"user_tz":-330,"elapsed":2,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from scipy.stats import boxcox\n","\n","df_aapl['Close_log'] = np.log(df_aapl['Close'] + 1)\n","df_aapl['Close_sqrt'] = np.sqrt(df_aapl['Close'])\n","df_aapl['Close_boxcox'], _ = boxcox(df_aapl['Close'] + 1)\n"],"metadata":{"id":"ttF4WNTkBxms","executionInfo":{"status":"ok","timestamp":1743258480535,"user_tz":-330,"elapsed":198,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["\n","skew_original = df_aapl['Close'].skew()\n","skew_log = df_aapl['Close_log'].skew()\n","skew_sqrt = df_aapl['Close_sqrt'].skew()\n","skew_boxcox = pd.Series(df_aapl['Close_boxcox']).skew()\n","\n","print(f\"Original Skewness: {skew_original}\")\n","print(f\"Log Transformation Skewness: {skew_log}\")\n","print(f\"Square Root Transformation Skewness: {skew_sqrt}\")\n","print(f\"Box-Cox Transformation Skewness: {skew_boxcox}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7rMhFf7B0Rr","executionInfo":{"status":"ok","timestamp":1743258480549,"user_tz":-330,"elapsed":11,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"34cd7f46-065e-4e64-81d7-905b3a70a635"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Skewness: 2.5045276102319933\n","Log Transformation Skewness: 0.8535555176510303\n","Square Root Transformation Skewness: 1.6211545809555206\n","Box-Cox Transformation Skewness: 0.43527466713563334\n"]}]},{"cell_type":"code","source":["\n","df_aapl['Open_log'] = np.log(df_aapl['Open'])\n","df_aapl['High_log'] = np.log(df_aapl['High'])\n","df_aapl['Low_log'] = np.log(df_aapl['Low'])\n","df_aapl['Adj Close_log'] = np.log(df_aapl['Adj Close'])\n","df_aapl['Volume_log'] = np.log(df_aapl['Volume'])\n","\n","\n","df_aapl['Open_sqrt'] = np.sqrt(df_aapl['Open'])\n","df_aapl['High_sqrt'] = np.sqrt(df_aapl['High'])\n","df_aapl['Low_sqrt'] = np.sqrt(df_aapl['Low'])\n","df_aapl['Adj Close_sqrt'] = np.sqrt(df_aapl['Adj Close'])\n","df_aapl['Volume_sqrt'] = np.sqrt(df_aapl['Volume'])\n","\n","from scipy.stats import boxcox\n","df_aapl['Open_boxcox'], _ = boxcox(df_aapl['Open'])\n","df_aapl['High_boxcox'], _ = boxcox(df_aapl['High'])\n","df_aapl['Low_boxcox'], _ = boxcox(df_aapl['Low'])\n","df_aapl['Adj Close_boxcox'], _ = boxcox(df_aapl['Adj Close'])"],"metadata":{"id":"FEyv3BNQB3TB","executionInfo":{"status":"ok","timestamp":1743258480862,"user_tz":-330,"elapsed":312,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["\n","skewness_before = df_aapl[['Open', 'High', 'Low', 'Adj Close', 'Volume']].skew()\n","skewness_after = df_aapl[['Open_log', 'High_log', 'Low_log', 'Adj Close_log',\n","                          'Open_sqrt', 'High_sqrt', 'Low_sqrt', 'Adj Close_sqrt', 'Volume_sqrt',\n","                          'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox']].skew()\n","\n","print(\"Skewness Before Transformation:\\n\", skewness_before)\n","print(\"\\nSkewness After Transformation:\\n\", skewness_after)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8CzGUPAB4vn","executionInfo":{"status":"ok","timestamp":1743258481000,"user_tz":-330,"elapsed":135,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"de27698e-4ba6-4dbd-b5bb-805da92ed2b1"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness Before Transformation:\n"," Open         2.504632\n","High         2.502208\n","Low          2.506714\n","Adj Close    2.550677\n","Volume       3.565699\n","dtype: float64\n","\n","Skewness After Transformation:\n"," Open_log            0.482872\n","High_log            0.481997\n","Low_log             0.484246\n","Adj Close_log       0.494009\n","Open_sqrt           1.620771\n","High_sqrt           1.621456\n","Low_sqrt            1.620661\n","Adj Close_sqrt      1.679402\n","Volume_sqrt         1.299776\n","Open_boxcox         0.181226\n","High_boxcox         0.179749\n","Low_boxcox          0.182882\n","Adj Close_boxcox    0.180085\n","dtype: float64\n"]}]},{"cell_type":"code","source":["from scipy import stats\n","\n","df_aapl['Open_boxcox'], _ = stats.boxcox(df_aapl['Open'] + 1)\n","df_aapl['High_boxcox'], _ = stats.boxcox(df_aapl['High'] + 1)\n","df_aapl['Low_boxcox'], _ = stats.boxcox(df_aapl['Low'] + 1)\n","df_aapl['Adj Close_boxcox'], _ = stats.boxcox(df_aapl['Adj Close'] + 1)\n","df_aapl['Close_boxcox'], _ = stats.boxcox(df_aapl['Close'] + 1)\n","\n","skewness_after_boxcox = df_aapl[['Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox', 'Close_boxcox']].skew()\n","\n","print(\"Skewness After Box-Cox Transformation:\")\n","print(skewness_after_boxcox)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSm4tARXB8Ys","executionInfo":{"status":"ok","timestamp":1743258481549,"user_tz":-330,"elapsed":550,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"ac666adb-3e41-482a-eeb6-21d1668b9d27"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness After Box-Cox Transformation:\n","Open_boxcox         0.435237\n","High_boxcox         0.433381\n","Low_boxcox          0.437331\n","Adj Close_boxcox    0.458762\n","Close_boxcox        0.435275\n","dtype: float64\n"]}]},{"cell_type":"code","source":["\n","df_aapl_cleaned = df_aapl[['Date', 'Open', 'High', 'Low', 'Adj Close', 'Close', 'Volume',\n","                           'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox',\n","                           'Close_boxcox']]\n","\n","print(df_aapl_cleaned.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8jxBy1MB-AY","executionInfo":{"status":"ok","timestamp":1743258481559,"user_tz":-330,"elapsed":8,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"20a89664-7035-4f72-81cf-cd15dd465576"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["         Date      Open      High       Low  Adj Close     Close     Volume  \\\n","0  1980-12-12  0.128348  0.128906  0.128348   0.098943  0.128348  469033600   \n","1  1980-12-15  0.122210  0.122210  0.121652   0.093781  0.121652  175884800   \n","2  1980-12-16  0.113281  0.113281  0.112723   0.086898  0.112723  105728000   \n","3  1980-12-17  0.115513  0.116071  0.115513   0.089049  0.115513   86441600   \n","4  1980-12-18  0.118862  0.119420  0.118862   0.091630  0.118862   73449600   \n","\n","   Open_boxcox  High_boxcox  Low_boxcox  Adj Close_boxcox  Close_boxcox  \n","0     0.117689     0.118173    0.117674          0.092374      0.117689  \n","1     0.112503     0.112516    0.112016          0.087857      0.112030  \n","2     0.104886     0.104897    0.104395          0.081785      0.104407  \n","3     0.106798     0.107287    0.106786          0.083688      0.106798  \n","4     0.109657     0.110145    0.109644          0.085966      0.109657  \n"]}]},{"cell_type":"markdown","source":["#Train, Validation and Testing"],"metadata":{"id":"MFeTjGxUCEpk"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df_aapl_cleaned[['Open_boxcox', 'High_boxcox', 'Low_boxcox']]\n","Y = df_aapl_cleaned['Close_boxcox']\n","\n","X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, shuffle=False)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, shuffle=False)\n","\n","print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCaInU2aCJZJ","executionInfo":{"status":"ok","timestamp":1743258481576,"user_tz":-330,"elapsed":16,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"4102d291-e00a-41cf-d60b-66d6084314e7"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (7736, 3), Validation set: (1658, 3), Test set: (1658, 3)\n"]}]},{"cell_type":"markdown","source":["# Extra tree"],"metadata":{"id":"Pk2BtMJuCPi9"}},{"cell_type":"markdown","source":["## Initial"],"metadata":{"id":"31Yn1i4585D5"}},{"cell_type":"code","source":["import time\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.ensemble import ExtraTreesRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Enable GPU for TensorFlow\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","        print(\"GPU activated for TensorFlow!\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Function to define and train an LSTM model on GPU\n","def train_lstm(X_train, Y_train, X_val, Y_val, layers):\n","    with tf.device('/GPU:0'):\n","        model = Sequential()\n","        model.add(LSTM(64, return_sequences=(layers > 1), input_shape=(X_train.shape[1], 1)))\n","        for _ in range(layers - 1):\n","            model.add(LSTM(64, return_sequences=(_ < layers - 2)))\n","        model.add(Dense(1))\n","\n","        model.compile(optimizer='adam', loss='mse')\n","        model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=16, verbose=0)\n","        return model\n","\n","# Reshaping input for LSTM\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Initialize timing dictionary\n","times = {}\n","\n","# Train Phase (includes training all LSTMs and Extra Trees)\n","start_train_time = time.time()\n","\n","# Train 2, 3, and 5-layer LSTM models\n","lstm_models = {}\n","lstm_predictions = {}\n","\n","for layers in [2, 3, 5]:\n","    model = train_lstm(X_train_r, Y_train, X_val_r, Y_val, layers)\n","    lstm_models[layers] = model\n","\n","# Generate predictions from all LSTM models\n","for layers in [2, 3, 5]:\n","    Y_train_pred = lstm_models[layers].predict(X_train_r)\n","    Y_val_pred = lstm_models[layers].predict(X_val_r)\n","    Y_test_pred = lstm_models[layers].predict(X_test_r)\n","    lstm_predictions[layers] = (Y_train_pred, Y_val_pred, Y_test_pred)\n","\n","# Prepare input for Extra Trees\n","X_train_et = np.column_stack([lstm_predictions[layers][0] for layers in [2, 3, 5]])\n","X_val_et = np.column_stack([lstm_predictions[layers][1] for layers in [2, 3, 5]])\n","X_test_et = np.column_stack([lstm_predictions[layers][2] for layers in [2, 3, 5]])\n","\n","# Train Extra Trees model\n","et_model = ExtraTreesRegressor(n_estimators=100, max_depth=None, min_samples_split=2,\n","                              min_samples_leaf=1, random_state=42, n_jobs=-1)\n","et_model.fit(X_train_et, Y_train)\n","\n","times['Total Train Time'] = time.time() - start_train_time\n","\n","# Validation Phase\n","start_val_time = time.time()\n","Y_val_pred_et = et_model.predict(X_val_et)\n","times['Total Validate Time'] = time.time() - start_val_time\n","\n","# Test Phase\n","start_test_time = time.time()\n","Y_test_pred_et = et_model.predict(X_test_et)\n","times['Total Test Time'] = time.time() - start_test_time\n","\n","# Function to calculate metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Compute and print metrics\n","metrics_train = compute_metrics(Y_train, et_model.predict(X_train_et))\n","metrics_val = compute_metrics(Y_val, Y_val_pred_et)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_et)\n","\n","print(\"\\nPerformance Metrics:\")\n","print(f\"Train Metrics: MAE={metrics_train[0]:.4f}, MSE={metrics_train[1]:.4f}, RMSE={metrics_train[2]:.4f}, R²={metrics_train[3]:.4f}, MAPE={metrics_train[4]:.2f}%\")\n","print(f\"Validation Metrics: MAE={metrics_val[0]:.4f}, MSE={metrics_val[1]:.4f}, RMSE={metrics_val[2]:.4f}, R²={metrics_val[3]:.4f}, MAPE={metrics_val[4]:.2f}%\")\n","print(f\"Test Metrics: MAE={metrics_test[0]:.4f}, MSE={metrics_test[1]:.4f}, RMSE={metrics_test[2]:.4f}, R²={metrics_test[3]:.4f}, MAPE={metrics_test[4]:.2f}%\")\n","\n","# Print timing information\n","print(\"\\nTiming Information:\")\n","for phase, t in times.items():\n","    print(f\"{phase}: {t:.2f} seconds\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-A4tWseQCSHW","executionInfo":{"status":"ok","timestamp":1743249862405,"user_tz":-330,"elapsed":281694,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"10fb255d-eaf1-4baa-afb8-5992f0cac74e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU activated for TensorFlow!\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\n","Performance Metrics:\n","Train Metrics: MAE=0.0001, MSE=0.0000, RMSE=0.0003, R²=1.0000, MAPE=0.03%\n","Validation Metrics: MAE=0.1352, MSE=0.0239, RMSE=0.1546, R²=-3.0652, MAPE=7.56%\n","Test Metrics: MAE=0.4034, MSE=0.1687, RMSE=0.4108, R²=-26.9577, MAPE=19.89%\n","\n","Timing Information:\n","Total Train Time: 281.51 seconds\n","Total Validate Time: 0.03 seconds\n","Total Test Time: 0.03 seconds\n"]}]},{"cell_type":"markdown","source":["## Optuna"],"metadata":{"id":"M10Oo7qqLZgm"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhqC08wbIYOF","executionInfo":{"status":"ok","timestamp":1743258491959,"user_tz":-330,"elapsed":2481,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"cbb98531-6201-427e-8fd8-6f7be88404b7"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.ensemble import ExtraTreesRegressor\n","import optuna\n","from sklearn.metrics import mean_absolute_error\n","\n","# --- GPU Setup ---\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    tf.config.experimental.set_memory_growth(gpus[0], True)\n","\n","# --- LSTM Training Function (supports 2/3/5 layers) ---\n","def train_lstm(X_train, Y_train, units, layers, lr, batch_size, epochs):\n","    model = tf.keras.Sequential()\n","    for _ in range(layers - 1):\n","        model.add(LSTM(units, return_sequences=True))\n","    model.add(LSTM(units))\n","    model.add(Dense(1))\n","    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='mse')\n","    model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n","    return model\n","\n","# --- Optuna Objective ---\n","def objective(trial):\n","    # LSTM Hyperparameters (optimized per layer count)\n","    lstm_params = {\n","        'units': trial.suggest_int('lstm_units', 32, 128),\n","        'lr': trial.suggest_float('lstm_lr', 1e-4, 1e-2, log=True),\n","        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n","        'epochs': trial.suggest_int('epochs', 10, 50)\n","    }\n","\n","    # Train ALL LSTMs (2, 3, 5 layers)\n","    lstm_preds = []\n","    for layers in [2, 3, 5]:  # YOUR REQUIRED STACKING\n","        model = train_lstm(\n","            X_train=np.expand_dims(X_train, -1),\n","            Y_train=Y_train,\n","            layers=layers,\n","            **lstm_params\n","        )\n","        lstm_preds.append(model.predict(np.expand_dims(X_val, -1)).flatten())\n","\n","    # Stack predictions\n","    X_val_et = np.column_stack(lstm_preds)\n","\n","    # ExtraTrees Hyperparameters\n","    et_params = {\n","        'n_estimators': trial.suggest_int('et_n_estimators', 50, 200),\n","        'max_depth': trial.suggest_int('et_max_depth', 3, 10),\n","        'min_samples_split': trial.suggest_int('et_min_samples_split', 2, 10),\n","        'max_features': trial.suggest_categorical('et_max_features', ['sqrt', 'log2'])\n","    }\n","\n","    # Train ExtraTrees\n","    et_model = ExtraTreesRegressor(**et_params, random_state=42, n_jobs=-1)\n","    et_model.fit(X_val_et, Y_val)\n","    return mean_absolute_error(Y_val, et_model.predict(X_val_et))\n","\n","# --- Run Optimization ---\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=30)\n","\n","# --- Train Final Model with Best Params ---\n","best_params = study.best_params\n","print(\"Best Params:\", best_params)\n","\n","# (Re-train with best params on full data and evaluate)"],"metadata":{"id":"9vqG9yM-TaTD","executionInfo":{"status":"ok","timestamp":1743263370211,"user_tz":-330,"elapsed":4341959,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"cb8858e1-23dc-49dd-a92d-177a4b4cde8b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 14:37:13,281] A new study created in memory with name: no-name-a307de8a-3239-4ead-b7a6-c9414b71fb0f\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 14:41:00,629] Trial 0 finished with value: 0.0024811500242978264 and parameters: {'lstm_units': 121, 'lstm_lr': 0.007007548974473547, 'batch_size': 32, 'epochs': 35, 'et_n_estimators': 144, 'et_max_depth': 8, 'et_min_samples_split': 5, 'et_max_features': 'log2'}. Best is trial 0 with value: 0.0024811500242978264.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 14:45:09,275] Trial 1 finished with value: 0.006596162349422881 and parameters: {'lstm_units': 96, 'lstm_lr': 0.00346804116518289, 'batch_size': 16, 'epochs': 19, 'et_n_estimators': 108, 'et_max_depth': 4, 'et_min_samples_split': 10, 'et_max_features': 'sqrt'}. Best is trial 0 with value: 0.0024811500242978264.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 14:48:00,878] Trial 2 finished with value: 0.0025266940391710448 and parameters: {'lstm_units': 101, 'lstm_lr': 0.005985035395540961, 'batch_size': 64, 'epochs': 50, 'et_n_estimators': 156, 'et_max_depth': 6, 'et_min_samples_split': 10, 'et_max_features': 'log2'}. Best is trial 0 with value: 0.0024811500242978264.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 14:51:43,600] Trial 3 finished with value: 0.001858540757759991 and parameters: {'lstm_units': 50, 'lstm_lr': 0.00018410646844921956, 'batch_size': 32, 'epochs': 35, 'et_n_estimators': 157, 'et_max_depth': 8, 'et_min_samples_split': 3, 'et_max_features': 'log2'}. Best is trial 3 with value: 0.001858540757759991.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 14:59:07,691] Trial 4 finished with value: 0.011144615563957436 and parameters: {'lstm_units': 79, 'lstm_lr': 0.0005033634006682623, 'batch_size': 16, 'epochs': 37, 'et_n_estimators': 122, 'et_max_depth': 3, 'et_min_samples_split': 10, 'et_max_features': 'sqrt'}. Best is trial 3 with value: 0.001858540757759991.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:01:25,238] Trial 5 finished with value: 0.0027352477637309267 and parameters: {'lstm_units': 46, 'lstm_lr': 0.00023669500940889089, 'batch_size': 64, 'epochs': 41, 'et_n_estimators': 163, 'et_max_depth': 6, 'et_min_samples_split': 5, 'et_max_features': 'sqrt'}. Best is trial 3 with value: 0.001858540757759991.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:05:13,754] Trial 6 finished with value: 0.0025290962936505403 and parameters: {'lstm_units': 83, 'lstm_lr': 0.0037163884551604854, 'batch_size': 16, 'epochs': 18, 'et_n_estimators': 74, 'et_max_depth': 6, 'et_min_samples_split': 4, 'et_max_features': 'sqrt'}. Best is trial 3 with value: 0.001858540757759991.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:09:08,153] Trial 7 finished with value: 0.006788274535953749 and parameters: {'lstm_units': 37, 'lstm_lr': 0.002830671195654449, 'batch_size': 16, 'epochs': 20, 'et_n_estimators': 54, 'et_max_depth': 4, 'et_min_samples_split': 9, 'et_max_features': 'log2'}. Best is trial 3 with value: 0.001858540757759991.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:10:22,506] Trial 8 finished with value: 0.0016425890967256217 and parameters: {'lstm_units': 125, 'lstm_lr': 0.0037823195051217983, 'batch_size': 64, 'epochs': 22, 'et_n_estimators': 183, 'et_max_depth': 9, 'et_min_samples_split': 6, 'et_max_features': 'log2'}. Best is trial 8 with value: 0.0016425890967256217.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:11:47,734] Trial 9 finished with value: 0.010997257247735967 and parameters: {'lstm_units': 102, 'lstm_lr': 0.00013003764290600415, 'batch_size': 64, 'epochs': 24, 'et_n_estimators': 104, 'et_max_depth': 3, 'et_min_samples_split': 5, 'et_max_features': 'sqrt'}. Best is trial 8 with value: 0.0016425890967256217.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:12:35,466] Trial 10 finished with value: 0.0016444758773383591 and parameters: {'lstm_units': 123, 'lstm_lr': 0.001395676569699605, 'batch_size': 64, 'epochs': 12, 'et_n_estimators': 198, 'et_max_depth': 10, 'et_min_samples_split': 7, 'et_max_features': 'log2'}. Best is trial 8 with value: 0.0016425890967256217.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:13:21,775] Trial 11 finished with value: 0.0016610847529081258 and parameters: {'lstm_units': 128, 'lstm_lr': 0.0011010180140717208, 'batch_size': 64, 'epochs': 11, 'et_n_estimators': 195, 'et_max_depth': 10, 'et_min_samples_split': 7, 'et_max_features': 'log2'}. Best is trial 8 with value: 0.0016425890967256217.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:14:07,281] Trial 12 finished with value: 0.0016545220509906946 and parameters: {'lstm_units': 116, 'lstm_lr': 0.0012989357292726635, 'batch_size': 64, 'epochs': 11, 'et_n_estimators': 195, 'et_max_depth': 10, 'et_min_samples_split': 7, 'et_max_features': 'log2'}. Best is trial 8 with value: 0.0016425890967256217.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:15:38,035] Trial 13 finished with value: 0.0017083543382603258 and parameters: {'lstm_units': 112, 'lstm_lr': 0.0016291538747506696, 'batch_size': 64, 'epochs': 27, 'et_n_estimators': 180, 'et_max_depth': 9, 'et_min_samples_split': 7, 'et_max_features': 'log2'}. Best is trial 8 with value: 0.0016425890967256217.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:16:33,492] Trial 14 finished with value: 0.001744727534457605 and parameters: {'lstm_units': 72, 'lstm_lr': 0.009975528724033648, 'batch_size': 64, 'epochs': 15, 'et_n_estimators': 182, 'et_max_depth': 8, 'et_min_samples_split': 8, 'et_max_features': 'log2'}. Best is trial 8 with value: 0.0016425890967256217.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:18:02,863] Trial 15 finished with value: 0.0016472698838778106 and parameters: {'lstm_units': 126, 'lstm_lr': 0.0005146674443896945, 'batch_size': 64, 'epochs': 25, 'et_n_estimators': 200, 'et_max_depth': 9, 'et_min_samples_split': 2, 'et_max_features': 'log2'}. Best is trial 8 with value: 0.0016425890967256217.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:19:41,656] Trial 16 finished with value: 0.0015650232753677221 and parameters: {'lstm_units': 109, 'lstm_lr': 0.0020624883080611884, 'batch_size': 32, 'epochs': 15, 'et_n_estimators': 136, 'et_max_depth': 10, 'et_min_samples_split': 6, 'et_max_features': 'log2'}. Best is trial 16 with value: 0.0015650232753677221.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:22:52,949] Trial 17 finished with value: 0.0021473580985102527 and parameters: {'lstm_units': 91, 'lstm_lr': 0.002029070322664711, 'batch_size': 32, 'epochs': 30, 'et_n_estimators': 135, 'et_max_depth': 7, 'et_min_samples_split': 6, 'et_max_features': 'log2'}. Best is trial 16 with value: 0.0015650232753677221.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:25:07,780] Trial 18 finished with value: 0.001724239643491734 and parameters: {'lstm_units': 110, 'lstm_lr': 0.0005351069245463085, 'batch_size': 32, 'epochs': 21, 'et_n_estimators': 94, 'et_max_depth': 9, 'et_min_samples_split': 6, 'et_max_features': 'log2'}. Best is trial 16 with value: 0.0015650232753677221.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:28:16,872] Trial 19 finished with value: 0.0021793465420821825 and parameters: {'lstm_units': 108, 'lstm_lr': 0.005225431867051273, 'batch_size': 32, 'epochs': 29, 'et_n_estimators': 173, 'et_max_depth': 7, 'et_min_samples_split': 4, 'et_max_features': 'log2'}. Best is trial 16 with value: 0.0015650232753677221.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:29:58,610] Trial 20 finished with value: 0.0016661454239736777 and parameters: {'lstm_units': 68, 'lstm_lr': 0.002490805080480492, 'batch_size': 32, 'epochs': 15, 'et_n_estimators': 125, 'et_max_depth': 9, 'et_min_samples_split': 8, 'et_max_features': 'log2'}. Best is trial 16 with value: 0.0015650232753677221.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:30:59,609] Trial 21 finished with value: 0.0016432517066945571 and parameters: {'lstm_units': 116, 'lstm_lr': 0.0008050856123925385, 'batch_size': 64, 'epochs': 15, 'et_n_estimators': 177, 'et_max_depth': 10, 'et_min_samples_split': 6, 'et_max_features': 'log2'}. Best is trial 16 with value: 0.0015650232753677221.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:31:58,665] Trial 22 finished with value: 0.001647108554618663 and parameters: {'lstm_units': 117, 'lstm_lr': 0.0007626659811231377, 'batch_size': 64, 'epochs': 16, 'et_n_estimators': 142, 'et_max_depth': 10, 'et_min_samples_split': 6, 'et_max_features': 'log2'}. Best is trial 16 with value: 0.0015650232753677221.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:34:30,153] Trial 23 finished with value: 0.0015657263140411272 and parameters: {'lstm_units': 107, 'lstm_lr': 0.0007509069126576348, 'batch_size': 32, 'epochs': 23, 'et_n_estimators': 167, 'et_max_depth': 10, 'et_min_samples_split': 4, 'et_max_features': 'log2'}. Best is trial 16 with value: 0.0015650232753677221.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:37:00,752] Trial 24 finished with value: 0.0015329320526116107 and parameters: {'lstm_units': 90, 'lstm_lr': 0.004364772840669995, 'batch_size': 32, 'epochs': 23, 'et_n_estimators': 167, 'et_max_depth': 9, 'et_min_samples_split': 4, 'et_max_features': 'log2'}. Best is trial 24 with value: 0.0015329320526116107.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:40:09,224] Trial 25 finished with value: 0.0017117964868389533 and parameters: {'lstm_units': 85, 'lstm_lr': 0.002151868651881023, 'batch_size': 32, 'epochs': 31, 'et_n_estimators': 162, 'et_max_depth': 8, 'et_min_samples_split': 3, 'et_max_features': 'log2'}. Best is trial 24 with value: 0.0015329320526116107.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:42:38,384] Trial 26 finished with value: 0.0016009329463151218 and parameters: {'lstm_units': 93, 'lstm_lr': 0.00030967236118288214, 'batch_size': 32, 'epochs': 24, 'et_n_estimators': 147, 'et_max_depth': 10, 'et_min_samples_split': 4, 'et_max_features': 'sqrt'}. Best is trial 24 with value: 0.0015329320526116107.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:45:38,345] Trial 27 finished with value: 0.0015953229814201534 and parameters: {'lstm_units': 103, 'lstm_lr': 0.0008950592362671808, 'batch_size': 32, 'epochs': 27, 'et_n_estimators': 131, 'et_max_depth': 9, 'et_min_samples_split': 2, 'et_max_features': 'log2'}. Best is trial 24 with value: 0.0015329320526116107.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:47:34,536] Trial 28 finished with value: 0.001501043851207137 and parameters: {'lstm_units': 63, 'lstm_lr': 0.0017480917852129142, 'batch_size': 32, 'epochs': 18, 'et_n_estimators': 166, 'et_max_depth': 10, 'et_min_samples_split': 3, 'et_max_features': 'log2'}. Best is trial 28 with value: 0.001501043851207137.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 15:49:35,215] Trial 29 finished with value: 0.0020161468774083555 and parameters: {'lstm_units': 72, 'lstm_lr': 0.00865274341386862, 'batch_size': 32, 'epochs': 18, 'et_n_estimators': 149, 'et_max_depth': 7, 'et_min_samples_split': 3, 'et_max_features': 'log2'}. Best is trial 28 with value: 0.001501043851207137.\n"]},{"output_type":"stream","name":"stdout","text":["Best Params: {'lstm_units': 63, 'lstm_lr': 0.0017480917852129142, 'batch_size': 32, 'epochs': 18, 'et_n_estimators': 166, 'et_max_depth': 10, 'et_min_samples_split': 3, 'et_max_features': 'log2'}\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.ensemble import ExtraTreesRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","\n","# Configure GPU\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Best parameters (from your Optuna study)\n","best_params = {\n","    'lstm_units': 63,\n","    'lstm_lr': 0.0017480917852129142,\n","    'batch_size': 32,\n","    'epochs': 18,\n","    'et_n_estimators': 166,\n","    'et_max_depth': 10,\n","    'et_min_samples_split': 3,\n","    'et_max_features': 'log2'\n","}\n","\n","# Custom MAPE calculation\n","def mean_absolute_percentage_error(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100  # Added small constant to avoid division by zero\n","\n","# LSTM training function with timing\n","def train_lstm(X_train, Y_train, units, layers, lr, batch_size, epochs):\n","    start_time = time.time()\n","\n","    model = tf.keras.Sequential()\n","    for _ in range(layers - 1):\n","        model.add(LSTM(units, return_sequences=True))\n","    model.add(LSTM(units))\n","    model.add(Dense(1))\n","    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='mse')\n","\n","    history = model.fit(\n","        X_train, Y_train,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        verbose=1\n","    )\n","\n","    training_time = time.time() - start_time\n","    return model, history, training_time\n","\n","# --- PHASE 1: Train All LSTM Models ---\n","lstm_models = {}\n","lstm_train_times = {}\n","lstm_pred_times = {'train': [], 'val': [], 'test': []}\n","\n","print(\"=== TRAINING LSTM MODELS ===\")\n","for layers in [2, 3, 5]:\n","    print(f\"\\nTraining LSTM with {layers} layers...\")\n","    model, _, train_time = train_lstm(\n","        X_train=np.expand_dims(X_train, -1),\n","        Y_train=Y_train,\n","        units=best_params['lstm_units'],\n","        layers=layers,\n","        lr=best_params['lstm_lr'],\n","        batch_size=best_params['batch_size'],\n","        epochs=best_params['epochs']\n","    )\n","    lstm_models[f'lstm_{layers}layers'] = model\n","    lstm_train_times[f'lstm_{layers}layers'] = train_time\n","\n","    # Time predictions for each dataset\n","    for dataset, x_data in [('train', X_train), ('val', X_val), ('test', X_test)]:\n","        start_time = time.time()\n","        model.predict(np.expand_dims(x_data, -1), verbose=0)\n","        lstm_pred_times[dataset].append(time.time() - start_time)\n","\n","# --- PHASE 2: Prepare Stacked Features ---\n","print(\"\\n=== PREPARING STACKED FEATURES ===\")\n","def get_stacked_features(X):\n","    start_time = time.time()\n","    features = np.column_stack([\n","        model.predict(np.expand_dims(X, -1), verbose=0).flatten()\n","        for model in lstm_models.values()\n","    ])\n","    return features, time.time() - start_time\n","\n","X_train_et, train_stack_time = get_stacked_features(X_train)\n","X_val_et, val_stack_time = get_stacked_features(X_val)\n","X_test_et, test_stack_time = get_stacked_features(X_test)\n","\n","# --- PHASE 3: Train Extra Trees ---\n","print(\"\\n=== TRAINING EXTRA TREES ===\")\n","start_time = time.time()\n","et_model = ExtraTreesRegressor(\n","    n_estimators=best_params['et_n_estimators'],\n","    max_depth=best_params['et_max_depth'],\n","    min_samples_split=best_params['et_min_samples_split'],\n","    max_features=best_params['et_max_features'],\n","    random_state=42,\n","    n_jobs=-1\n",")\n","et_model.fit(X_train_et, Y_train)\n","et_train_time = time.time() - start_time\n","\n","# --- PHASE 4: Make Predictions ---\n","print(\"\\n=== MAKING PREDICTIONS ===\")\n","def timed_predict(model, X):\n","    start_time = time.time()\n","    preds = model.predict(X)\n","    return preds, time.time() - start_time\n","\n","Y_train_pred, train_pred_time = timed_predict(et_model, X_train_et)\n","Y_val_pred, val_pred_time = timed_predict(et_model, X_val_et)\n","Y_test_pred, test_pred_time = timed_predict(et_model, X_test_et)\n","\n","# --- PHASE 5: Calculate Metrics ---\n","def calculate_all_metrics(y_true, y_pred):\n","    return {\n","        'MAE': mean_absolute_error(y_true, y_pred),\n","        'MSE': mean_squared_error(y_true, y_pred),\n","        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n","        'R2': r2_score(y_true, y_pred),\n","        'MAPE': mean_absolute_percentage_error(y_true, y_pred)\n","    }\n","\n","metrics_train = calculate_all_metrics(Y_train, Y_train_pred)\n","metrics_val = calculate_all_metrics(Y_val, Y_val_pred)\n","metrics_test = calculate_all_metrics(Y_test, Y_test_pred)\n","\n","# --- PHASE 6: Print Comprehensive Results ---\n","print(\"\\n=== FINAL RESULTS ===\")\n","\n","# 1. Timing Metrics\n","print(\"\\n=== TIMING METRICS (seconds) ===\")\n","print(f\"{'LSTM Training Times':<25} {'2L':<8} {'3L':<8} {'5L':<8}\")\n","print(f\"{'':<25} {lstm_train_times['lstm_2layers']:<8.2f} {lstm_train_times['lstm_3layers']:<8.2f} {lstm_train_times['lstm_5layers']:<8.2f}\")\n","\n","print(\"\\nLSTM Prediction Times per Dataset:\")\n","print(f\"{'Dataset':<15} {'2L':<8} {'3L':<8} {'5L':<8}\")\n","for dataset in ['train', 'val', 'test']:\n","    times = lstm_pred_times[dataset]\n","    print(f\"{dataset:<15} {times[0]:<8.4f} {times[1]:<8.4f} {times[2]:<8.4f}\")\n","\n","print(f\"\\n{'Feature Stacking Time':<30} {train_stack_time:.4f} (train) | {val_stack_time:.4f} (val) | {test_stack_time:.4f} (test)\")\n","print(f\"{'Extra Trees Training Time':<30} {et_train_time:.2f}\")\n","print(f\"{'Extra Trees Prediction Time':<30} {train_pred_time:.4f} (train) | {val_pred_time:.4f} (val) | {test_pred_time:.4f} (test)\")\n","\n","# 2. Performance Metrics\n","print(\"\\n=== PERFORMANCE METRICS ===\")\n","def print_metrics(name, metrics):\n","    print(f\"\\n{name}:\")\n","    print(f\"{'MAE':<10} {metrics['MAE']:.4f}\")\n","    print(f\"{'MSE':<10} {metrics['MSE']:.4f}\")\n","    print(f\"{'RMSE':<10} {metrics['RMSE']:.4f}\")\n","    print(f\"{'R2':<10} {metrics['R2']:.4f}\")\n","    print(f\"{'MAPE':<10} {metrics['MAPE']:.2f}%\")\n","\n","print_metrics(\"Training Set\", metrics_train)\n","print_metrics(\"Validation Set\", metrics_val)\n","print_metrics(\"Test Set\", metrics_test)\n","\n","# 3. Feature Importance\n","print(\"\\n=== FEATURE IMPORTANCES ===\")\n","for i, (name, importance) in enumerate(zip(lstm_models.keys(), et_model.feature_importances_)):\n","    print(f\"{name:<15} {importance:.4f}\")"],"metadata":{"id":"3JZecfBqmb1a","executionInfo":{"status":"ok","timestamp":1743263954083,"user_tz":-330,"elapsed":133707,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"1a12ab1e-a6fb-4cef-829e-532e516e36f6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["=== TRAINING LSTM MODELS ===\n","\n","Training LSTM with 2 layers...\n","Epoch 1/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0535\n","Epoch 2/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.5853e-05\n","Epoch 3/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 4.0391e-05\n","Epoch 4/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.7746e-05\n","Epoch 5/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.0562e-05\n","Epoch 6/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.0531e-05\n","Epoch 7/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.4114e-05\n","Epoch 8/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.9513e-05\n","Epoch 9/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.0090e-05\n","Epoch 10/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 3.3574e-05\n","Epoch 11/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 3.2411e-05\n","Epoch 12/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.5197e-05\n","Epoch 13/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.0898e-05\n","Epoch 14/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.9336e-05\n","Epoch 15/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.4692e-05\n","Epoch 16/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.8697e-05\n","Epoch 17/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.0486e-05\n","Epoch 18/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.1119e-05\n","\n","Training LSTM with 3 layers...\n","Epoch 1/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0499\n","Epoch 2/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 7.1871e-05\n","Epoch 3/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5659e-05\n","Epoch 4/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.2739e-05\n","Epoch 5/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 3.4008e-05\n","Epoch 6/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 4.8576e-05\n","Epoch 7/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.0875e-05\n","Epoch 8/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 5.8823e-05\n","Epoch 9/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.6958e-05\n","Epoch 10/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.0687e-04\n","Epoch 11/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.0559e-04\n","Epoch 12/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.2903e-05\n","Epoch 13/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.5632e-05\n","Epoch 14/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.0084e-05\n","Epoch 15/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.0141e-05\n","Epoch 16/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 4.6741e-05\n","Epoch 17/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.3879e-04\n","Epoch 18/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.4447e-05\n","\n","Training LSTM with 5 layers...\n","Epoch 1/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0690\n","Epoch 2/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 4.0536e-04\n","Epoch 3/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 1.9845e-04\n","Epoch 4/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.3926e-04\n","Epoch 5/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.1173e-04\n","Epoch 6/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 5.3415e-05\n","Epoch 7/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.5503e-04\n","Epoch 8/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1691e-04\n","Epoch 9/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.7809e-05\n","Epoch 10/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 8.1163e-05\n","Epoch 11/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 9.2655e-05\n","Epoch 12/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.6354e-05\n","Epoch 13/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 4.9003e-05\n","Epoch 14/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 3.9899e-04\n","Epoch 15/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 2.2444e-04\n","Epoch 16/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 8.9105e-05\n","Epoch 17/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.3434e-04\n","Epoch 18/18\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.5354e-04\n","\n","=== PREPARING STACKED FEATURES ===\n","\n","=== TRAINING EXTRA TREES ===\n","\n","=== MAKING PREDICTIONS ===\n","\n","=== FINAL RESULTS ===\n","\n","=== TIMING METRICS (seconds) ===\n","LSTM Training Times       2L       3L       5L      \n","                          28.41    39.17    54.44   \n","\n","LSTM Prediction Times per Dataset:\n","Dataset         2L       3L       5L      \n","train           1.2454   1.3304   2.5932  \n","val             0.3638   0.1892   0.3538  \n","test            0.3644   0.1755   0.2149  \n","\n","Feature Stacking Time          2.5661 (train) | 0.7202 (val) | 0.7316 (test)\n","Extra Trees Training Time      0.52\n","Extra Trees Prediction Time    0.1430 (train) | 0.0540 (val) | 0.0605 (test)\n","\n","=== PERFORMANCE METRICS ===\n","\n","Training Set:\n","MAE        0.0034\n","MSE        0.0000\n","RMSE       0.0048\n","R2         0.9999\n","MAPE       1.08%\n","\n","Validation Set:\n","MAE        0.1385\n","MSE        0.0249\n","RMSE       0.1577\n","R2         -3.2306\n","MAPE       7.76%\n","\n","Test Set:\n","MAE        0.4069\n","MSE        0.1716\n","RMSE       0.4143\n","R2         -27.4353\n","MAPE       20.07%\n","\n","=== FEATURE IMPORTANCES ===\n","lstm_2layers    0.3148\n","lstm_3layers    0.3743\n","lstm_5layers    0.3109\n"]}]},{"cell_type":"markdown","source":["## BOHB"],"metadata":{"id":"eZRR2DI_T-8W"}},{"cell_type":"code","source":["!pip install ConfigSpace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXtRijg2ULai","executionInfo":{"status":"ok","timestamp":1743236502465,"user_tz":-330,"elapsed":7208,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"bfbc763b-655c-4edf-eb31-1ce672430e37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ConfigSpace\n","  Downloading configspace-1.2.1.tar.gz (130 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (2.0.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (3.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (1.14.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (10.6.0)\n","Building wheels for collected packages: ConfigSpace\n","  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ConfigSpace: filename=configspace-1.2.1-py3-none-any.whl size=115990 sha256=2223b63ddd46f77450a71d7a4c4838e63b88159927e3a97695871e14fbaea187\n","  Stored in directory: /root/.cache/pip/wheels/11/0f/36/d5027c3eeb038827889830f7efbe6a1bad8956b3eb44ab2f44\n","Successfully built ConfigSpace\n","Installing collected packages: ConfigSpace\n","Successfully installed ConfigSpace-1.2.1\n"]}]},{"cell_type":"code","source":["!pip install hpbandster"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptsnU6gQUVYy","executionInfo":{"status":"ok","timestamp":1743236511910,"user_tz":-330,"elapsed":7832,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"31d1a575-8754-4ba9-e928-2b7ea353bad1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hpbandster\n","  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Pyro4 (from hpbandster)\n","  Downloading Pyro4-4.82-py2.py3-none-any.whl.metadata (2.2 kB)\n","Collecting serpent (from hpbandster)\n","  Downloading serpent-1.41-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hpbandster) (2.0.2)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.14.1)\n","Collecting netifaces (from hpbandster)\n","  Downloading netifaces-0.11.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (3.2.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (10.6.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n","Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading serpent-1.41-py3-none-any.whl (9.6 kB)\n","Building wheels for collected packages: hpbandster, netifaces\n","  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=79986 sha256=295fd854a5d1c094592ba232ba3b4a6a5b30714c33e67485ce9e5b477bc4915f\n","  Stored in directory: /root/.cache/pip/wheels/fb/da/7d/af80a6b0a6898aaf2e1e93ab00cdf03251624e67f0641e9f0b\n","  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for netifaces: filename=netifaces-0.11.0-cp311-cp311-linux_x86_64.whl size=35182 sha256=131db818d333000517225e536b268cf5771ef71bb90a8ee18d8e149159d053ba\n","  Stored in directory: /root/.cache/pip/wheels/40/85/29/648c19bbbb5f1d30e33bfb343fd7fb54296b402f7205d8e46f\n","Successfully built hpbandster netifaces\n","Installing collected packages: netifaces, serpent, Pyro4, hpbandster\n","Successfully installed Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","from sklearn.ensemble import ExtraTreesRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import time\n","\n","# Check for GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define LSTM Model\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","# Function to calculate metrics\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Convert datasets to PyTorch tensors and move to GPU\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# LSTM Configurations\n","lstm_layers = [2, 3, 5]\n","hidden_dim = 64\n","output_dim = 1\n","input_dim = X_train.shape[1]\n","\n","# Dictionary to store LSTM feature representations\n","lstm_features = []\n","\n","for num_layers in lstm_layers:\n","    print(f\"Training LSTM with {num_layers} layers...\")\n","\n","    lstm_model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n","    num_epochs = 35\n","\n","    start_time = time.time()\n","    for epoch in range(num_epochs):\n","        lstm_model.train()\n","        optimizer.zero_grad()\n","        outputs = lstm_model(X_train_torch)\n","        loss = criterion(outputs, Y_train_torch)\n","        loss.backward()\n","        optimizer.step()\n","    train_time = time.time() - start_time\n","\n","    # Extract Feature Representations\n","    lstm_model.eval()\n","    with torch.no_grad():\n","        val_start = time.time()\n","        train_features = lstm_model(X_train_torch).cpu().numpy()\n","        val_features = lstm_model(X_val_torch).cpu().numpy()\n","        val_time = time.time() - val_start\n","\n","        test_start = time.time()\n","        test_features = lstm_model(X_test_torch).cpu().numpy()\n","        test_time = time.time() - test_start\n","\n","    lstm_features.append((train_features, val_features, test_features, train_time, val_time, test_time))\n","\n","# Concatenate Features from All Layers\n","final_train_features = np.hstack([feat[0] for feat in lstm_features])\n","final_val_features = np.hstack([feat[1] for feat in lstm_features])\n","final_test_features = np.hstack([feat[2] for feat in lstm_features])\n","\n","# Record Time for Each Stage\n","total_train_time = sum([feat[3] for feat in lstm_features])\n","total_val_time = sum([feat[4] for feat in lstm_features])\n","total_test_time = sum([feat[5] for feat in lstm_features])\n","\n","# Define ConfigSpace for BOHB\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"n_estimators\", 50, 500, default_value=100))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"max_depth\", 3, 15, default_value=6))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_split\", 2, 10, default_value=2))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 5, default_value=1))\n","    return cs\n","\n","# BOHB Worker for Extra Trees\n","class ETWorker(Worker):\n","    def compute(self, config, budget, **kwargs):\n","        model = ExtraTreesRegressor(\n","            n_estimators=config[\"n_estimators\"],\n","            max_depth=config[\"max_depth\"],\n","            min_samples_split=config[\"min_samples_split\"],\n","            min_samples_leaf=config[\"min_samples_leaf\"],\n","            random_state=42\n","        )\n","        model.fit(final_train_features, Y_train)\n","        Y_val_pred = model.predict(final_val_features)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Run BOHB\n","NS = hpns.NameServer(run_id=\"lstm_et_bohb\", host=\"127.0.0.2\", port=None)\n","NS.start()\n","\n","worker = ETWorker(nameserver=\"127.0.0.2\", run_id=\"lstm_et_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(configspace=get_config_space(), run_id=\"lstm_et_bohb\", nameserver=\"127.0.0.2\", min_budget=1, max_budget=3)\n","res = bohb.run(n_iterations=50)\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Train Best Extra Trees Model\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","best_et_model = ExtraTreesRegressor(\n","    n_estimators=best_params[\"n_estimators\"],\n","    max_depth=best_params[\"max_depth\"],\n","    min_samples_split=best_params[\"min_samples_split\"],\n","    min_samples_leaf=best_params[\"min_samples_leaf\"],\n","    random_state=42\n",")\n","\n","best_et_model.fit(final_train_features, Y_train)\n","\n","# Predictions\n","Y_train_pred = best_et_model.predict(final_train_features)\n","Y_val_pred = best_et_model.predict(final_val_features)\n","Y_test_pred = best_et_model.predict(final_test_features)\n","\n","# Calculate Metrics\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print Results\n","print(\"Train Metrics:\", train_metrics, \"Time:\", total_train_time)\n","print(\"Validation Metrics:\", val_metrics, \"Time:\", total_val_time)\n","print(\"Test Metrics:\", test_metrics, \"Time:\", total_test_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtcD-y7TEpt-","executionInfo":{"status":"ok","timestamp":1743254871301,"user_tz":-330,"elapsed":231262,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"e7fd6725-ad1f-4fb7-d723-dd8dff51f8bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training LSTM with 2 layers...\n","Training LSTM with 3 layers...\n","Training LSTM with 5 layers...\n","Train Metrics: (0.002565484193522361, 1.3337153721626793e-05, 0.0036520068074452974, 0.9999237968401418, 0.8055239074732535) Time: 36.16904854774475\n","Validation Metrics: (0.13687320290358435, 0.02440584209047576, 0.1562236924748476, -3.1495642016183316, 7.660723872899469) Time: 0.40578222274780273\n","Test Metrics: (0.4051772716636299, 0.17020369186378098, 0.41255750128167706, -27.20243689579124, 19.980381794560085) Time: 0.058008670806884766\n"]}]},{"cell_type":"markdown","source":["# RandomForest"],"metadata":{"id":"uUCh_YB9Vf7S"}},{"cell_type":"markdown","source":["## Intial"],"metadata":{"id":"qUH36NvmtM2G"}},{"cell_type":"code","source":["import time\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.ensemble import RandomForestRegressor  # Changed from ExtraTreesRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Enable GPU for TensorFlow\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","        print(\"GPU activated for TensorFlow!\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Function to define and train an LSTM model on GPU (unchanged)\n","def train_lstm(X_train, Y_train, X_val, Y_val, layers):\n","    with tf.device('/GPU:0'):\n","        model = Sequential()\n","        model.add(LSTM(64, return_sequences=(layers > 1), input_shape=(X_train.shape[1], 1)))\n","        for _ in range(layers - 1):\n","            model.add(LSTM(64, return_sequences=(_ < layers - 2)))\n","        model.add(Dense(1))\n","\n","        model.compile(optimizer='adam', loss='mse')\n","        model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=16, verbose=0)\n","        return model\n","\n","# Reshaping input for LSTM (unchanged)\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Initialize timing dictionary (unchanged)\n","times = {}\n","\n","# Train Phase (includes training all LSTMs and Random Forest)\n","start_train_time = time.time()\n","\n","# Train 2, 3, and 5-layer LSTM models (unchanged)\n","lstm_models = {}\n","lstm_predictions = {}\n","\n","for layers in [2, 3, 5]:\n","    model = train_lstm(X_train_r, Y_train, X_val_r, Y_val, layers)\n","    lstm_models[layers] = model\n","\n","# Generate predictions from all LSTM models (unchanged)\n","for layers in [2, 3, 5]:\n","    Y_train_pred = lstm_models[layers].predict(X_train_r)\n","    Y_val_pred = lstm_models[layers].predict(X_val_r)\n","    Y_test_pred = lstm_models[layers].predict(X_test_r)\n","    lstm_predictions[layers] = (Y_train_pred, Y_val_pred, Y_test_pred)\n","\n","# Prepare input for Random Forest (unchanged except variable names)\n","X_train_rf = np.column_stack([lstm_predictions[layers][0] for layers in [2, 3, 5]])\n","X_val_rf = np.column_stack([lstm_predictions[layers][1] for layers in [2, 3, 5]])\n","X_test_rf = np.column_stack([lstm_predictions[layers][2] for layers in [2, 3, 5]])\n","\n","# Train Random Forest model (modified)\n","rf_model = RandomForestRegressor(n_estimators=100,\n","                               max_depth=None,\n","                               min_samples_split=2,\n","                               min_samples_leaf=1,\n","                               random_state=42,\n","                               n_jobs=-1)  # Using all available cores\n","rf_model.fit(X_train_rf, Y_train)\n","\n","times['Total Train Time'] = time.time() - start_train_time\n","\n","# Validation Phase (unchanged except variable names)\n","start_val_time = time.time()\n","Y_val_pred_rf = rf_model.predict(X_val_rf)\n","times['Total Validate Time'] = time.time() - start_val_time\n","\n","# Test Phase (unchanged except variable names)\n","start_test_time = time.time()\n","Y_test_pred_rf = rf_model.predict(X_test_rf)\n","times['Total Test Time'] = time.time() - start_test_time\n","\n","# Function to calculate metrics (unchanged)\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Compute and print metrics (unchanged except variable names)\n","metrics_train = compute_metrics(Y_train, rf_model.predict(X_train_rf))\n","metrics_val = compute_metrics(Y_val, Y_val_pred_rf)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_rf)\n","\n","print(\"\\nPerformance Metrics:\")\n","print(f\"Train Metrics: MAE={metrics_train[0]:.4f}, MSE={metrics_train[1]:.4f}, RMSE={metrics_train[2]:.4f}, R²={metrics_train[3]:.4f}, MAPE={metrics_train[4]:.2f}%\")\n","print(f\"Validation Metrics: MAE={metrics_val[0]:.4f}, MSE={metrics_val[1]:.4f}, RMSE={metrics_val[2]:.4f}, R²={metrics_val[3]:.4f}, MAPE={metrics_val[4]:.2f}%\")\n","print(f\"Test Metrics: MAE={metrics_test[0]:.4f}, MSE={metrics_test[1]:.4f}, RMSE={metrics_test[2]:.4f}, R²={metrics_test[3]:.4f}, MAPE={metrics_test[4]:.2f}%\")\n","\n","# Print timing information (unchanged)\n","print(\"\\nTiming Information:\")\n","for phase, t in times.items():\n","    print(f\"{phase}: {t:.2f} seconds\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hcZDoVAPV2Gh","executionInfo":{"status":"ok","timestamp":1743250314988,"user_tz":-330,"elapsed":267446,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"c94551af-c14e-4fdf-aba9-df6552ffb531"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU activated for TensorFlow!\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\n","Performance Metrics:\n","Train Metrics: MAE=0.0011, MSE=0.0000, RMSE=0.0017, R²=1.0000, MAPE=0.33%\n","Validation Metrics: MAE=0.1375, MSE=0.0246, RMSE=0.1568, R²=-3.1781, MAPE=7.70%\n","Test Metrics: MAE=0.4058, MSE=0.1707, RMSE=0.4132, R²=-27.2845, MAPE=20.01%\n","\n","Timing Information:\n","Total Train Time: 267.27 seconds\n","Total Validate Time: 0.03 seconds\n","Total Test Time: 0.03 seconds\n"]}]},{"cell_type":"markdown","source":["## Optuna"],"metadata":{"id":"PnPul0h2lqPU"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iaFt4LZ3mLdj","executionInfo":{"status":"ok","timestamp":1743245087306,"user_tz":-330,"elapsed":4340,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"eec623b9-2529-4503-8b79-6008855fa3f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"F2BHvQTFLRsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.ensemble import RandomForestRegressor\n","import optuna\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","\n","# Configure GPU\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Restrict TensorFlow to only allocate required GPU memory\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.list_logical_devices('GPU')\n","        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Early stopping callback\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Function to train LSTM model with GPU acceleration\n","def train_lstm(X_train, Y_train, X_val, Y_val, units, layers, learning_rate, batch_size, epochs):\n","    # Use strategy scope for multi-GPU support (if available)\n","    strategy = tf.distribute.MirroredStrategy()\n","    with strategy.scope():\n","        model = keras.Sequential()\n","        for _ in range(layers - 1):\n","            model.add(LSTM(units, return_sequences=True))\n","        model.add(LSTM(units))\n","        model.add(Dense(1))\n","\n","        model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n","                     loss=\"mse\")\n","\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","\n","    # Convert data to TensorFlow tensors\n","    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n","    train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n","    val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","    start_time = time.time()\n","    history = model.fit(train_dataset,\n","                       validation_data=val_dataset,\n","                       epochs=epochs,\n","                       verbose=0,\n","                       callbacks=[early_stopping])\n","    lstm_train_time = time.time() - start_time\n","\n","    return model, history, lstm_train_time\n","\n","# Updated objective function for Random Forest\n","def objective(trial):\n","    # LSTM parameters\n","    units = trial.suggest_int(\"lstm_units\", 32, 128, step=16)\n","    layers = trial.suggest_categorical(\"lstm_layers\", [2, 3, 5])\n","    learning_rate = trial.suggest_float(\"lstm_learning_rate\", 1e-4, 1e-2, log=True)\n","    batch_size = trial.suggest_categorical(\"lstm_batch_size\", [16, 32, 64])\n","    epochs = trial.suggest_int(\"lstm_epochs\", 10, 50, step=10)\n","\n","    # Reshape and train LSTM\n","    X_train_r = np.expand_dims(X_train, axis=-1)\n","    X_val_r = np.expand_dims(X_val, axis=-1)\n","    model, _, lstm_train_time = train_lstm(X_train_r, Y_train, X_val_r, Y_val,\n","                                         units, layers, learning_rate, batch_size, epochs)\n","    Y_val_pred_lstm = model.predict(X_val_r, verbose=0).flatten()\n","\n","    # Prepare data for Random Forest\n","    X_val_rf = np.column_stack([Y_val_pred_lstm])\n","\n","    # Random Forest hyperparameters\n","    rf_params = {\n","        \"n_estimators\": trial.suggest_int(\"rf_n_estimators\", 50, 200, step=50),\n","        \"max_depth\": trial.suggest_int(\"rf_max_depth\", 3, 10),\n","        \"min_samples_split\": trial.suggest_int(\"rf_min_samples_split\", 2, 10),\n","        \"min_samples_leaf\": trial.suggest_int(\"rf_min_samples_leaf\", 1, 5),\n","        \"max_features\": trial.suggest_categorical(\"rf_max_features\", ['sqrt', 'log2']),\n","        \"random_state\": 42,\n","        \"n_jobs\": -1\n","    }\n","\n","    # Train Random Forest\n","    start_time = time.time()\n","    rf_model = RandomForestRegressor(**rf_params)\n","    rf_model.fit(X_val_rf, Y_val)\n","    rf_train_time = time.time() - start_time\n","\n","    # Predict and evaluate\n","    Y_val_pred_rf = rf_model.predict(X_val_rf)\n","    rmse = np.sqrt(mean_squared_error(Y_val, Y_val_pred_rf))\n","\n","    print(f\"LSTM Training Time: {lstm_train_time:.2f} seconds\")\n","    print(f\"Random Forest Training Time: {rf_train_time:.2f} seconds\")\n","\n","    return rmse\n","\n","# Run Optuna study\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=25)\n","print(\"Best hyperparameters:\", study.best_params)\n","\n","# Final Model Implementation with Random Forest\n","best_params = study.best_params\n","units = best_params[\"lstm_units\"]\n","layers = best_params[\"lstm_layers\"]\n","learning_rate = best_params[\"lstm_learning_rate\"]\n","batch_size = best_params[\"lstm_batch_size\"]\n","epochs = best_params[\"lstm_epochs\"]\n","n_estimators = best_params[\"rf_n_estimators\"]\n","max_depth = best_params[\"rf_max_depth\"]\n","min_samples_split = best_params[\"rf_min_samples_split\"]\n","min_samples_leaf = best_params[\"rf_min_samples_leaf\"]\n","max_features = best_params[\"rf_max_features\"]\n","\n","# Reshape input for LSTM\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Train final LSTM model\n","final_lstm, lstm_train_time = train_lstm(X_train_r, Y_train, X_val_r, Y_val,\n","                                       units, layers, learning_rate, batch_size, epochs)\n","\n","# Predictions with timing\n","start_time = time.time()\n","Y_train_pred_lstm = final_lstm.predict(X_train_r, verbose=0).flatten()\n","lstm_train_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_lstm = final_lstm.predict(X_val_r, verbose=0).flatten()\n","lstm_val_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_lstm = final_lstm.predict(X_test_r, verbose=0).flatten()\n","lstm_test_pred_time = time.time() - start_time\n","\n","# Prepare data for Random Forest\n","X_train_rf = np.column_stack([Y_train_pred_lstm])\n","X_val_rf = np.column_stack([Y_val_pred_lstm])\n","X_test_rf = np.column_stack([Y_test_pred_lstm])\n","\n","# Random Forest parameters\n","rf_params = {\n","    \"n_estimators\": n_estimators,\n","    \"max_depth\": max_depth,\n","    \"min_samples_split\": min_samples_split,\n","    \"min_samples_leaf\": min_samples_leaf,\n","    \"max_features\": max_features,\n","    \"random_state\": 42,\n","    \"n_jobs\": -1\n","}\n","\n","# Train final Random Forest model\n","start_time = time.time()\n","final_rf = RandomForestRegressor(**rf_params)\n","final_rf.fit(X_train_rf, Y_train)\n","rf_train_time = time.time() - start_time\n","\n","# Random Forest Predictions with timing\n","start_time = time.time()\n","Y_train_pred_rf = final_rf.predict(X_train_rf)\n","rf_train_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_rf = final_rf.predict(X_val_rf)\n","rf_val_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_rf = final_rf.predict(X_test_rf)\n","rf_test_pred_time = time.time() - start_time\n","\n","# Compute Metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train, Y_train_pred_rf)\n","metrics_val = compute_metrics(Y_val, Y_val_pred_rf)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_rf)\n","\n","# Print results\n","print(\"\\nFinal Model Performance:\")\n","print(f\"LSTM Training Time: {lstm_train_time:.2f} seconds\")\n","print(f\"Random Forest Training Time: {rf_train_time:.2f} seconds\\n\")\n","\n","print(f\"LSTM Train Prediction Time: {lstm_train_pred_time:.4f} seconds\")\n","print(f\"LSTM Validation Prediction Time: {lstm_val_pred_time:.4f} seconds\")\n","print(f\"LSTM Test Prediction Time: {lstm_test_pred_time:.4f} seconds\\n\")\n","\n","print(f\"Random Forest Train Prediction Time: {rf_train_pred_time:.4f} seconds\")\n","print(f\"Random Forest Validation Prediction Time: {rf_val_pred_time:.4f} seconds\")\n","print(f\"Random Forest Test Prediction Time: {rf_test_pred_time:.4f} seconds\\n\")\n","\n","print(\"Train Set Metrics:\")\n","print(f\"MAE: {metrics_train[0]:.4f}, MSE: {metrics_train[1]:.4f}, RMSE: {metrics_train[2]:.4f}, R²: {metrics_train[3]:.4f}, MAPE: {metrics_train[4]:.2f}%\")\n","\n","print(\"\\nValidation Set Metrics:\")\n","print(f\"MAE: {metrics_val[0]:.4f}, MSE: {metrics_val[1]:.4f}, RMSE: {metrics_val[2]:.4f}, R²: {metrics_val[3]:.4f}, MAPE: {metrics_val[4]:.2f}%\")\n","\n","print(\"\\nTest Set Metrics:\")\n","print(f\"MAE: {metrics_test[0]:.4f}, MSE: {metrics_test[1]:.4f}, RMSE: {metrics_test[2]:.4f}, R²: {metrics_test[3]:.4f}, MAPE: {metrics_test[4]:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tWME1g2xEXoP","executionInfo":{"status":"error","timestamp":1743255355145,"user_tz":-330,"elapsed":603409,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"bfcdb0db-ee4f-42ff-feae-8a8d5bb59527"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:25:56,750] A new study created in memory with name: no-name-385ec998-b0d4-44d2-a840-adc6f4d6dffc\n"]},{"output_type":"stream","name":"stdout","text":["1 Physical GPUs, 1 Logical GPUs\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:26:07,548] Trial 0 finished with value: 0.001961492249323409 and parameters: {'lstm_units': 80, 'lstm_layers': 2, 'lstm_learning_rate': 0.0005490612684285567, 'lstm_batch_size': 64, 'lstm_epochs': 30, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 2, 'rf_max_features': 'sqrt'}. Best is trial 0 with value: 0.001961492249323409.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 9.65 seconds\n","Random Forest Training Time: 0.35 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:27:00,040] Trial 1 finished with value: 0.002532995510984966 and parameters: {'lstm_units': 128, 'lstm_layers': 2, 'lstm_learning_rate': 0.008649461900744712, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'rf_n_estimators': 200, 'rf_max_depth': 10, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 3, 'rf_max_features': 'sqrt'}. Best is trial 0 with value: 0.001961492249323409.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 51.36 seconds\n","Random Forest Training Time: 0.35 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:27:14,342] Trial 2 finished with value: 0.0018125109141041145 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.00015907867683047526, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 13.16 seconds\n","Random Forest Training Time: 0.38 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:27:27,176] Trial 3 finished with value: 0.0022004612651811044 and parameters: {'lstm_units': 128, 'lstm_layers': 3, 'lstm_learning_rate': 0.0004612902879129881, 'lstm_batch_size': 64, 'lstm_epochs': 50, 'rf_n_estimators': 150, 'rf_max_depth': 10, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 5, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 11.69 seconds\n","Random Forest Training Time: 0.27 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:27:47,156] Trial 4 finished with value: 0.002314071819400903 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.00026139234420368036, 'lstm_batch_size': 32, 'lstm_epochs': 20, 'rf_n_estimators': 150, 'rf_max_depth': 6, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 5, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 18.83 seconds\n","Random Forest Training Time: 0.27 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:28:32,374] Trial 5 finished with value: 0.01012972899010514 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.0031565945674339618, 'lstm_batch_size': 16, 'lstm_epochs': 50, 'rf_n_estimators': 150, 'rf_max_depth': 3, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 44.08 seconds\n","Random Forest Training Time: 0.24 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:29:32,457] Trial 6 finished with value: 0.002083335544679415 and parameters: {'lstm_units': 48, 'lstm_layers': 2, 'lstm_learning_rate': 0.0007229560965324383, 'lstm_batch_size': 16, 'lstm_epochs': 50, 'rf_n_estimators': 100, 'rf_max_depth': 6, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 2, 'rf_max_features': 'sqrt'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 59.18 seconds\n","Random Forest Training Time: 0.17 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:30:05,657] Trial 7 finished with value: 0.0041820275858125994 and parameters: {'lstm_units': 96, 'lstm_layers': 2, 'lstm_learning_rate': 0.00018593986136564812, 'lstm_batch_size': 16, 'lstm_epochs': 50, 'rf_n_estimators': 150, 'rf_max_depth': 4, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 2, 'rf_max_features': 'sqrt'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 32.16 seconds\n","Random Forest Training Time: 0.24 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:30:32,392] Trial 8 finished with value: 0.002264996417367797 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.0008498071391575237, 'lstm_batch_size': 32, 'lstm_epochs': 20, 'rf_n_estimators': 150, 'rf_max_depth': 6, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 25.59 seconds\n","Random Forest Training Time: 0.26 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:31:36,360] Trial 9 finished with value: 0.0020671323691670053 and parameters: {'lstm_units': 32, 'lstm_layers': 3, 'lstm_learning_rate': 0.0003155721349271929, 'lstm_batch_size': 16, 'lstm_epochs': 40, 'rf_n_estimators': 200, 'rf_max_depth': 8, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 62.71 seconds\n","Random Forest Training Time: 0.34 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:31:57,707] Trial 10 finished with value: 0.002350284861531761 and parameters: {'lstm_units': 48, 'lstm_layers': 5, 'lstm_learning_rate': 0.00010142900158164547, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'rf_n_estimators': 50, 'rf_max_depth': 8, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 20.08 seconds\n","Random Forest Training Time: 0.09 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:32:06,952] Trial 11 finished with value: 0.0019325352526864848 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.0022222910913311526, 'lstm_batch_size': 64, 'lstm_epochs': 30, 'rf_n_estimators': 200, 'rf_max_depth': 8, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 7.97 seconds\n","Random Forest Training Time: 0.48 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:32:25,978] Trial 12 finished with value: 0.001882248738015702 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.0022592967657598145, 'lstm_batch_size': 64, 'lstm_epochs': 30, 'rf_n_estimators': 200, 'rf_max_depth': 8, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 17.85 seconds\n","Random Forest Training Time: 0.36 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:32:41,762] Trial 13 finished with value: 0.002276863453899723 and parameters: {'lstm_units': 48, 'lstm_layers': 5, 'lstm_learning_rate': 0.0018409739216420158, 'lstm_batch_size': 64, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 14.34 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:32:54,172] Trial 14 finished with value: 0.0018424307301031478 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.005493042737323932, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 11.24 seconds\n","Random Forest Training Time: 0.38 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:33:07,542] Trial 15 finished with value: 0.002078040448420761 and parameters: {'lstm_units': 64, 'lstm_layers': 2, 'lstm_learning_rate': 0.00955171072514633, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'rf_n_estimators': 50, 'rf_max_depth': 10, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 12.52 seconds\n","Random Forest Training Time: 0.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:33:30,220] Trial 16 finished with value: 0.002627164556152886 and parameters: {'lstm_units': 64, 'lstm_layers': 5, 'lstm_learning_rate': 0.004791692380475712, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 21.13 seconds\n","Random Forest Training Time: 0.37 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:33:46,216] Trial 17 finished with value: 0.0020554357369802793 and parameters: {'lstm_units': 112, 'lstm_layers': 2, 'lstm_learning_rate': 0.0013194086272617655, 'lstm_batch_size': 32, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 9, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 15.04 seconds\n","Random Forest Training Time: 0.17 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:33:59,104] Trial 18 finished with value: 0.002503708857998682 and parameters: {'lstm_units': 64, 'lstm_layers': 2, 'lstm_learning_rate': 0.00010036240527355147, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'rf_n_estimators': 200, 'rf_max_depth': 5, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 11.80 seconds\n","Random Forest Training Time: 0.33 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:34:18,136] Trial 19 finished with value: 0.0019843956286892017 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.005354301118049498, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'rf_n_estimators': 150, 'rf_max_depth': 7, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 17.99 seconds\n","Random Forest Training Time: 0.27 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:34:56,792] Trial 20 finished with value: 0.0023365571236856923 and parameters: {'lstm_units': 48, 'lstm_layers': 5, 'lstm_learning_rate': 0.00015694538561655054, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 37.16 seconds\n","Random Forest Training Time: 0.36 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:35:11,873] Trial 21 finished with value: 0.0019049609423117445 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.0037804131173137558, 'lstm_batch_size': 64, 'lstm_epochs': 40, 'rf_n_estimators': 200, 'rf_max_depth': 8, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 13.91 seconds\n","Random Forest Training Time: 0.35 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:35:24,829] Trial 22 finished with value: 0.0020595749800439355 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.0013959740677776796, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'rf_n_estimators': 200, 'rf_max_depth': 7, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 2, 'rf_max_features': 'sqrt'}. Best is trial 2 with value: 0.0018125109141041145.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 11.81 seconds\n","Random Forest Training Time: 0.35 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:35:35,667] Trial 23 finished with value: 0.0017643995138562482 and parameters: {'lstm_units': 48, 'lstm_layers': 2, 'lstm_learning_rate': 0.0024060989777901134, 'lstm_batch_size': 64, 'lstm_epochs': 30, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 23 with value: 0.0017643995138562482.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 9.66 seconds\n","Random Forest Training Time: 0.35 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 13:35:49,060] Trial 24 finished with value: 0.0016432612768511104 and parameters: {'lstm_units': 48, 'lstm_layers': 2, 'lstm_learning_rate': 0.006522190446147382, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'rf_n_estimators': 150, 'rf_max_depth': 10, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 24 with value: 0.0016432612768511104.\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Training Time: 12.33 seconds\n","Random Forest Training Time: 0.28 seconds\n","Best hyperparameters: {'lstm_units': 48, 'lstm_layers': 2, 'lstm_learning_rate': 0.006522190446147382, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'rf_n_estimators': 150, 'rf_max_depth': 10, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}\n"]},{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-ff99778ad0ca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Train final LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m final_lstm, lstm_train_time = train_lstm(X_train_r, Y_train, X_val_r, Y_val,\n\u001b[0m\u001b[1;32m    128\u001b[0m                                        units, layers, learning_rate, batch_size, epochs)\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","import joblib\n","\n","# Configure GPU\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Restrict TensorFlow to only allocate required GPU memory\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.list_logical_devices('GPU')\n","        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Early stopping callback\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Function to train LSTM model with GPU acceleration\n","def train_lstm(X_train, Y_train, X_val, Y_val, units, layers, learning_rate, batch_size, epochs):\n","    # Use strategy scope for multi-GPU support (if available)\n","    strategy = tf.distribute.MirroredStrategy()\n","    with strategy.scope():\n","        model = keras.Sequential()\n","        for _ in range(layers - 1):\n","            model.add(LSTM(units, return_sequences=True))\n","        model.add(LSTM(units))\n","        model.add(Dense(1))\n","\n","        model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n","                     loss=\"mse\")\n","\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","\n","    # Convert data to TensorFlow tensors\n","    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n","    train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n","    val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","    start_time = time.time()\n","    history = model.fit(train_dataset,\n","                       validation_data=val_dataset,\n","                       epochs=epochs,\n","                       verbose=1,  # Changed to verbose=1 to see training progress\n","                       callbacks=[early_stopping])\n","    train_time = time.time() - start_time\n","\n","    return model, history, train_time\n","\n","# Your best parameters from Optuna\n","best_params = {\n","    'lstm_units': 48,\n","    'lstm_layers': 2,\n","    'lstm_learning_rate': 0.006522190446147382,\n","    'lstm_batch_size': 64,\n","    'lstm_epochs': 10,\n","    'rf_n_estimators': 150,\n","    'rf_max_depth': 10,\n","    'rf_min_samples_split': 7,\n","    'rf_min_samples_leaf': 2,\n","    'rf_max_features': 'log2'\n","}\n","\n","# Extract parameters\n","units = best_params[\"lstm_units\"]\n","layers = best_params[\"lstm_layers\"]\n","learning_rate = best_params[\"lstm_learning_rate\"]\n","batch_size = best_params[\"lstm_batch_size\"]\n","epochs = best_params[\"lstm_epochs\"]\n","n_estimators = best_params[\"rf_n_estimators\"]\n","max_depth = best_params[\"rf_max_depth\"]\n","min_samples_split = best_params[\"rf_min_samples_split\"]\n","min_samples_leaf = best_params[\"rf_min_samples_leaf\"]\n","max_features = best_params[\"rf_max_features\"]\n","\n","# Reshape input for LSTM (assuming X_train, X_val, X_test are defined)\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Initialize timing dictionary\n","timing_metrics = {}\n","\n","# ========== LSTM Training ==========\n","print(\"\\n=== Training LSTM Model with Best Parameters ===\")\n","start_time = time.time()\n","final_lstm, _, lstm_train_time = train_lstm(\n","    X_train_r, Y_train, X_val_r, Y_val,\n","    units, layers, learning_rate, batch_size, epochs\n",")\n","timing_metrics['lstm_train'] = time.time() - start_time\n","print(f\"LSTM Training Completed in {timing_metrics['lstm_train']:.2f} seconds\")\n","\n","# LSTM Predictions\n","print(\"\\nGenerating LSTM predictions...\")\n","start_time = time.time()\n","Y_train_pred_lstm = final_lstm.predict(X_train_r, verbose=0).flatten()\n","timing_metrics['lstm_train_pred'] = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_lstm = final_lstm.predict(X_val_r, verbose=0).flatten()\n","timing_metrics['lstm_val_pred'] = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_lstm = final_lstm.predict(X_test_r, verbose=0).flatten()\n","timing_metrics['lstm_test_pred'] = time.time() - start_time\n","\n","# ========== Random Forest Preparation ==========\n","print(\"\\nPreparing data for Random Forest...\")\n","X_train_rf = np.column_stack([Y_train_pred_lstm])\n","X_val_rf = np.column_stack([Y_val_pred_lstm])\n","X_test_rf = np.column_stack([Y_test_pred_lstm])\n","\n","rf_params = {\n","    \"n_estimators\": n_estimators,\n","    \"max_depth\": max_depth,\n","    \"min_samples_split\": min_samples_split,\n","    \"min_samples_leaf\": min_samples_leaf,\n","    \"max_features\": max_features,\n","    \"random_state\": 42,\n","    \"n_jobs\": -1\n","}\n","\n","# ========== Random Forest Training ==========\n","print(\"\\n=== Training Random Forest Model ===\")\n","start_time = time.time()\n","final_rf = RandomForestRegressor(**rf_params)\n","final_rf.fit(X_train_rf, Y_train)\n","timing_metrics['rf_train'] = time.time() - start_time\n","print(f\"Random Forest Training Completed in {timing_metrics['rf_train']:.2f} seconds\")\n","\n","# Random Forest Predictions\n","print(\"\\nGenerating Random Forest predictions...\")\n","start_time = time.time()\n","Y_train_pred_rf = final_rf.predict(X_train_rf)\n","timing_metrics['rf_train_pred'] = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_rf = final_rf.predict(X_val_rf)\n","timing_metrics['rf_val_pred'] = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_rf = final_rf.predict(X_test_rf)\n","timing_metrics['rf_test_pred'] = time.time() - start_time\n","\n","# ========== Evaluation ==========\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / np.abs(y_true))) * 100  # Robust MAPE\n","    return mae, mse, rmse, r2, mape\n","\n","print(\"\\n=== Calculating Metrics ===\")\n","metrics_train = compute_metrics(Y_train, Y_train_pred_rf)\n","metrics_val = compute_metrics(Y_val, Y_val_pred_rf)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_rf)\n","\n","# ========== Feature Importance ==========\n","print(\"\\n=== Random Forest Feature Importance ===\")\n","importances = final_rf.feature_importances_\n","for i, importance in enumerate(importances):\n","    print(f\"Feature {i+1} (from LSTM): {importance:.4f}\")\n","\n","# ========== Results ==========\n","print(\"\\n=== Final Results ===\")\n","print(\"\\nPerformance Metrics:\")\n","print(f\"{'Dataset':<15} {'MAE':<10} {'MSE':<10} {'RMSE':<10} {'R²':<10} {'MAPE':<10}\")\n","print(f\"{'Train':<15} {metrics_train[0]:<10.4f} {metrics_train[1]:<10.4f} {metrics_train[2]:<10.4f} {metrics_train[3]:<10.4f} {metrics_train[4]:<10.2f}%\")\n","print(f\"{'Validation':<15} {metrics_val[0]:<10.4f} {metrics_val[1]:<10.4f} {metrics_val[2]:<10.4f} {metrics_val[3]:<10.4f} {metrics_val[4]:<10.2f}%\")\n","print(f\"{'Test':<15} {metrics_test[0]:<10.4f} {metrics_test[1]:<10.4f} {metrics_test[2]:<10.4f} {metrics_test[3]:<10.4f} {metrics_test[4]:<10.2f}%\")\n","\n","print(\"\\nTiming Metrics (seconds):\")\n","print(f\"{'Phase':<25} {'Time':<10}\")\n","print(f\"{'LSTM Training':<25} {timing_metrics['lstm_train']:<10.2f}\")\n","print(f\"{'LSTM Train Pred':<25} {timing_metrics['lstm_train_pred']:<10.4f}\")\n","print(f\"{'LSTM Val Pred':<25} {timing_metrics['lstm_val_pred']:<10.4f}\")\n","print(f\"{'LSTM Test Pred':<25} {timing_metrics['lstm_test_pred']:<10.4f}\")\n","print(f\"{'Random Forest Training':<25} {timing_metrics['rf_train']:<10.2f}\")\n","print(f\"{'RF Train Pred':<25} {timing_metrics['rf_train_pred']:<10.4f}\")\n","print(f\"{'RF Val Pred':<25} {timing_metrics['rf_val_pred']:<10.4f}\")\n","print(f\"{'RF Test Pred':<25} {timing_metrics['rf_test_pred']:<10.4f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lf0Kex5AIO7Z","executionInfo":{"status":"ok","timestamp":1743255628874,"user_tz":-330,"elapsed":18245,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"eba1e8bf-7b23-462d-f5c7-8dad1f3d6ca0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 Physical GPUs, 1 Logical GPUs\n","\n","=== Training LSTM Model with Best Parameters ===\n","Epoch 1/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0089 - val_loss: 0.0048\n","Epoch 2/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1075 - val_loss: 0.0061\n","Epoch 3/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0255 - val_loss: 0.0074\n","Epoch 4/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0094\n","Epoch 5/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0227 - val_loss: 0.0043\n","Epoch 6/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0125\n","Epoch 7/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0170 - val_loss: 0.0030\n","Epoch 8/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0027\n","Epoch 9/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0070\n","Epoch 10/10\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0034\n","LSTM Training Completed in 13.14 seconds\n","\n","Generating LSTM predictions...\n","\n","Preparing data for Random Forest...\n","\n","=== Training Random Forest Model ===\n","Random Forest Training Completed in 0.89 seconds\n","\n","Generating Random Forest predictions...\n","\n","=== Calculating Metrics ===\n","\n","=== Random Forest Feature Importance ===\n","Feature 1 (from LSTM): 1.0000\n","\n","=== Final Results ===\n","\n","Performance Metrics:\n","Dataset         MAE        MSE        RMSE       R²         MAPE      \n","Train           0.0025     0.0000     0.0037     0.9999     0.79      %\n","Validation      0.1410     0.0256     0.1600     -3.3534    7.90      %\n","Test            0.4095     0.1737     0.4168     -27.7854   20.19     %\n","\n","Timing Metrics (seconds):\n","Phase                     Time      \n","LSTM Training             13.14     \n","LSTM Train Pred           2.6477    \n","LSTM Val Pred             0.7843    \n","LSTM Test Pred            0.5373    \n","Random Forest Training    0.89      \n","RF Train Pred             0.0944    \n","RF Val Pred               0.0433    \n","RF Test Pred              0.0432    \n"]}]},{"cell_type":"markdown","source":["## BOHB"],"metadata":{"id":"UA4RDkuZXHto"}},{"cell_type":"code","source":["!pip install ConfigSpace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHZKQWHJeO1O","executionInfo":{"status":"ok","timestamp":1743250600128,"user_tz":-330,"elapsed":8668,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"4da04cab-d864-48f5-f8e4-69603cfbd983"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ConfigSpace\n","  Downloading configspace-1.2.1.tar.gz (130 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (2.0.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (3.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (1.14.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (10.6.0)\n","Building wheels for collected packages: ConfigSpace\n","  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ConfigSpace: filename=configspace-1.2.1-py3-none-any.whl size=115990 sha256=fa9bfc6a7426fcc65565fdeb7ed195773710ff6db091e6f4c947a3df726e7956\n","  Stored in directory: /root/.cache/pip/wheels/11/0f/36/d5027c3eeb038827889830f7efbe6a1bad8956b3eb44ab2f44\n","Successfully built ConfigSpace\n","Installing collected packages: ConfigSpace\n","Successfully installed ConfigSpace-1.2.1\n"]}]},{"cell_type":"code","source":["!pip install hpbandster"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2UHtYiTefE7","executionInfo":{"status":"ok","timestamp":1743250615945,"user_tz":-330,"elapsed":15815,"user":{"displayName":"JIYA GAYAWER (RA2211031010129)","userId":"04696136268844808803"}},"outputId":"0929c0a6-22d8-46cc-841a-6e2d4259c744"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hpbandster\n","  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Pyro4 (from hpbandster)\n","  Downloading Pyro4-4.82-py2.py3-none-any.whl.metadata (2.2 kB)\n","Collecting serpent (from hpbandster)\n","  Downloading serpent-1.41-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hpbandster) (2.0.2)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.14.1)\n","Collecting netifaces (from hpbandster)\n","  Downloading netifaces-0.11.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (3.2.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (10.6.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n","Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading serpent-1.41-py3-none-any.whl (9.6 kB)\n","Building wheels for collected packages: hpbandster, netifaces\n","  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=79986 sha256=2c2062167dcaa6dce64bf4ccf938b8e27930bfe8721c1cb7fd4c00a49e037ec0\n","  Stored in directory: /root/.cache/pip/wheels/fb/da/7d/af80a6b0a6898aaf2e1e93ab00cdf03251624e67f0641e9f0b\n","  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for netifaces: filename=netifaces-0.11.0-cp311-cp311-linux_x86_64.whl size=35193 sha256=ea7fa5c43eecf09260a29b5b7371af68f57f8293cac86d3160d2a90d5db5b405\n","  Stored in directory: /root/.cache/pip/wheels/40/85/29/648c19bbbb5f1d30e33bfb343fd7fb54296b402f7205d8e46f\n","Successfully built hpbandster netifaces\n","Installing collected packages: netifaces, serpent, Pyro4, hpbandster\n","Successfully installed Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import time\n","\n","# Check for GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define LSTM Model\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","# Function to calculate metrics\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Convert datasets to PyTorch tensors and move to GPU\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# LSTM Configurations\n","lstm_layers = [2, 3, 5]\n","hidden_dim = 64\n","output_dim = 1\n","input_dim = X_train.shape[1]\n","\n","# Dictionary to store LSTM feature representations\n","lstm_features = []\n","\n","for num_layers in lstm_layers:\n","    print(f\"Training LSTM with {num_layers} layers...\")\n","\n","    lstm_model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n","    num_epochs = 35\n","\n","    start_time = time.time()\n","    for epoch in range(num_epochs):\n","        lstm_model.train()\n","        optimizer.zero_grad()\n","        outputs = lstm_model(X_train_torch)\n","        loss = criterion(outputs, Y_train_torch)\n","        loss.backward()\n","        optimizer.step()\n","    train_time = time.time() - start_time\n","\n","    # Extract Feature Representations\n","    lstm_model.eval()\n","    with torch.no_grad():\n","        val_start = time.time()\n","        train_features = lstm_model(X_train_torch).cpu().numpy()\n","        val_features = lstm_model(X_val_torch).cpu().numpy()\n","        val_time = time.time() - val_start\n","\n","        test_start = time.time()\n","        test_features = lstm_model(X_test_torch).cpu().numpy()\n","        test_time = time.time() - test_start\n","\n","    lstm_features.append((train_features, val_features, test_features, train_time, val_time, test_time))\n","\n","# Concatenate Features from All Layers\n","final_train_features = np.hstack([feat[0] for feat in lstm_features])\n","final_val_features = np.hstack([feat[1] for feat in lstm_features])\n","final_test_features = np.hstack([feat[2] for feat in lstm_features])\n","\n","# Record Time for Each Stage\n","total_train_time = sum([feat[3] for feat in lstm_features])\n","total_val_time = sum([feat[4] for feat in lstm_features])\n","total_test_time = sum([feat[5] for feat in lstm_features])\n","\n","# Define ConfigSpace for BOHB\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"n_estimators\", 50, 500, default_value=100))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"max_depth\", 3, 15, default_value=6))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_split\", 2, 10, default_value=2))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 5, default_value=1))\n","    return cs\n","\n","# BOHB Worker for Random Forest\n","class RFWorker(Worker):\n","    def compute(self, config, budget, **kwargs):\n","        model = RandomForestRegressor(\n","            n_estimators=config[\"n_estimators\"],\n","            max_depth=config[\"max_depth\"],\n","            min_samples_split=config[\"min_samples_split\"],\n","            min_samples_leaf=config[\"min_samples_leaf\"],\n","            random_state=42\n","        )\n","        model.fit(final_train_features, Y_train)\n","        Y_val_pred = model.predict(final_val_features)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Run BOHB\n","NS = hpns.NameServer(run_id=\"lstm_rf_bohb\", host=\"127.0.0.2\", port=None)\n","NS.start()\n","\n","worker = RFWorker(nameserver=\"127.0.0.2\", run_id=\"lstm_rf_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(configspace=get_config_space(), run_id=\"lstm_rf_bohb\", nameserver=\"127.0.0.2\", min_budget=1, max_budget=3)\n","res = bohb.run(n_iterations=50)\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Train Best Random Forest Model\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","best_rf_model = RandomForestRegressor(\n","    n_estimators=best_params[\"n_estimators\"],\n","    max_depth=best_params[\"max_depth\"],\n","    min_samples_split=best_params[\"min_samples_split\"],\n","    min_samples_leaf=best_params[\"min_samples_leaf\"],\n","    random_state=42\n",")\n","\n","best_rf_model.fit(final_train_features, Y_train)\n","\n","# Predictions\n","Y_train_pred = best_rf_model.predict(final_train_features)\n","Y_val_pred = best_rf_model.predict(final_val_features)\n","Y_test_pred = best_rf_model.predict(final_test_features)\n","\n","# Calculate Metrics\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print Results\n","print(\"Train Metrics:\", train_metrics, \"Time:\", total_train_time)\n","print(\"Validation Metrics:\", val_metrics, \"Time:\", total_val_time)\n","print(\"Test Metrics:\", test_metrics, \"Time:\", total_test_time)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw8vhtlXFPUm","executionInfo":{"status":"ok","timestamp":1743255868273,"user_tz":-330,"elapsed":746122,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"e011863c-cc6f-4645-dbce-3ce01bab1232"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training LSTM with 2 layers...\n","Training LSTM with 3 layers...\n","Training LSTM with 5 layers...\n","Train Metrics: (0.0019636370108342942, 7.231082957958517e-06, 0.0026890673026085674, 0.9999586844853037, 0.6290564566595542) Time: 32.42417860031128\n","Validation Metrics: (0.13746071182242878, 0.02457433881973903, 0.15676204521420048, -3.178212588068127, 7.694290811851231) Time: 0.47695016860961914\n","Test Metrics: (0.4057919015290884, 0.17070213773759144, 0.4131611522609446, -27.285028455046948, 20.01092301865549) Time: 0.07733273506164551\n"]}]}]}