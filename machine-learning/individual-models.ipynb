{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["5ebGneEwoKEe","5d4hGeSAw953","CZwacxTnx0Wb"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Initial Code"],"metadata":{"id":"5ebGneEwoKEe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WY7I5C1zqFJt"},"outputs":[],"source":["# Importing necessary libraries for data analysis and manipulation\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# For handling warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27640,"status":"ok","timestamp":1739124140724,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"3RKq8vfwqVHB","outputId":"56c2d1ad-b6b9-4aa3-990a-cd224c64b0a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4yeLMDyqd2o"},"outputs":[],"source":["df_aapl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/stocks/AAPL.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHvcgRGPruCy"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import boxcox\n","\n","df_aapl['Close_log'] = np.log(df_aapl['Close'] + 1)\n","df_aapl['Close_sqrt'] = np.sqrt(df_aapl['Close'])\n","df_aapl['Close_boxcox'], _ = boxcox(df_aapl['Close'] + 1)\n"]},{"cell_type":"markdown","metadata":{"id":"lLz5cmQlryah"},"source":["This code calculates the skewness of the 'Close' column in the `df_aapl` DataFrame before and after applying various transformations:\n","\n","1. **Original Skewness**: Calculates the skewness of the original 'Close' data.\n","2. **Log Transformation Skewness**: Calculates the skewness of the 'Close_log' column after applying the log transformation.\n","3. **Square Root Transformation Skewness**: Calculates the skewness of the 'Close_sqrt' column after applying the square root transformation.\n","4. **Box-Cox Transformation Skewness**: Calculates the skewness of the 'Close_boxcox' column after applying the Box-Cox transformation.\n","\n","The printed results help assess how each transformation affects the distribution's symmetry and the success of skewness correction.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1739124142227,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"DIPGiQydr2K0","outputId":"3656b47a-40f2-453f-c525-bbba29164bab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Skewness: 2.5045276102319933\n","Log Transformation Skewness: 0.8535555176510308\n","Square Root Transformation Skewness: 1.6211545809555206\n","Box-Cox Transformation Skewness: 0.4352746472149233\n"]}],"source":["\n","skew_original = df_aapl['Close'].skew()\n","skew_log = df_aapl['Close_log'].skew()\n","skew_sqrt = df_aapl['Close_sqrt'].skew()\n","skew_boxcox = pd.Series(df_aapl['Close_boxcox']).skew()\n","\n","print(f\"Original Skewness: {skew_original}\")\n","print(f\"Log Transformation Skewness: {skew_log}\")\n","print(f\"Square Root Transformation Skewness: {skew_sqrt}\")\n","print(f\"Box-Cox Transformation Skewness: {skew_boxcox}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"De4W27wEr9-p"},"outputs":[],"source":["\n","df_aapl['Open_log'] = np.log(df_aapl['Open'])\n","df_aapl['High_log'] = np.log(df_aapl['High'])\n","df_aapl['Low_log'] = np.log(df_aapl['Low'])\n","df_aapl['Adj Close_log'] = np.log(df_aapl['Adj Close'])\n","df_aapl['Volume_log'] = np.log(df_aapl['Volume'])\n","\n","\n","df_aapl['Open_sqrt'] = np.sqrt(df_aapl['Open'])\n","df_aapl['High_sqrt'] = np.sqrt(df_aapl['High'])\n","df_aapl['Low_sqrt'] = np.sqrt(df_aapl['Low'])\n","df_aapl['Adj Close_sqrt'] = np.sqrt(df_aapl['Adj Close'])\n","df_aapl['Volume_sqrt'] = np.sqrt(df_aapl['Volume'])\n","\n","from scipy.stats import boxcox\n","df_aapl['Open_boxcox'], _ = boxcox(df_aapl['Open'])\n","df_aapl['High_boxcox'], _ = boxcox(df_aapl['High'])\n","df_aapl['Low_boxcox'], _ = boxcox(df_aapl['Low'])\n","df_aapl['Adj Close_boxcox'], _ = boxcox(df_aapl['Adj Close'])"]},{"cell_type":"markdown","source":["This helps compare how the transformations reduce skewness in the data, aiming for a more normal distribution."],"metadata":{"id":"2XrZQHaDAigS"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1739124142692,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"of1KONYmsC8t","outputId":"3fe40835-13b0-4c94-f486-86f4a7b2b094"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness Before Transformation:\n"," Open         2.504632\n","High         2.502208\n","Low          2.506714\n","Adj Close    2.550677\n","Volume       3.565699\n","dtype: float64\n","\n","Skewness After Transformation:\n"," Open_log            0.482872\n","High_log            0.481997\n","Low_log             0.484246\n","Adj Close_log       0.494009\n","Open_sqrt           1.620771\n","High_sqrt           1.621456\n","Low_sqrt            1.620661\n","Adj Close_sqrt      1.679402\n","Volume_sqrt         1.299776\n","Open_boxcox         0.181226\n","High_boxcox         0.179749\n","Low_boxcox          0.182882\n","Adj Close_boxcox    0.180085\n","dtype: float64\n"]}],"source":["\n","skewness_before = df_aapl[['Open', 'High', 'Low', 'Adj Close', 'Volume']].skew()\n","skewness_after = df_aapl[['Open_log', 'High_log', 'Low_log', 'Adj Close_log',\n","                          'Open_sqrt', 'High_sqrt', 'Low_sqrt', 'Adj Close_sqrt', 'Volume_sqrt',\n","                          'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox']].skew()\n","\n","print(\"Skewness Before Transformation:\\n\", skewness_before)\n","print(\"\\nSkewness After Transformation:\\n\", skewness_after)\n"]},{"cell_type":"markdown","source":["- Applied Box-Cox transformation to the 'Open', 'High', 'Low', 'Adj Close', and 'Close' columns.\n","- Recalculated skewness after the transformation to reduce skew and normalize the data for modeling."],"metadata":{"id":"zfEokf4iAmnv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1739124142936,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"s9oEP05csI66","outputId":"61f77318-79f3-4459-d816-031f2d5d6597"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness After Box-Cox Transformation:\n","Open_boxcox         0.435237\n","High_boxcox         0.433381\n","Low_boxcox          0.437331\n","Adj Close_boxcox    0.458762\n","Close_boxcox        0.435275\n","dtype: float64\n"]}],"source":["from scipy import stats\n","\n","df_aapl['Open_boxcox'], _ = stats.boxcox(df_aapl['Open'] + 1)\n","df_aapl['High_boxcox'], _ = stats.boxcox(df_aapl['High'] + 1)\n","df_aapl['Low_boxcox'], _ = stats.boxcox(df_aapl['Low'] + 1)\n","df_aapl['Adj Close_boxcox'], _ = stats.boxcox(df_aapl['Adj Close'] + 1)\n","df_aapl['Close_boxcox'], _ = stats.boxcox(df_aapl['Close'] + 1)\n","\n","skewness_after_boxcox = df_aapl[['Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox', 'Close_boxcox']].skew()\n","\n","print(\"Skewness After Box-Cox Transformation:\")\n","print(skewness_after_boxcox)\n"]},{"cell_type":"markdown","source":["Feature Selection"],"metadata":{"id":"uvZe7IzRAwHu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1739124142969,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"aczNHUI4rk8x","outputId":"6df58f24-84b5-4522-9d7c-a3ceb25b9290"},"outputs":[{"output_type":"stream","name":"stdout","text":["         Date      Open      High       Low  Adj Close     Close     Volume  \\\n","0  1980-12-12  0.128348  0.128906  0.128348   0.098943  0.128348  469033600   \n","1  1980-12-15  0.122210  0.122210  0.121652   0.093781  0.121652  175884800   \n","2  1980-12-16  0.113281  0.113281  0.112723   0.086898  0.112723  105728000   \n","3  1980-12-17  0.115513  0.116071  0.115513   0.089049  0.115513   86441600   \n","4  1980-12-18  0.118862  0.119420  0.118862   0.091630  0.118862   73449600   \n","\n","   Open_boxcox  High_boxcox  Low_boxcox  Adj Close_boxcox  Close_boxcox  \n","0     0.117689     0.118173    0.117674          0.092374      0.117689  \n","1     0.112503     0.112516    0.112016          0.087857      0.112030  \n","2     0.104886     0.104897    0.104395          0.081785      0.104407  \n","3     0.106798     0.107287    0.106786          0.083688      0.106798  \n","4     0.109657     0.110145    0.109644          0.085966      0.109657  \n"]}],"source":["\n","df_aapl_cleaned = df_aapl[['Date', 'Open', 'High', 'Low', 'Adj Close', 'Close', 'Volume',\n","                           'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox',\n","                           'Close_boxcox']]\n","\n","print(df_aapl_cleaned.head())\n"]},{"cell_type":"markdown","source":["### Train Validation Test Split\n","\n","The code splits the data into training, validation, and test sets. The features `X` and target `Y` are split as follows:\n","\n","- 70% for training (`X_train`, `Y_train`)\n","- 15% for validation (`X_val`, `Y_val`)\n","- 15% for testing (`X_test`, `Y_test`)\n","\n","The split is done using a 30% test size, followed by splitting the remaining 70% into validation and test sets without shuffling (time series data)."],"metadata":{"id":"chw5ijVT_JRM"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df_aapl_cleaned[['Open_boxcox', 'High_boxcox', 'Low_boxcox']]\n","Y = df_aapl_cleaned['Close_boxcox']\n","\n","X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, shuffle=False)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, shuffle=False)\n","\n","print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSztwxnoy8-U","executionInfo":{"status":"ok","timestamp":1739124143018,"user_tz":-330,"elapsed":47,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"633150cc-c5af-437c-ced7-a07aa2083ffa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (7736, 3), Validation set: (1658, 3), Test set: (1658, 3)\n"]}]},{"cell_type":"markdown","source":["## GPU Activation"],"metadata":{"id":"5d4hGeSAw953"}},{"cell_type":"code","source":["import torch\n","\n","# Check GPU status\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is enabled:\", torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"No GPU found, using CPU.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0d6nftTwf7T","executionInfo":{"status":"ok","timestamp":1739124143122,"user_tz":-330,"elapsed":106,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"2437d5d7-3039-4939-9a78-a9c3c507cf0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is enabled: Tesla T4\n"]}]},{"cell_type":"markdown","source":["## ANN"],"metadata":{"id":"CZwacxTnx0Wb"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Set device to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DLvHvru45mw","executionInfo":{"status":"ok","timestamp":1739124478010,"user_tz":-330,"elapsed":7,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"bdf369f8-6b63-4526-ba3c-3cdcbf11e654"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# Assuming X_train, X_val, X_test, Y_train, Y_val, Y_test are already defined\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).to(device).view(-1, 1)\n"],"metadata":{"id":"1Uygh1Zx5Y9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ANN(nn.Module):\n","    def __init__(self, input_size):\n","        super(ANN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 1)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.3)  # Dropout to prevent overfitting\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)  # Apply dropout\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)  # No activation for regression\n","        return x\n","\n","# Initialize model\n","model = ANN(input_size=X_train.shape[1]).to(device)\n"],"metadata":{"id":"gmqn2DWa5av4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.MSELoss()  # MSE for regression\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # L2 Regularization\n"],"metadata":{"id":"66iD-gag5cVo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 200\n","patience = 10  # Stop training if no improvement after 10 epochs\n","best_val_loss = float(\"inf\")\n","counter = 0\n","\n","for epoch in range(epochs):\n","    # Training\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Validation\n","    model.eval()\n","    with torch.no_grad():\n","        val_outputs = model(X_val_torch)\n","        val_loss = criterion(val_outputs, Y_val_torch)\n","\n","    # Early stopping\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        counter = 0\n","    else:\n","        counter += 1\n","        if counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n","\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}, Val Loss: {val_loss.item():.6f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LnBJs7W-5eTJ","executionInfo":{"status":"ok","timestamp":1739124507824,"user_tz":-330,"elapsed":554,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"fc711bc2-e28e-4561-85cc-36884b9fe303"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200, Loss: 0.193401, Val Loss: 1.567056\n","Epoch 2/200, Loss: 0.174322, Val Loss: 1.432983\n","Epoch 3/200, Loss: 0.154621, Val Loss: 1.306110\n","Epoch 4/200, Loss: 0.138142, Val Loss: 1.183969\n","Epoch 5/200, Loss: 0.123961, Val Loss: 1.063381\n","Epoch 6/200, Loss: 0.109427, Val Loss: 0.945019\n","Epoch 7/200, Loss: 0.099343, Val Loss: 0.827867\n","Epoch 8/200, Loss: 0.086156, Val Loss: 0.715117\n","Epoch 9/200, Loss: 0.077368, Val Loss: 0.610022\n","Epoch 10/200, Loss: 0.069780, Val Loss: 0.518160\n","Epoch 11/200, Loss: 0.062221, Val Loss: 0.434913\n","Epoch 12/200, Loss: 0.058163, Val Loss: 0.359932\n","Epoch 13/200, Loss: 0.053779, Val Loss: 0.294038\n","Epoch 14/200, Loss: 0.048779, Val Loss: 0.237188\n","Epoch 15/200, Loss: 0.047834, Val Loss: 0.189271\n","Epoch 16/200, Loss: 0.044631, Val Loss: 0.149880\n","Epoch 17/200, Loss: 0.043444, Val Loss: 0.118095\n","Epoch 18/200, Loss: 0.042534, Val Loss: 0.093086\n","Epoch 19/200, Loss: 0.040575, Val Loss: 0.074017\n","Epoch 20/200, Loss: 0.038927, Val Loss: 0.059875\n","Epoch 21/200, Loss: 0.037575, Val Loss: 0.049398\n","Epoch 22/200, Loss: 0.034873, Val Loss: 0.041789\n","Epoch 23/200, Loss: 0.033827, Val Loss: 0.036394\n","Epoch 24/200, Loss: 0.031592, Val Loss: 0.032728\n","Epoch 25/200, Loss: 0.028609, Val Loss: 0.030472\n","Epoch 26/200, Loss: 0.026275, Val Loss: 0.029143\n","Epoch 27/200, Loss: 0.023824, Val Loss: 0.028509\n","Epoch 28/200, Loss: 0.022472, Val Loss: 0.028310\n","Epoch 29/200, Loss: 0.020124, Val Loss: 0.028321\n","Epoch 30/200, Loss: 0.017994, Val Loss: 0.028528\n","Epoch 31/200, Loss: 0.017229, Val Loss: 0.028683\n","Epoch 32/200, Loss: 0.016424, Val Loss: 0.028602\n","Epoch 33/200, Loss: 0.014468, Val Loss: 0.028143\n","Epoch 34/200, Loss: 0.014029, Val Loss: 0.027216\n","Epoch 35/200, Loss: 0.013322, Val Loss: 0.025793\n","Epoch 36/200, Loss: 0.012400, Val Loss: 0.023876\n","Epoch 37/200, Loss: 0.012482, Val Loss: 0.021490\n","Epoch 38/200, Loss: 0.012355, Val Loss: 0.018704\n","Epoch 39/200, Loss: 0.011670, Val Loss: 0.015707\n","Epoch 40/200, Loss: 0.012145, Val Loss: 0.012579\n","Epoch 41/200, Loss: 0.011877, Val Loss: 0.009526\n","Epoch 42/200, Loss: 0.011424, Val Loss: 0.006703\n","Epoch 43/200, Loss: 0.011652, Val Loss: 0.004272\n","Epoch 44/200, Loss: 0.011475, Val Loss: 0.002357\n","Epoch 45/200, Loss: 0.010729, Val Loss: 0.001032\n","Epoch 46/200, Loss: 0.011201, Val Loss: 0.000254\n","Epoch 47/200, Loss: 0.010323, Val Loss: 0.000007\n","Epoch 48/200, Loss: 0.010581, Val Loss: 0.000181\n","Epoch 49/200, Loss: 0.009926, Val Loss: 0.000626\n","Epoch 50/200, Loss: 0.010387, Val Loss: 0.001201\n","Epoch 51/200, Loss: 0.010837, Val Loss: 0.001777\n","Epoch 52/200, Loss: 0.010324, Val Loss: 0.002246\n","Epoch 53/200, Loss: 0.010663, Val Loss: 0.002524\n","Epoch 54/200, Loss: 0.010319, Val Loss: 0.002605\n","Epoch 55/200, Loss: 0.010209, Val Loss: 0.002468\n","Epoch 56/200, Loss: 0.010050, Val Loss: 0.002142\n","Early stopping at epoch 57\n"]}]},{"cell_type":"code","source":["def evaluate_model(model, X, Y, set_name):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(X).cpu().numpy()\n","        Y_true = Y.cpu().numpy()\n","\n","    mae = mean_absolute_error(Y_true, predictions)\n","    mse = mean_squared_error(Y_true, predictions)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(Y_true, predictions)\n","    mape = np.mean(np.abs((Y_true - predictions) / Y_true)) * 100  # MAPE in %\n","\n","    print(f\"{set_name} Metrics: MAE={mae:.4f}, MSE={mse:.6f}, RMSE={rmse:.4f}, R²={r2:.4f}, MAPE={mape:.2f}%\")\n","\n","# Evaluate on all sets\n","evaluate_model(model, X_train_torch, Y_train_torch, \"Train\")\n","evaluate_model(model, X_val_torch, Y_val_torch, \"Validation\")\n","evaluate_model(model, X_test_torch, Y_test_torch, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7_Tp3l-5gGC","executionInfo":{"status":"ok","timestamp":1739124517753,"user_tz":-330,"elapsed":32,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"16e71807-ec35-4d51-a612-1b281141a902"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Metrics: MAE=0.0206, MSE=0.000493, RMSE=0.0222, R²=0.9972, MAPE=7.42%\n","Validation Metrics: MAE=0.0408, MSE=0.001672, RMSE=0.0409, R²=0.7157, MAPE=2.34%\n","Test Metrics: MAE=0.0442, MSE=0.001957, RMSE=0.0442, R²=0.6757, MAPE=2.19%\n"]}]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ff2EZLpo90sq","executionInfo":{"status":"ok","timestamp":1739125668575,"user_tz":-330,"elapsed":3239,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"174c74c0-9fe0-48d4-f493-3641db575fd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.0\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import optuna\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Set device to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Convert data to PyTorch tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).to(device).view(-1, 1)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","# Define the model class\n","class ANN(nn.Module):\n","    def __init__(self, input_size, hidden1, hidden2, dropout_rate):\n","        super(ANN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden1)\n","        self.fc2 = nn.Linear(hidden1, hidden2)\n","        self.fc3 = nn.Linear(hidden2, 1)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)  # No activation for regression\n","        return x\n","\n","# Define the objective function for Optuna\n","def objective(trial):\n","    # Hyperparameters to tune\n","    hidden1 = trial.suggest_int(\"hidden1\", 32, 128, step=16)\n","    hidden2 = trial.suggest_int(\"hidden2\", 16, 64, step=16)\n","    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n","    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n","    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n","\n","    # Initialize model\n","    model = ANN(X_train.shape[1], hidden1, hidden2, dropout_rate).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","    # Training loop\n","    best_val_loss = float(\"inf\")\n","    patience = 10\n","    counter = 0\n","\n","    for epoch in range(200):  # Max 200 epochs\n","        model.train()\n","        optimizer.zero_grad()\n","        outputs = model(X_train_torch)\n","        loss = criterion(outputs, Y_train_torch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Validation\n","        model.eval()\n","        with torch.no_grad():\n","            val_outputs = model(X_val_torch)\n","            val_loss = criterion(val_outputs, Y_val_torch)\n","\n","        # Early stopping\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            counter = 0\n","        else:\n","            counter += 1\n","            if counter >= patience:\n","                break\n","\n","    return best_val_loss.item()  # Optuna minimizes this\n","\n","# Run Optuna study\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)  # Run 50 trials\n","\n","# Print best parameters\n","print(\"Best Hyperparameters:\", study.best_params)\n","\n","# Train final model with best hyperparameters\n","best_params = study.best_params\n","final_model = ANN(X_train.shape[1], best_params[\"hidden1\"], best_params[\"hidden2\"], best_params[\"dropout\"]).to(device)\n","optimizer = optim.Adam(final_model.parameters(), lr=best_params[\"lr\"], weight_decay=best_params[\"weight_decay\"])\n","\n","# Train with best params\n","for epoch in range(200):\n","    final_model.train()\n","    optimizer.zero_grad()\n","    outputs = final_model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Validation\n","    final_model.eval()\n","    with torch.no_grad():\n","        val_outputs = final_model(X_val_torch)\n","        val_loss = criterion(val_outputs, Y_val_torch)\n","\n","# Evaluation function\n","def evaluate_model(model, X, Y, set_name):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(X).cpu().numpy()\n","        Y_true = Y.cpu().numpy()\n","\n","    mae = mean_absolute_error(Y_true, predictions)\n","    mse = mean_squared_error(Y_true, predictions)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(Y_true, predictions)\n","    mape = np.mean(np.abs((Y_true - predictions) / Y_true)) * 100  # MAPE in %\n","\n","    print(f\"{set_name} Metrics: MAE={mae:.4f}, MSE={mse:.6f}, RMSE={rmse:.4f}, R²={r2:.4f}, MAPE={mape:.2f}%\")\n","\n","# Evaluate on all sets\n","evaluate_model(final_model, X_train_torch, Y_train_torch, \"Train\")\n","evaluate_model(final_model, X_val_torch, Y_val_torch, \"Validation\")\n","evaluate_model(final_model, X_test_torch, Y_test_torch, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtqQMjFc51zg","executionInfo":{"status":"ok","timestamp":1739125690747,"user_tz":-330,"elapsed":16550,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"883b8244-2098-411d-aec4-e4afcd1d08c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-02-09 18:27:56,312] A new study created in memory with name: no-name-48266d59-3bed-406d-bcd3-02a79785f701\n"]},{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-09 18:27:56,618] Trial 0 finished with value: 0.054957929998636246 and parameters: {'hidden1': 64, 'hidden2': 16, 'dropout': 0.2, 'lr': 0.0006240698846171853, 'weight_decay': 1.3840009879062286e-06}. Best is trial 0 with value: 0.054957929998636246.\n","[I 2025-02-09 18:27:57,437] Trial 1 finished with value: 0.4436366558074951 and parameters: {'hidden1': 48, 'hidden2': 16, 'dropout': 0.4, 'lr': 0.00012158855295734993, 'weight_decay': 0.00034447228971052127}. Best is trial 0 with value: 0.054957929998636246.\n","[I 2025-02-09 18:27:57,541] Trial 2 finished with value: 1.435631656931946e-05 and parameters: {'hidden1': 32, 'hidden2': 64, 'dropout': 0.30000000000000004, 'lr': 0.004215798965438718, 'weight_decay': 1.3604481381637065e-05}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:27:57,879] Trial 3 finished with value: 0.0006602357607334852 and parameters: {'hidden1': 64, 'hidden2': 32, 'dropout': 0.1, 'lr': 0.00046195114171576157, 'weight_decay': 0.00030945186338763686}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:27:58,303] Trial 4 finished with value: 3.638794441940263e-05 and parameters: {'hidden1': 96, 'hidden2': 32, 'dropout': 0.2, 'lr': 0.00020393969968589962, 'weight_decay': 2.007868004458797e-05}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:27:58,552] Trial 5 finished with value: 0.036372922360897064 and parameters: {'hidden1': 48, 'hidden2': 16, 'dropout': 0.30000000000000004, 'lr': 0.0007531850405425415, 'weight_decay': 0.0007356652434575785}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:27:59,336] Trial 6 finished with value: 0.12390676140785217 and parameters: {'hidden1': 96, 'hidden2': 48, 'dropout': 0.5, 'lr': 0.00010486817351718723, 'weight_decay': 1.5073747358418763e-06}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:27:59,831] Trial 7 finished with value: 0.003826054511591792 and parameters: {'hidden1': 32, 'hidden2': 32, 'dropout': 0.2, 'lr': 0.0004989549114662245, 'weight_decay': 1.3207233144503887e-05}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:00,567] Trial 8 finished with value: 0.0032345119398087263 and parameters: {'hidden1': 48, 'hidden2': 64, 'dropout': 0.30000000000000004, 'lr': 0.00016357801319637823, 'weight_decay': 9.140702415008559e-06}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:00,660] Trial 9 finished with value: 0.0006251106387935579 and parameters: {'hidden1': 32, 'hidden2': 16, 'dropout': 0.4, 'lr': 0.004819828397837552, 'weight_decay': 7.696947635507628e-05}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:00,761] Trial 10 finished with value: 0.00017808142001740634 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.5, 'lr': 0.005561197282739453, 'weight_decay': 6.150590088214251e-05}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:00,898] Trial 11 finished with value: 0.0004474316956475377 and parameters: {'hidden1': 96, 'hidden2': 48, 'dropout': 0.2, 'lr': 0.0021548577616304944, 'weight_decay': 1.1684301988235994e-05}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:00,995] Trial 12 finished with value: 0.00030777425854466856 and parameters: {'hidden1': 112, 'hidden2': 48, 'dropout': 0.1, 'lr': 0.0027331418427062088, 'weight_decay': 4.934717198595695e-06}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:01,124] Trial 13 finished with value: 0.04702869430184364 and parameters: {'hidden1': 80, 'hidden2': 32, 'dropout': 0.30000000000000004, 'lr': 0.002030971256366324, 'weight_decay': 3.894697611374084e-05}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:01,360] Trial 14 finished with value: 0.0002043886051978916 and parameters: {'hidden1': 96, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.009374791791774646, 'weight_decay': 4.49542445801253e-06}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:01,729] Trial 15 finished with value: 0.0017886728746816516 and parameters: {'hidden1': 128, 'hidden2': 48, 'dropout': 0.4, 'lr': 0.00026049126474337925, 'weight_decay': 2.3058430602783124e-05}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:01,892] Trial 16 finished with value: 0.00947551243007183 and parameters: {'hidden1': 80, 'hidden2': 32, 'dropout': 0.1, 'lr': 0.0011740660969366268, 'weight_decay': 0.0001352843348032865}. Best is trial 2 with value: 1.435631656931946e-05.\n","[I 2025-02-09 18:28:02,279] Trial 17 finished with value: 6.1057130551489536e-06 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.00028198480240221514, 'weight_decay': 2.2066170170177573e-05}. Best is trial 17 with value: 6.1057130551489536e-06.\n","[I 2025-02-09 18:28:02,854] Trial 18 finished with value: 1.2982806765649002e-05 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.30000000000000004, 'lr': 0.00032472559322911963, 'weight_decay': 3.851470852157205e-06}. Best is trial 17 with value: 6.1057130551489536e-06.\n","[I 2025-02-09 18:28:03,286] Trial 19 finished with value: 2.78290990536334e-05 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.4, 'lr': 0.0003205145158521549, 'weight_decay': 3.2245687169052076e-06}. Best is trial 17 with value: 6.1057130551489536e-06.\n","[I 2025-02-09 18:28:03,392] Trial 20 finished with value: 0.007660109084099531 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.0010892468200360602, 'weight_decay': 2.503327878179542e-06}. Best is trial 17 with value: 6.1057130551489536e-06.\n","[I 2025-02-09 18:28:03,620] Trial 21 finished with value: 3.124032446066849e-05 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.30000000000000004, 'lr': 0.00035733661519514123, 'weight_decay': 7.324291364761613e-06}. Best is trial 17 with value: 6.1057130551489536e-06.\n","[I 2025-02-09 18:28:04,224] Trial 22 finished with value: 9.010088979266584e-05 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.30000000000000004, 'lr': 0.00019424749362779528, 'weight_decay': 3.2389369184756555e-05}. Best is trial 17 with value: 6.1057130551489536e-06.\n","[I 2025-02-09 18:28:04,456] Trial 23 finished with value: 1.3017533092352096e-05 and parameters: {'hidden1': 64, 'hidden2': 48, 'dropout': 0.30000000000000004, 'lr': 0.0013609346277366635, 'weight_decay': 1.5304242580221916e-05}. Best is trial 17 with value: 6.1057130551489536e-06.\n","[I 2025-02-09 18:28:04,693] Trial 24 finished with value: 0.0067839003168046474 and parameters: {'hidden1': 64, 'hidden2': 48, 'dropout': 0.4, 'lr': 0.0014623447957014864, 'weight_decay': 5.358416929333546e-06}. Best is trial 17 with value: 6.1057130551489536e-06.\n","[I 2025-02-09 18:28:05,059] Trial 25 finished with value: 5.621714990411419e-06 and parameters: {'hidden1': 80, 'hidden2': 48, 'dropout': 0.2, 'lr': 0.000715574339427951, 'weight_decay': 1.0030111167606968e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:05,354] Trial 26 finished with value: 8.972042269306257e-05 and parameters: {'hidden1': 80, 'hidden2': 48, 'dropout': 0.1, 'lr': 0.0006604019278642186, 'weight_decay': 1.11422368546402e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:05,864] Trial 27 finished with value: 1.895048080768902e-05 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.0003664437296428945, 'weight_decay': 2.174021491345241e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:06,106] Trial 28 finished with value: 3.302952609374188e-05 and parameters: {'hidden1': 96, 'hidden2': 48, 'dropout': 0.2, 'lr': 0.0008193152924757007, 'weight_decay': 1.9325257318416615e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:06,335] Trial 29 finished with value: 5.963482180959545e-05 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.00048546562870394587, 'weight_decay': 1.0359759094546315e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:06,565] Trial 30 finished with value: 1.182140658784192e-05 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.1, 'lr': 0.00024076645137341966, 'weight_decay': 3.051185180765379e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:06,752] Trial 31 finished with value: 1.638012872717809e-05 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.1, 'lr': 0.00024121855478562276, 'weight_decay': 3.58205743502586e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:07,071] Trial 32 finished with value: 1.8460552382748574e-05 and parameters: {'hidden1': 96, 'hidden2': 64, 'dropout': 0.1, 'lr': 0.00014694823930879082, 'weight_decay': 1.70587876591568e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:07,302] Trial 33 finished with value: 4.220288974465802e-05 and parameters: {'hidden1': 80, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.0005524653028672884, 'weight_decay': 2.7787938439856615e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:07,515] Trial 34 finished with value: 7.36357833375223e-06 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.1, 'lr': 0.0002914768430141482, 'weight_decay': 6.463659293468423e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:08,001] Trial 35 finished with value: 0.0015377679374068975 and parameters: {'hidden1': 80, 'hidden2': 48, 'dropout': 0.1, 'lr': 0.00013066927938355964, 'weight_decay': 7.538487810865914e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:08,277] Trial 36 finished with value: 2.75675774901174e-05 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.1, 'lr': 0.00021832209177567028, 'weight_decay': 5.851491128371641e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:08,539] Trial 37 finished with value: 1.6254520232905634e-05 and parameters: {'hidden1': 64, 'hidden2': 48, 'dropout': 0.1, 'lr': 0.0004058286534941209, 'weight_decay': 2.0885123405052017e-05}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:09,002] Trial 38 finished with value: 1.4905428542988375e-05 and parameters: {'hidden1': 96, 'hidden2': 64, 'dropout': 0.1, 'lr': 0.0002825159520587664, 'weight_decay': 1.3470272770366472e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:09,115] Trial 39 finished with value: 9.332565241493285e-05 and parameters: {'hidden1': 112, 'hidden2': 32, 'dropout': 0.2, 'lr': 0.0008470335695646413, 'weight_decay': 4.601015816085156e-05}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:09,636] Trial 40 finished with value: 0.3860442638397217 and parameters: {'hidden1': 96, 'hidden2': 16, 'dropout': 0.1, 'lr': 0.00010050971372563003, 'weight_decay': 9.42144298480605e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:10,164] Trial 41 finished with value: 0.00034454467822797596 and parameters: {'hidden1': 112, 'hidden2': 64, 'dropout': 0.30000000000000004, 'lr': 0.0001794366454211271, 'weight_decay': 3.5831535006358085e-06}. Best is trial 25 with value: 5.621714990411419e-06.\n","[I 2025-02-09 18:28:10,425] Trial 42 finished with value: 4.707344942289637e-06 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.00030251631116183893, 'weight_decay': 1.6486940906465844e-06}. Best is trial 42 with value: 4.707344942289637e-06.\n","[I 2025-02-09 18:28:10,587] Trial 43 finished with value: 8.751079803914763e-06 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.0005987848103975714, 'weight_decay': 1.4853732377980838e-06}. Best is trial 42 with value: 4.707344942289637e-06.\n","[I 2025-02-09 18:28:10,689] Trial 44 finished with value: 0.0004952502204105258 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.0006512504195907125, 'weight_decay': 1.4690622945425973e-06}. Best is trial 42 with value: 4.707344942289637e-06.\n","[I 2025-02-09 18:28:10,816] Trial 45 finished with value: 8.916110346035566e-06 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.0004158775655662861, 'weight_decay': 9.39934214079506e-05}. Best is trial 42 with value: 4.707344942289637e-06.\n","[I 2025-02-09 18:28:10,970] Trial 46 finished with value: 3.2661966542946175e-05 and parameters: {'hidden1': 128, 'hidden2': 48, 'dropout': 0.2, 'lr': 0.0004677210568892666, 'weight_decay': 0.0007187194944660832}. Best is trial 42 with value: 4.707344942289637e-06.\n","[I 2025-02-09 18:28:11,071] Trial 47 finished with value: 5.303676152834669e-05 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.0005865946053708468, 'weight_decay': 1.027134479836249e-06}. Best is trial 42 with value: 4.707344942289637e-06.\n","[I 2025-02-09 18:28:11,167] Trial 48 finished with value: 0.006208859384059906 and parameters: {'hidden1': 128, 'hidden2': 48, 'dropout': 0.2, 'lr': 0.0008769080643408799, 'weight_decay': 1.8630507528164092e-06}. Best is trial 42 with value: 4.707344942289637e-06.\n","[I 2025-02-09 18:28:11,366] Trial 49 finished with value: 1.0009065590566024e-05 and parameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.0002818501175297827, 'weight_decay': 1.5229072449927155e-05}. Best is trial 42 with value: 4.707344942289637e-06.\n"]},{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'hidden1': 128, 'hidden2': 64, 'dropout': 0.2, 'lr': 0.00030251631116183893, 'weight_decay': 1.6486940906465844e-06}\n","Train Metrics: MAE=0.0110, MSE=0.000155, RMSE=0.0124, R²=0.9991, MAPE=4.56%\n","Validation Metrics: MAE=0.0108, MSE=0.000123, RMSE=0.0111, R²=0.9791, MAPE=0.62%\n","Test Metrics: MAE=0.0127, MSE=0.000163, RMSE=0.0128, R²=0.9730, MAPE=0.63%\n"]}]},{"cell_type":"markdown","source":["## DNN"],"metadata":{"id":"GmAaEcTQA4gD"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Set device to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Convert Data to Tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","\n","# Define Deep Neural Network Model\n","class DNN(nn.Module):\n","    def __init__(self, input_size):\n","        super(DNN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 128)  # First hidden layer\n","        self.fc2 = nn.Linear(128, 64)  # Second hidden layer\n","        self.fc3 = nn.Linear(64, 32)  # Third hidden layer\n","        self.fc4 = nn.Linear(32, 1)  # Output layer\n","\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.2)  # Regularization\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc3(x))\n","        x = self.fc4(x)  # No activation for regression\n","        return x\n","\n","\n","# Initialize Model\n","model = DNN(input_size=X_train.shape[1]).to(device)\n","\n","# Loss Function & Optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n","\n","# Training Loop\n","epochs = 200\n","patience = 10  # Early stopping patience\n","best_val_loss = float(\"inf\")\n","counter = 0\n","\n","for epoch in range(epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","    loss.backward()\n","    optimizer.step()\n","\n","    model.eval()\n","    with torch.no_grad():\n","        val_outputs = model(X_val_torch)\n","        val_loss = criterion(val_outputs, Y_val_torch)\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        counter = 0\n","    else:\n","        counter += 1\n","        if counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n","\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}, Val Loss: {val_loss.item():.6f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mBXRlu1ABA24","executionInfo":{"status":"ok","timestamp":1739126478434,"user_tz":-330,"elapsed":105,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"deed4fa5-34f9-4eed-df8d-bdb2a3ea9630"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Epoch 1/200, Loss: 0.552473, Val Loss: 3.336216\n","Epoch 2/200, Loss: 0.503372, Val Loss: 3.180955\n","Epoch 3/200, Loss: 0.463147, Val Loss: 3.012921\n","Epoch 4/200, Loss: 0.427143, Val Loss: 2.883939\n","Epoch 5/200, Loss: 0.399188, Val Loss: 2.767354\n","Epoch 6/200, Loss: 0.372178, Val Loss: 2.633403\n","Epoch 7/200, Loss: 0.349387, Val Loss: 2.489299\n","Epoch 8/200, Loss: 0.324809, Val Loss: 2.341400\n","Epoch 9/200, Loss: 0.300863, Val Loss: 2.184827\n","Epoch 10/200, Loss: 0.275835, Val Loss: 2.028053\n","Epoch 11/200, Loss: 0.252260, Val Loss: 1.867168\n","Epoch 12/200, Loss: 0.226817, Val Loss: 1.707970\n","Epoch 13/200, Loss: 0.203228, Val Loss: 1.544718\n","Epoch 14/200, Loss: 0.178215, Val Loss: 1.378437\n","Epoch 15/200, Loss: 0.154886, Val Loss: 1.203386\n","Epoch 16/200, Loss: 0.131977, Val Loss: 1.029333\n","Epoch 17/200, Loss: 0.109680, Val Loss: 0.859390\n","Epoch 18/200, Loss: 0.092941, Val Loss: 0.696841\n","Epoch 19/200, Loss: 0.074885, Val Loss: 0.544018\n","Epoch 20/200, Loss: 0.062107, Val Loss: 0.400039\n","Epoch 21/200, Loss: 0.052979, Val Loss: 0.275699\n","Epoch 22/200, Loss: 0.047490, Val Loss: 0.175251\n","Epoch 23/200, Loss: 0.046555, Val Loss: 0.100652\n","Epoch 24/200, Loss: 0.047847, Val Loss: 0.050867\n","Epoch 25/200, Loss: 0.050793, Val Loss: 0.022147\n","Epoch 26/200, Loss: 0.054883, Val Loss: 0.008253\n","Epoch 27/200, Loss: 0.057349, Val Loss: 0.002792\n","Epoch 28/200, Loss: 0.057332, Val Loss: 0.001128\n","Epoch 29/200, Loss: 0.055274, Val Loss: 0.000938\n","Epoch 30/200, Loss: 0.052742, Val Loss: 0.001727\n","Epoch 31/200, Loss: 0.046968, Val Loss: 0.004025\n","Epoch 32/200, Loss: 0.040449, Val Loss: 0.008622\n","Epoch 33/200, Loss: 0.035135, Val Loss: 0.015974\n","Epoch 34/200, Loss: 0.029555, Val Loss: 0.026070\n","Epoch 35/200, Loss: 0.025975, Val Loss: 0.038432\n","Epoch 36/200, Loss: 0.022395, Val Loss: 0.051995\n","Epoch 37/200, Loss: 0.020580, Val Loss: 0.065509\n","Epoch 38/200, Loss: 0.019375, Val Loss: 0.077712\n","Early stopping at epoch 39\n"]}]},{"cell_type":"code","source":["# Function to Evaluate Model\n","def evaluate_model(model, X, Y, set_name):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(X).cpu().numpy()\n","        Y_true = Y.cpu().numpy()\n","\n","    mae = mean_absolute_error(Y_true, predictions)\n","    mse = mean_squared_error(Y_true, predictions)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(Y_true, predictions)\n","    mape = np.mean(np.abs((Y_true - predictions) / Y_true)) * 100  # MAPE in %\n","\n","    print(f\"{set_name} Metrics: MAE={mae:.4f}, MSE={mse:.6f}, RMSE={rmse:.4f}, R²={r2:.4f}, MAPE={mape:.2f}%\")\n","\n","# Evaluate on Train, Validation, and Test sets\n","evaluate_model(model, X_train_torch, Y_train_torch, \"Train\")\n","evaluate_model(model, X_val_torch, Y_val_torch, \"Validation\")\n","evaluate_model(model, X_test_torch, Y_test_torch, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFFupmWcBBVW","executionInfo":{"status":"ok","timestamp":1739126487707,"user_tz":-330,"elapsed":17,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"16845dee-5782-4f07-8768-da5fa96003e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Metrics: MAE=0.0867, MSE=0.012322, RMSE=0.1110, R²=0.9296, MAPE=36.21%\n","Validation Metrics: MAE=0.2946, MSE=0.086972, RMSE=0.2949, R²=-13.7872, MAPE=16.87%\n","Test Metrics: MAE=0.3399, MSE=0.115678, RMSE=0.3401, R²=-18.1677, MAPE=16.86%\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import optuna\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Convert data to tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","\n","# Define DNN model with variable layers\n","class DNN(nn.Module):\n","    def __init__(self, input_size, hidden_layers, hidden_units, dropout_rate):\n","        super(DNN, self).__init__()\n","        layers = []\n","\n","        # Input Layer\n","        layers.append(nn.Linear(input_size, hidden_units))\n","        layers.append(nn.ReLU())\n","        layers.append(nn.Dropout(dropout_rate))\n","\n","        # Hidden Layers\n","        for _ in range(hidden_layers - 1):\n","            layers.append(nn.Linear(hidden_units, hidden_units))\n","            layers.append(nn.ReLU())\n","            layers.append(nn.Dropout(dropout_rate))\n","\n","        # Output Layer\n","        layers.append(nn.Linear(hidden_units, 1))\n","\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","# Define the Optuna optimization function\n","def objective(trial):\n","    hidden_layers = trial.suggest_int(\"hidden_layers\", 3, 6)  # Number of hidden layers\n","    hidden_units = trial.suggest_int(\"hidden_units\", 64, 256)  # Neurons per layer\n","    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)  # Dropout\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)  # Learning rate\n","    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)  # L2 regularization\n","\n","    model = DNN(input_size=X_train.shape[1], hidden_layers=hidden_layers, hidden_units=hidden_units, dropout_rate=dropout_rate).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","    epochs = 100\n","    for epoch in range(epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        outputs = model(X_train_torch)\n","        loss = criterion(outputs, Y_train_torch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Validation Loss\n","        model.eval()\n","        with torch.no_grad():\n","            val_outputs = model(X_val_torch)\n","            val_loss = criterion(val_outputs, Y_val_torch)\n","\n","    return val_loss.item()\n","\n","\n","# Run Optuna optimization\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=30)\n","\n","# Get best hyperparameters\n","best_params = study.best_params\n","print(\"Best Hyperparameters:\", best_params)\n","\n","\n","# Train the best model\n","best_model = DNN(\n","    input_size=X_train.shape[1],\n","    hidden_layers=best_params[\"hidden_layers\"],\n","    hidden_units=best_params[\"hidden_units\"],\n","    dropout_rate=best_params[\"dropout_rate\"]\n",").to(device)\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(best_model.parameters(), lr=best_params[\"lr\"], weight_decay=best_params[\"weight_decay\"])\n","\n","epochs = 200\n","for epoch in range(epochs):\n","    best_model.train()\n","    optimizer.zero_grad()\n","    outputs = best_model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","    loss.backward()\n","    optimizer.step()\n","\n","\n","# Function to evaluate model\n","def evaluate_model(model, X, Y, set_name):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(X).cpu().numpy()\n","        Y_true = Y.cpu().numpy()\n","\n","    mae = mean_absolute_error(Y_true, predictions)\n","    mse = mean_squared_error(Y_true, predictions)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(Y_true, predictions)\n","    mape = np.mean(np.abs((Y_true - predictions) / Y_true)) * 100\n","\n","    print(f\"{set_name} Metrics: MAE={mae:.4f}, MSE={mse:.6f}, RMSE={rmse:.4f}, R²={r2:.4f}, MAPE={mape:.2f}%\")\n","\n","\n","# Evaluate model on train, validation, and test sets\n","evaluate_model(best_model, X_train_torch, Y_train_torch, \"Train\")\n","evaluate_model(best_model, X_val_torch, Y_val_torch, \"Validation\")\n","evaluate_model(best_model, X_test_torch, Y_test_torch, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0f9KLYr7BDm4","executionInfo":{"status":"ok","timestamp":1739127018664,"user_tz":-330,"elapsed":12744,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"a635fc0c-d1d5-45af-bc1f-24a112a447cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-02-09 18:50:06,802] A new study created in memory with name: no-name-d1881fe6-ce52-4e40-bf00-52b20042325b\n"]},{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-09 18:50:07,343] Trial 0 finished with value: 0.0004791483806911856 and parameters: {'hidden_layers': 3, 'hidden_units': 172, 'dropout_rate': 0.11968700455527817, 'lr': 0.004115761476855755, 'weight_decay': 0.0009031311184265404}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:07,834] Trial 1 finished with value: 0.21277083456516266 and parameters: {'hidden_layers': 3, 'hidden_units': 134, 'dropout_rate': 0.4351985972833001, 'lr': 0.0016581273967353502, 'weight_decay': 1.583172324321955e-05}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:08,558] Trial 2 finished with value: 0.028164507821202278 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.2076410698400221, 'lr': 0.0005208788093962377, 'weight_decay': 1.2171625953605177e-06}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:09,295] Trial 3 finished with value: 2.530266284942627 and parameters: {'hidden_layers': 4, 'hidden_units': 174, 'dropout_rate': 0.17720717931388294, 'lr': 1.44331167219928e-05, 'weight_decay': 0.00023728521989831717}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:10,099] Trial 4 finished with value: 0.5219963192939758 and parameters: {'hidden_layers': 5, 'hidden_units': 96, 'dropout_rate': 0.4079018326510089, 'lr': 0.001037213350125949, 'weight_decay': 7.686689101574347e-05}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:10,749] Trial 5 finished with value: 0.4449886381626129 and parameters: {'hidden_layers': 4, 'hidden_units': 206, 'dropout_rate': 0.46340097180813655, 'lr': 0.0007784024019610991, 'weight_decay': 8.151918841495405e-06}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:11,137] Trial 6 finished with value: 0.5335968136787415 and parameters: {'hidden_layers': 4, 'hidden_units': 204, 'dropout_rate': 0.46120540983501224, 'lr': 0.0005151915418527327, 'weight_decay': 1.8373121340572235e-05}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:11,870] Trial 7 finished with value: 0.06374997645616531 and parameters: {'hidden_layers': 6, 'hidden_units': 255, 'dropout_rate': 0.3406858113145258, 'lr': 7.16025801422047e-05, 'weight_decay': 1.57417078852429e-06}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:12,142] Trial 8 finished with value: 0.27351638674736023 and parameters: {'hidden_layers': 3, 'hidden_units': 206, 'dropout_rate': 0.4384185994755181, 'lr': 0.0011127771885740955, 'weight_decay': 4.639229701986009e-06}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:12,380] Trial 9 finished with value: 0.03371390700340271 and parameters: {'hidden_layers': 3, 'hidden_units': 95, 'dropout_rate': 0.3631033975836072, 'lr': 0.0009635355612885996, 'weight_decay': 1.1403962369173367e-06}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:12,766] Trial 10 finished with value: 0.0028071794658899307 and parameters: {'hidden_layers': 6, 'hidden_units': 140, 'dropout_rate': 0.10031921619219603, 'lr': 0.00825630215371276, 'weight_decay': 0.0006991165181532352}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:13,160] Trial 11 finished with value: 0.004217490553855896 and parameters: {'hidden_layers': 6, 'hidden_units': 141, 'dropout_rate': 0.1030886343850464, 'lr': 0.009692188667613087, 'weight_decay': 0.0008848661092444424}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:13,488] Trial 12 finished with value: 0.001611043931916356 and parameters: {'hidden_layers': 5, 'hidden_units': 64, 'dropout_rate': 0.10926602952928181, 'lr': 0.007775171729447037, 'weight_decay': 0.0008101599188210175}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:13,815] Trial 13 finished with value: 0.11275967210531235 and parameters: {'hidden_layers': 5, 'hidden_units': 76, 'dropout_rate': 0.233684747809546, 'lr': 0.0034414351858418437, 'weight_decay': 0.0001776137216407796}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:14,227] Trial 14 finished with value: 0.005861436482518911 and parameters: {'hidden_layers': 5, 'hidden_units': 181, 'dropout_rate': 0.15206684492690867, 'lr': 0.00015996007933869675, 'weight_decay': 0.00034594289225692255}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:14,559] Trial 15 finished with value: 0.24193747341632843 and parameters: {'hidden_layers': 5, 'hidden_units': 112, 'dropout_rate': 0.25007634074580437, 'lr': 0.0024188805664781157, 'weight_decay': 8.308240485681458e-05}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:14,818] Trial 16 finished with value: 0.09856383502483368 and parameters: {'hidden_layers': 3, 'hidden_units': 67, 'dropout_rate': 0.2859870551017287, 'lr': 0.003207404415043554, 'weight_decay': 0.0004309771934865395}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:15,122] Trial 17 finished with value: 0.0017983559519052505 and parameters: {'hidden_layers': 4, 'hidden_units': 163, 'dropout_rate': 0.1492782153761634, 'lr': 0.004600640243386976, 'weight_decay': 0.00010127185822144641}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:15,667] Trial 18 finished with value: 0.0019725454039871693 and parameters: {'hidden_layers': 5, 'hidden_units': 232, 'dropout_rate': 0.14103066450813892, 'lr': 0.00020252011627422425, 'weight_decay': 0.0009643825166301654}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:16,041] Trial 19 finished with value: 1.4766017198562622 and parameters: {'hidden_layers': 6, 'hidden_units': 118, 'dropout_rate': 0.2019451340762351, 'lr': 4.715370442813842e-05, 'weight_decay': 2.9521027199445367e-05}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:16,299] Trial 20 finished with value: 0.008509262464940548 and parameters: {'hidden_layers': 3, 'hidden_units': 189, 'dropout_rate': 0.27620859741952714, 'lr': 0.006087990448269421, 'weight_decay': 0.0001475722224458144}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:16,608] Trial 21 finished with value: 0.010699374601244926 and parameters: {'hidden_layers': 4, 'hidden_units': 165, 'dropout_rate': 0.13681081624352837, 'lr': 0.004906956474741605, 'weight_decay': 8.759718581353795e-05}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:16,914] Trial 22 finished with value: 0.006617408245801926 and parameters: {'hidden_layers': 4, 'hidden_units': 154, 'dropout_rate': 0.16328639503258113, 'lr': 0.0024330156933837074, 'weight_decay': 0.00035415249526538946}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:17,293] Trial 23 finished with value: 0.013582048006355762 and parameters: {'hidden_layers': 5, 'hidden_units': 155, 'dropout_rate': 0.12611454803933725, 'lr': 0.004790373673164064, 'weight_decay': 0.0005883308920392326}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:17,566] Trial 24 finished with value: 0.004952426068484783 and parameters: {'hidden_layers': 3, 'hidden_units': 188, 'dropout_rate': 0.18785594948845244, 'lr': 0.0017979674801387282, 'weight_decay': 4.839110207647188e-05}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:17,857] Trial 25 finished with value: 0.008859027177095413 and parameters: {'hidden_layers': 4, 'hidden_units': 123, 'dropout_rate': 0.23050260106820963, 'lr': 0.005823571924312419, 'weight_decay': 0.0002676006910604719}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:18,397] Trial 26 finished with value: 0.05356501042842865 and parameters: {'hidden_layers': 5, 'hidden_units': 229, 'dropout_rate': 0.10917128374986054, 'lr': 0.009205505497423426, 'weight_decay': 0.00012119308970054665}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:18,719] Trial 27 finished with value: 0.0078083304688334465 and parameters: {'hidden_layers': 4, 'hidden_units': 164, 'dropout_rate': 0.16424165720921044, 'lr': 0.003787564630203207, 'weight_decay': 0.0006136952983668407}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:18,967] Trial 28 finished with value: 0.08540806174278259 and parameters: {'hidden_layers': 3, 'hidden_units': 96, 'dropout_rate': 0.3204228538587013, 'lr': 0.0019292947914698612, 'weight_decay': 0.00049092014556386}. Best is trial 0 with value: 0.0004791483806911856.\n","[I 2025-02-09 18:50:19,227] Trial 29 finished with value: 0.0007782432367093861 and parameters: {'hidden_layers': 3, 'hidden_units': 131, 'dropout_rate': 0.13045380942531368, 'lr': 0.0014144583554350752, 'weight_decay': 3.995529907245799e-05}. Best is trial 0 with value: 0.0004791483806911856.\n"]},{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'hidden_layers': 3, 'hidden_units': 172, 'dropout_rate': 0.11968700455527817, 'lr': 0.004115761476855755, 'weight_decay': 0.0009031311184265404}\n","Train Metrics: MAE=0.0147, MSE=0.000329, RMSE=0.0181, R²=0.9981, MAPE=4.52%\n","Validation Metrics: MAE=0.0647, MSE=0.004235, RMSE=0.0651, R²=0.2799, MAPE=3.69%\n","Test Metrics: MAE=0.0888, MSE=0.007929, RMSE=0.0890, R²=-0.3138, MAPE=4.40%\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import optuna\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Convert data to PyTorch tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).to(device).view(-1, 1)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).to(device).view(-1, 1)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).to(device).view(-1, 1)\n","\n","# Define DNN model with batch normalization\n","class DNN(nn.Module):\n","    def __init__(self, input_size, hidden_layers, hidden_units, dropout_rate):\n","        super(DNN, self).__init__()\n","        self.layers = nn.ModuleList()\n","        self.layers.append(nn.Linear(input_size, hidden_units))\n","        self.layers.append(nn.BatchNorm1d(hidden_units))\n","        self.layers.append(nn.ReLU())\n","        self.layers.append(nn.Dropout(dropout_rate))\n","\n","        for _ in range(hidden_layers - 1):\n","            self.layers.append(nn.Linear(hidden_units, hidden_units))\n","            self.layers.append(nn.BatchNorm1d(hidden_units))\n","            self.layers.append(nn.ReLU())\n","            self.layers.append(nn.Dropout(dropout_rate))\n","\n","        self.layers.append(nn.Linear(hidden_units, 1))\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","# Define function to train and evaluate model\n","def objective(trial):\n","    hidden_layers = trial.suggest_int(\"hidden_layers\", 2, 5)\n","    hidden_units = trial.suggest_int(\"hidden_units\", 100, 150)\n","    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.4)\n","    lr = trial.suggest_float(\"lr\", 0.0005, 0.0015, log=True)\n","    weight_decay = trial.suggest_float(\"weight_decay\", 0.001, 0.01, log=True)\n","\n","    model = DNN(X_train.shape[1], hidden_layers, hidden_units, dropout_rate).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n","\n","    best_val_loss = float(\"inf\")\n","    patience = 10\n","    counter = 0\n","\n","    for epoch in range(200):\n","        model.train()\n","        optimizer.zero_grad()\n","        outputs = model(X_train_torch)\n","        loss = criterion(outputs, Y_train_torch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        model.eval()\n","        with torch.no_grad():\n","            val_outputs = model(X_val_torch)\n","            val_loss = criterion(val_outputs, Y_val_torch)\n","\n","        scheduler.step(val_loss)\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            counter = 0\n","        else:\n","            counter += 1\n","            if counter >= patience:\n","                break\n","\n","    return best_val_loss.item()\n","\n","# Run Optuna optimization\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=30)\n","\n","# Get best parameters\n","best_params = study.best_params\n","print(\"Best Hyperparameters:\", best_params)\n","\n","# Train best model\n","best_model = DNN(X_train.shape[1], best_params['hidden_layers'], best_params['hidden_units'], best_params['dropout_rate']).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(best_model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n","\n","for epoch in range(200):\n","    best_model.train()\n","    optimizer.zero_grad()\n","    outputs = best_model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","    loss.backward()\n","    optimizer.step()\n","\n","# Evaluate function\n","def evaluate_model(model, X, Y, set_name):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(X).cpu().numpy()\n","        Y_true = Y.cpu().numpy()\n","\n","    mae = mean_absolute_error(Y_true, predictions)\n","    mse = mean_squared_error(Y_true, predictions)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(Y_true, predictions)\n","    mape = np.mean(np.abs((Y_true - predictions) / Y_true)) * 100\n","\n","    print(f\"{set_name} Metrics: MAE={mae:.4f}, MSE={mse:.6f}, RMSE={rmse:.4f}, R²={r2:.4f}, MAPE={mape:.2f}%\")\n","\n","# Evaluate model\n","evaluate_model(best_model, X_train_torch, Y_train_torch, \"Train\")\n","evaluate_model(best_model, X_val_torch, Y_val_torch, \"Validation\")\n","evaluate_model(best_model, X_test_torch, Y_test_torch, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdXhmy18CzVB","executionInfo":{"status":"ok","timestamp":1739127207888,"user_tz":-330,"elapsed":11286,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"504ca9a0-597b-4cf4-c160-27735267d0cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-02-09 18:53:17,590] A new study created in memory with name: no-name-38eafa5c-a098-4996-a50e-fd8f2960c721\n","[I 2025-02-09 18:53:18,628] Trial 0 finished with value: 0.32991117238998413 and parameters: {'hidden_layers': 4, 'hidden_units': 148, 'dropout_rate': 0.3151924614093718, 'lr': 0.00099409384658947, 'weight_decay': 0.005109620347560256}. Best is trial 0 with value: 0.32991117238998413.\n","[I 2025-02-09 18:53:18,934] Trial 1 finished with value: 0.35571053624153137 and parameters: {'hidden_layers': 2, 'hidden_units': 144, 'dropout_rate': 0.2656312889359005, 'lr': 0.0014226719236575362, 'weight_decay': 0.0016503216087987405}. Best is trial 0 with value: 0.32991117238998413.\n","[I 2025-02-09 18:53:19,251] Trial 2 finished with value: 0.08823561668395996 and parameters: {'hidden_layers': 2, 'hidden_units': 108, 'dropout_rate': 0.28364276834374946, 'lr': 0.0005501589353261401, 'weight_decay': 0.005367521880837673}. Best is trial 2 with value: 0.08823561668395996.\n","[I 2025-02-09 18:53:19,410] Trial 3 finished with value: 2.966552257537842 and parameters: {'hidden_layers': 5, 'hidden_units': 137, 'dropout_rate': 0.3691212712026922, 'lr': 0.0014870394465051305, 'weight_decay': 0.0039738399565192066}. Best is trial 2 with value: 0.08823561668395996.\n","[I 2025-02-09 18:53:19,805] Trial 4 finished with value: 0.1360398530960083 and parameters: {'hidden_layers': 3, 'hidden_units': 116, 'dropout_rate': 0.3553810390447517, 'lr': 0.0013685171823820533, 'weight_decay': 0.007217197750014212}. Best is trial 2 with value: 0.08823561668395996.\n","[I 2025-02-09 18:53:20,163] Trial 5 finished with value: 0.04277228191494942 and parameters: {'hidden_layers': 2, 'hidden_units': 141, 'dropout_rate': 0.3823982271719008, 'lr': 0.0005280295356863941, 'weight_decay': 0.006943082185900467}. Best is trial 5 with value: 0.04277228191494942.\n","[I 2025-02-09 18:53:20,889] Trial 6 finished with value: 0.5591374039649963 and parameters: {'hidden_layers': 5, 'hidden_units': 136, 'dropout_rate': 0.37705976166635813, 'lr': 0.0014565985577011515, 'weight_decay': 0.0010850737750360507}. Best is trial 5 with value: 0.04277228191494942.\n","[I 2025-02-09 18:53:21,090] Trial 7 finished with value: 0.26110026240348816 and parameters: {'hidden_layers': 3, 'hidden_units': 141, 'dropout_rate': 0.30819670107830377, 'lr': 0.0005027400927295355, 'weight_decay': 0.005534052352291133}. Best is trial 5 with value: 0.04277228191494942.\n","[I 2025-02-09 18:53:21,403] Trial 8 finished with value: 0.2945064604282379 and parameters: {'hidden_layers': 4, 'hidden_units': 124, 'dropout_rate': 0.23982918834232442, 'lr': 0.0009583430270022477, 'weight_decay': 0.0027578909182103266}. Best is trial 5 with value: 0.04277228191494942.\n","[I 2025-02-09 18:53:21,465] Trial 9 finished with value: 2.1533286571502686 and parameters: {'hidden_layers': 3, 'hidden_units': 110, 'dropout_rate': 0.395118021275683, 'lr': 0.0011273094581192627, 'weight_decay': 0.002774132363697898}. Best is trial 5 with value: 0.04277228191494942.\n","[I 2025-02-09 18:53:21,710] Trial 10 finished with value: 0.02215786650776863 and parameters: {'hidden_layers': 2, 'hidden_units': 130, 'dropout_rate': 0.20221991469241196, 'lr': 0.0006940314637489098, 'weight_decay': 0.008845591473210597}. Best is trial 10 with value: 0.02215786650776863.\n","[I 2025-02-09 18:53:21,964] Trial 11 finished with value: 0.00014855370682198554 and parameters: {'hidden_layers': 2, 'hidden_units': 129, 'dropout_rate': 0.20184620201029646, 'lr': 0.0006636046628916647, 'weight_decay': 0.008740892579522007}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:22,168] Trial 12 finished with value: 0.02888667769730091 and parameters: {'hidden_layers': 2, 'hidden_units': 128, 'dropout_rate': 0.20539111814641517, 'lr': 0.0006925848976024278, 'weight_decay': 0.009267647949167436}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:22,329] Trial 13 finished with value: 0.004231522791087627 and parameters: {'hidden_layers': 2, 'hidden_units': 125, 'dropout_rate': 0.20290253624733406, 'lr': 0.0006863015471168307, 'weight_decay': 0.009792307774055169}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:22,648] Trial 14 finished with value: 0.1466272622346878 and parameters: {'hidden_layers': 3, 'hidden_units': 119, 'dropout_rate': 0.23790923615449133, 'lr': 0.0007114168491763409, 'weight_decay': 0.009054358852969024}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:22,816] Trial 15 finished with value: 0.10072655975818634 and parameters: {'hidden_layers': 2, 'hidden_units': 118, 'dropout_rate': 0.23105984566345744, 'lr': 0.0006234955993337065, 'weight_decay': 0.0038946105276757357}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:23,353] Trial 16 finished with value: 0.30614328384399414 and parameters: {'hidden_layers': 4, 'hidden_units': 101, 'dropout_rate': 0.26436471179665916, 'lr': 0.0008032395993028853, 'weight_decay': 0.002018259723134333}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:24,115] Trial 17 finished with value: 0.18894465267658234 and parameters: {'hidden_layers': 3, 'hidden_units': 132, 'dropout_rate': 0.33413710291161725, 'lr': 0.0008030315876375941, 'weight_decay': 0.006958631015512907}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:24,317] Trial 18 finished with value: 0.03789887577295303 and parameters: {'hidden_layers': 2, 'hidden_units': 124, 'dropout_rate': 0.21414021986566215, 'lr': 0.0006033746216925491, 'weight_decay': 0.00959109867221207}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:24,758] Trial 19 finished with value: 0.09872762113809586 and parameters: {'hidden_layers': 3, 'hidden_units': 124, 'dropout_rate': 0.25917592274324813, 'lr': 0.0006014879162954892, 'weight_decay': 0.0038824836755663537}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:24,968] Trial 20 finished with value: 0.17605005204677582 and parameters: {'hidden_layers': 2, 'hidden_units': 134, 'dropout_rate': 0.22455254354505122, 'lr': 0.0007740626830318895, 'weight_decay': 0.006429679130097825}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:25,272] Trial 21 finished with value: 0.00857387576252222 and parameters: {'hidden_layers': 2, 'hidden_units': 129, 'dropout_rate': 0.20177213728131893, 'lr': 0.0006821652261476239, 'weight_decay': 0.008290749648833052}. Best is trial 11 with value: 0.00014855370682198554.\n","[I 2025-02-09 18:53:25,607] Trial 22 finished with value: 0.00010097373888129368 and parameters: {'hidden_layers': 2, 'hidden_units': 128, 'dropout_rate': 0.2199652595007233, 'lr': 0.000659222685305151, 'weight_decay': 0.008146400410283663}. Best is trial 22 with value: 0.00010097373888129368.\n","[I 2025-02-09 18:53:25,760] Trial 23 finished with value: 0.04496660456061363 and parameters: {'hidden_layers': 2, 'hidden_units': 113, 'dropout_rate': 0.24438518681834362, 'lr': 0.0008699716438845558, 'weight_decay': 0.004671016764291223}. Best is trial 22 with value: 0.00010097373888129368.\n","[I 2025-02-09 18:53:26,136] Trial 24 finished with value: 0.18801434338092804 and parameters: {'hidden_layers': 3, 'hidden_units': 121, 'dropout_rate': 0.2209913520842175, 'lr': 0.0006320025750497376, 'weight_decay': 0.007329437098297378}. Best is trial 22 with value: 0.00010097373888129368.\n","[I 2025-02-09 18:53:26,621] Trial 25 finished with value: 0.029325289651751518 and parameters: {'hidden_layers': 2, 'hidden_units': 128, 'dropout_rate': 0.2873231049201955, 'lr': 0.0005572241668573882, 'weight_decay': 0.005902468785116481}. Best is trial 22 with value: 0.00010097373888129368.\n","[I 2025-02-09 18:53:27,154] Trial 26 finished with value: 0.11188975721597672 and parameters: {'hidden_layers': 3, 'hidden_units': 122, 'dropout_rate': 0.2187948601502149, 'lr': 0.0007544440697217999, 'weight_decay': 0.009998554656777544}. Best is trial 22 with value: 0.00010097373888129368.\n","[I 2025-02-09 18:53:27,573] Trial 27 finished with value: 0.00101693335454911 and parameters: {'hidden_layers': 2, 'hidden_units': 137, 'dropout_rate': 0.2531898353657006, 'lr': 0.0008766562277475625, 'weight_decay': 0.007811029484580123}. Best is trial 22 with value: 0.00010097373888129368.\n","[I 2025-02-09 18:53:28,176] Trial 28 finished with value: 0.2185826599597931 and parameters: {'hidden_layers': 4, 'hidden_units': 139, 'dropout_rate': 0.2532024247138033, 'lr': 0.0009295264195577916, 'weight_decay': 0.007793339716322265}. Best is trial 22 with value: 0.00010097373888129368.\n","[I 2025-02-09 18:53:28,489] Trial 29 finished with value: 0.014947113581001759 and parameters: {'hidden_layers': 2, 'hidden_units': 150, 'dropout_rate': 0.2851278677525507, 'lr': 0.0010564293909123713, 'weight_decay': 0.004664045720360766}. Best is trial 22 with value: 0.00010097373888129368.\n"]},{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'hidden_layers': 2, 'hidden_units': 128, 'dropout_rate': 0.2199652595007233, 'lr': 0.000659222685305151, 'weight_decay': 0.008146400410283663}\n","Train Metrics: MAE=0.0388, MSE=0.002240, RMSE=0.0473, R²=0.9872, MAPE=13.62%\n","Validation Metrics: MAE=0.1375, MSE=0.018963, RMSE=0.1377, R²=-2.2241, MAPE=7.87%\n","Test Metrics: MAE=0.1614, MSE=0.026081, RMSE=0.1615, R²=-3.3216, MAPE=8.00%\n"]}]},{"cell_type":"markdown","source":["## GRU"],"metadata":{"id":"wpOo3u4FXfee"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Define GRU Model\n","class GRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(GRUModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.gru(x, h0)\n","        return self.fc(out[:, -1, :])\n","\n","# Set parameters\n","input_size = 3  # Open, High, Low\n","hidden_size = 64\n","num_layers = 2\n","learning_rate = 0.001\n","num_epochs = 100\n","\n","# Convert data to PyTorch tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# Initialize model, loss function, and optimizer\n","model = GRUModel(input_size, hidden_size, num_layers).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    outputs = model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    train_pred = model(X_train_torch).cpu().numpy()\n","    val_pred = model(X_val_torch).cpu().numpy()\n","    test_pred = model(X_test_torch).cpu().numpy()\n","\n","# Convert back to NumPy for metric calculations\n","Y_train_np = Y_train_torch.cpu().numpy()\n","Y_val_np = Y_val_torch.cpu().numpy()\n","Y_test_np = Y_test_torch.cpu().numpy()\n","\n","# Compute metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # MAPE in %\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train_np, train_pred)\n","metrics_val = compute_metrics(Y_val_np, val_pred)\n","metrics_test = compute_metrics(Y_test_np, test_pred)\n","\n","# Print metrics\n","print(\"\\nTraining Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_train))\n","print(\"Validation Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_val))\n","print(\"Test Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZtFlYxeN64F","executionInfo":{"status":"ok","timestamp":1739264206875,"user_tz":-330,"elapsed":9030,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"4da528a0-fc82-4f73-e375-d1d0dc8cce3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.3086\n","Epoch [20/100], Loss: 0.1553\n","Epoch [30/100], Loss: 0.0518\n","Epoch [40/100], Loss: 0.0430\n","Epoch [50/100], Loss: 0.0206\n","Epoch [60/100], Loss: 0.0098\n","Epoch [70/100], Loss: 0.0024\n","Epoch [80/100], Loss: 0.0005\n","Epoch [90/100], Loss: 0.0001\n","Epoch [100/100], Loss: 0.0002\n","\n","Training Metrics: MAE=0.0114, MSE=0.0002, RMSE=0.0134, R²=0.9990, MAPE=3.74%\n","Validation Metrics: MAE=0.0172, MSE=0.0003, RMSE=0.0176, R²=0.9472, MAPE=0.99%\n","Test Metrics: MAE=0.0083, MSE=0.0001, RMSE=0.0089, R²=0.9869, MAPE=0.41%\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Define GRU Model\n","class GRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(GRUModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.gru(x, h0)\n","        return self.fc(out[:, -1, :])\n","\n","# Set parameters\n","input_size = 3  # Open, High, Low\n","hidden_size = 64\n","num_layers = 3\n","learning_rate = 0.001\n","num_epochs = 100\n","\n","# Convert data to PyTorch tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# Initialize model, loss function, and optimizer\n","model = GRUModel(input_size, hidden_size, num_layers).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    outputs = model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    train_pred = model(X_train_torch).cpu().numpy()\n","    val_pred = model(X_val_torch).cpu().numpy()\n","    test_pred = model(X_test_torch).cpu().numpy()\n","\n","# Convert back to NumPy for metric calculations\n","Y_train_np = Y_train_torch.cpu().numpy()\n","Y_val_np = Y_val_torch.cpu().numpy()\n","Y_test_np = Y_test_torch.cpu().numpy()\n","\n","# Compute metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # MAPE in %\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train_np, train_pred)\n","metrics_val = compute_metrics(Y_val_np, val_pred)\n","metrics_test = compute_metrics(Y_test_np, test_pred)\n","\n","# Print metrics\n","print(\"\\nTraining Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_train))\n","print(\"Validation Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_val))\n","print(\"Test Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Z43jGd9OYN5","executionInfo":{"status":"ok","timestamp":1739264219778,"user_tz":-330,"elapsed":1686,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"02887a82-2eef-4019-c24f-a075d4a7d831"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.2116\n","Epoch [20/100], Loss: 0.1298\n","Epoch [30/100], Loss: 0.0997\n","Epoch [40/100], Loss: 0.0452\n","Epoch [50/100], Loss: 0.0067\n","Epoch [60/100], Loss: 0.0020\n","Epoch [70/100], Loss: 0.0023\n","Epoch [80/100], Loss: 0.0006\n","Epoch [90/100], Loss: 0.0007\n","Epoch [100/100], Loss: 0.0005\n","\n","Training Metrics: MAE=0.0176, MSE=0.0005, RMSE=0.0220, R²=0.9972, MAPE=10.67%\n","Validation Metrics: MAE=0.0088, MSE=0.0001, RMSE=0.0103, R²=0.9820, MAPE=0.51%\n","Test Metrics: MAE=0.0313, MSE=0.0012, RMSE=0.0347, R²=0.8008, MAPE=1.53%\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Define GRU Model\n","class GRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(GRUModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.gru(x, h0)\n","        return self.fc(out[:, -1, :])\n","\n","# Set parameters\n","input_size = 3  # Open, High, Low\n","hidden_size = 64\n","num_layers = 5\n","learning_rate = 0.001\n","num_epochs = 100\n","\n","# Convert data to PyTorch tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# Initialize model, loss function, and optimizer\n","model = GRUModel(input_size, hidden_size, num_layers).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    outputs = model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    train_pred = model(X_train_torch).cpu().numpy()\n","    val_pred = model(X_val_torch).cpu().numpy()\n","    test_pred = model(X_test_torch).cpu().numpy()\n","\n","# Convert back to NumPy for metric calculations\n","Y_train_np = Y_train_torch.cpu().numpy()\n","Y_val_np = Y_val_torch.cpu().numpy()\n","Y_test_np = Y_test_torch.cpu().numpy()\n","\n","# Compute metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # MAPE in %\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train_np, train_pred)\n","metrics_val = compute_metrics(Y_val_np, val_pred)\n","metrics_test = compute_metrics(Y_test_np, test_pred)\n","\n","# Print metrics\n","print(\"\\nTraining Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_train))\n","print(\"Validation Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_val))\n","print(\"Test Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vz8X7x_HOdKz","executionInfo":{"status":"ok","timestamp":1739264230756,"user_tz":-330,"elapsed":2597,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"e0b2c047-ebe2-472e-b95e-35a61c952c41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.2233\n","Epoch [20/100], Loss: 0.1596\n","Epoch [30/100], Loss: 0.1312\n","Epoch [40/100], Loss: 0.0553\n","Epoch [50/100], Loss: 0.0022\n","Epoch [60/100], Loss: 0.0065\n","Epoch [70/100], Loss: 0.0013\n","Epoch [80/100], Loss: 0.0017\n","Epoch [90/100], Loss: 0.0011\n","Epoch [100/100], Loss: 0.0011\n","\n","Training Metrics: MAE=0.0296, MSE=0.0011, RMSE=0.0329, R²=0.9938, MAPE=13.75%\n","Validation Metrics: MAE=0.1457, MSE=0.0231, RMSE=0.1518, R²=-2.9197, MAPE=8.25%\n","Test Metrics: MAE=0.3171, MSE=0.1035, RMSE=0.3217, R²=-16.1438, MAPE=15.65%\n"]}]},{"cell_type":"markdown","source":["## BI-LSTM"],"metadata":{"id":"Glneg0lVOonc"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Define Bi-LSTM Model\n","class BiLSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(BiLSTMModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size * 2, 1)  # Bi-directional → hidden_size * 2\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)  # *2 for bidirectional\n","        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        return self.fc(out[:, -1, :])  # Take last time step output\n","\n","# Set Parameters\n","input_size = 3\n","hidden_size = 64\n","num_layers = 2\n","learning_rate = 0.001\n","num_epochs = 100\n","\n","# Convert data to PyTorch tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# Initialize model, loss function, and optimizer\n","model = BiLSTMModel(input_size, hidden_size, num_layers).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    outputs = model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    train_pred = model(X_train_torch).cpu().numpy()\n","    val_pred = model(X_val_torch).cpu().numpy()\n","    test_pred = model(X_test_torch).cpu().numpy()\n","\n","# Convert back to NumPy for metric calculations\n","Y_train_np = Y_train_torch.cpu().numpy()\n","Y_val_np = Y_val_torch.cpu().numpy()\n","Y_test_np = Y_test_torch.cpu().numpy()\n","\n","# Compute metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # MAPE as %\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train_np, train_pred)\n","metrics_val = compute_metrics(Y_val_np, val_pred)\n","metrics_test = compute_metrics(Y_test_np, test_pred)\n","\n","# Print metrics\n","print(\"\\nTraining Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_train))\n","print(\"Validation Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_val))\n","print(\"Test Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F16ykofSOfm1","executionInfo":{"status":"ok","timestamp":1739264335069,"user_tz":-330,"elapsed":3282,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"2dd8c8e2-12c8-45dc-aeac-621b8d07dbb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.2700\n","Epoch [20/100], Loss: 0.1525\n","Epoch [30/100], Loss: 0.0823\n","Epoch [40/100], Loss: 0.0605\n","Epoch [50/100], Loss: 0.0271\n","Epoch [60/100], Loss: 0.0074\n","Epoch [70/100], Loss: 0.0017\n","Epoch [80/100], Loss: 0.0017\n","Epoch [90/100], Loss: 0.0016\n","Epoch [100/100], Loss: 0.0012\n","\n","Training Metrics: MAE=0.0289, MSE=0.0012, RMSE=0.0343, R²=0.9933, MAPE=13.05%\n","Validation Metrics: MAE=0.1051, MSE=0.0113, RMSE=0.1063, R²=-0.9207, MAPE=5.99%\n","Test Metrics: MAE=0.1533, MSE=0.0236, RMSE=0.1537, R²=-2.9167, MAPE=7.59%\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Define Bi-LSTM Model\n","class BiLSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(BiLSTMModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size * 2, 1)  # Bi-directional → hidden_size * 2\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)  # *2 for bidirectional\n","        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        return self.fc(out[:, -1, :])  # Take last time step output\n","\n","# Set Parameters\n","input_size = 3\n","hidden_size = 64\n","num_layers = 3\n","learning_rate = 0.001\n","num_epochs = 100\n","\n","# Convert data to PyTorch tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# Initialize model, loss function, and optimizer\n","model = BiLSTMModel(input_size, hidden_size, num_layers).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    outputs = model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    train_pred = model(X_train_torch).cpu().numpy()\n","    val_pred = model(X_val_torch).cpu().numpy()\n","    test_pred = model(X_test_torch).cpu().numpy()\n","\n","# Convert back to NumPy for metric calculations\n","Y_train_np = Y_train_torch.cpu().numpy()\n","Y_val_np = Y_val_torch.cpu().numpy()\n","Y_test_np = Y_test_torch.cpu().numpy()\n","\n","# Compute metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # MAPE as %\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train_np, train_pred)\n","metrics_val = compute_metrics(Y_val_np, val_pred)\n","metrics_test = compute_metrics(Y_test_np, test_pred)\n","\n","# Print metrics\n","print(\"\\nTraining Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_train))\n","print(\"Validation Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_val))\n","print(\"Test Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQF2wiZLO46q","executionInfo":{"status":"ok","timestamp":1739264363572,"user_tz":-330,"elapsed":3856,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"3ae79f3f-eb1b-4b9a-d379-734a045ba8de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.3436\n","Epoch [20/100], Loss: 0.1889\n","Epoch [30/100], Loss: 0.1164\n","Epoch [40/100], Loss: 0.0615\n","Epoch [50/100], Loss: 0.0207\n","Epoch [60/100], Loss: 0.0036\n","Epoch [70/100], Loss: 0.0027\n","Epoch [80/100], Loss: 0.0028\n","Epoch [90/100], Loss: 0.0019\n","Epoch [100/100], Loss: 0.0016\n","\n","Training Metrics: MAE=0.0321, MSE=0.0016, RMSE=0.0402, R²=0.9908, MAPE=18.71%\n","Validation Metrics: MAE=0.0434, MSE=0.0019, RMSE=0.0435, R²=0.6782, MAPE=2.49%\n","Test Metrics: MAE=0.0246, MSE=0.0007, RMSE=0.0266, R²=0.8830, MAPE=1.24%\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Define Bi-LSTM Model\n","class BiLSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(BiLSTMModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size * 2, 1)  # Bi-directional → hidden_size * 2\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)  # *2 for bidirectional\n","        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        return self.fc(out[:, -1, :])  # Take last time step output\n","\n","# Set Parameters\n","input_size = 3\n","hidden_size = 64\n","num_layers = 5\n","learning_rate = 0.001\n","num_epochs = 100\n","\n","# Convert data to PyTorch tensors\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# Initialize model, loss function, and optimizer\n","model = BiLSTMModel(input_size, hidden_size, num_layers).to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    outputs = model(X_train_torch)\n","    loss = criterion(outputs, Y_train_torch)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    train_pred = model(X_train_torch).cpu().numpy()\n","    val_pred = model(X_val_torch).cpu().numpy()\n","    test_pred = model(X_test_torch).cpu().numpy()\n","\n","# Convert back to NumPy for metric calculations\n","Y_train_np = Y_train_torch.cpu().numpy()\n","Y_val_np = Y_val_torch.cpu().numpy()\n","Y_test_np = Y_test_torch.cpu().numpy()\n","\n","# Compute metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # MAPE as %\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train_np, train_pred)\n","metrics_val = compute_metrics(Y_val_np, val_pred)\n","metrics_test = compute_metrics(Y_test_np, test_pred)\n","\n","# Print metrics\n","print(\"\\nTraining Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_train))\n","print(\"Validation Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_val))\n","print(\"Test Metrics: MAE={:.4f}, MSE={:.4f}, RMSE={:.4f}, R²={:.4f}, MAPE={:.2f}%\".format(*metrics_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xnirT2NO_u0","executionInfo":{"status":"ok","timestamp":1739264380101,"user_tz":-330,"elapsed":6447,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"9b9ebced-4b26-494c-fd50-f7077e2e8f38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.2673\n","Epoch [20/100], Loss: 0.1615\n","Epoch [30/100], Loss: 0.1314\n","Epoch [40/100], Loss: 0.0521\n","Epoch [50/100], Loss: 0.0080\n","Epoch [60/100], Loss: 0.0079\n","Epoch [70/100], Loss: 0.0035\n","Epoch [80/100], Loss: 0.0028\n","Epoch [90/100], Loss: 0.0026\n","Epoch [100/100], Loss: 0.0024\n","\n","Training Metrics: MAE=0.0420, MSE=0.0024, RMSE=0.0486, R²=0.9865, MAPE=22.11%\n","Validation Metrics: MAE=0.1931, MSE=0.0400, RMSE=0.2001, R²=-5.8052, MAPE=10.94%\n","Test Metrics: MAE=0.3950, MSE=0.1598, RMSE=0.3998, R²=-25.4853, MAPE=19.51%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Y0aDHxQSTO5-"},"execution_count":null,"outputs":[]}]}