{"cells":[{"cell_type":"markdown","source":["## Initial Code"],"metadata":{"id":"5ebGneEwoKEe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WY7I5C1zqFJt"},"outputs":[],"source":["# Importing necessary libraries for data analysis and manipulation\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# For handling warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23115,"status":"ok","timestamp":1741461236021,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"},"user_tz":-330},"id":"3RKq8vfwqVHB","outputId":"152d9c68-1cc2-4b61-98e5-0b081e7aae87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4yeLMDyqd2o"},"outputs":[],"source":["df_aapl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AAPL.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHvcgRGPruCy"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import boxcox\n","\n","df_aapl['Close_log'] = np.log(df_aapl['Close'] + 1)\n","df_aapl['Close_sqrt'] = np.sqrt(df_aapl['Close'])\n","df_aapl['Close_boxcox'], _ = boxcox(df_aapl['Close'] + 1)\n"]},{"cell_type":"markdown","metadata":{"id":"lLz5cmQlryah"},"source":["This code calculates the skewness of the 'Close' column in the `df_aapl` DataFrame before and after applying various transformations:\n","\n","1. **Original Skewness**: Calculates the skewness of the original 'Close' data.\n","2. **Log Transformation Skewness**: Calculates the skewness of the 'Close_log' column after applying the log transformation.\n","3. **Square Root Transformation Skewness**: Calculates the skewness of the 'Close_sqrt' column after applying the square root transformation.\n","4. **Box-Cox Transformation Skewness**: Calculates the skewness of the 'Close_boxcox' column after applying the Box-Cox transformation.\n","\n","The printed results help assess how each transformation affects the distribution's symmetry and the success of skewness correction.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1741461357251,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"},"user_tz":-330},"id":"DIPGiQydr2K0","outputId":"12a628e3-a796-480e-a6c5-3fcb4e033652"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Skewness: 2.5045276102319933\n","Log Transformation Skewness: 0.8535555176510303\n","Square Root Transformation Skewness: 1.6211545809555206\n","Box-Cox Transformation Skewness: 0.43527466713563334\n"]}],"source":["\n","skew_original = df_aapl['Close'].skew()\n","skew_log = df_aapl['Close_log'].skew()\n","skew_sqrt = df_aapl['Close_sqrt'].skew()\n","skew_boxcox = pd.Series(df_aapl['Close_boxcox']).skew()\n","\n","print(f\"Original Skewness: {skew_original}\")\n","print(f\"Log Transformation Skewness: {skew_log}\")\n","print(f\"Square Root Transformation Skewness: {skew_sqrt}\")\n","print(f\"Box-Cox Transformation Skewness: {skew_boxcox}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"De4W27wEr9-p"},"outputs":[],"source":["\n","df_aapl['Open_log'] = np.log(df_aapl['Open'])\n","df_aapl['High_log'] = np.log(df_aapl['High'])\n","df_aapl['Low_log'] = np.log(df_aapl['Low'])\n","df_aapl['Adj Close_log'] = np.log(df_aapl['Adj Close'])\n","df_aapl['Volume_log'] = np.log(df_aapl['Volume'])\n","\n","\n","df_aapl['Open_sqrt'] = np.sqrt(df_aapl['Open'])\n","df_aapl['High_sqrt'] = np.sqrt(df_aapl['High'])\n","df_aapl['Low_sqrt'] = np.sqrt(df_aapl['Low'])\n","df_aapl['Adj Close_sqrt'] = np.sqrt(df_aapl['Adj Close'])\n","df_aapl['Volume_sqrt'] = np.sqrt(df_aapl['Volume'])\n","\n","from scipy.stats import boxcox\n","df_aapl['Open_boxcox'], _ = boxcox(df_aapl['Open'])\n","df_aapl['High_boxcox'], _ = boxcox(df_aapl['High'])\n","df_aapl['Low_boxcox'], _ = boxcox(df_aapl['Low'])\n","df_aapl['Adj Close_boxcox'], _ = boxcox(df_aapl['Adj Close'])"]},{"cell_type":"markdown","source":["This helps compare how the transformations reduce skewness in the data, aiming for a more normal distribution."],"metadata":{"id":"2XrZQHaDAigS"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1741461360594,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"},"user_tz":-330},"id":"of1KONYmsC8t","outputId":"a618f33c-7eb7-41a2-f58f-33d316d44e75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness Before Transformation:\n"," Open         2.504632\n","High         2.502208\n","Low          2.506714\n","Adj Close    2.550677\n","Volume       3.565699\n","dtype: float64\n","\n","Skewness After Transformation:\n"," Open_log            0.482872\n","High_log            0.481997\n","Low_log             0.484246\n","Adj Close_log       0.494009\n","Open_sqrt           1.620771\n","High_sqrt           1.621456\n","Low_sqrt            1.620661\n","Adj Close_sqrt      1.679402\n","Volume_sqrt         1.299776\n","Open_boxcox         0.181226\n","High_boxcox         0.179749\n","Low_boxcox          0.182882\n","Adj Close_boxcox    0.180085\n","dtype: float64\n"]}],"source":["\n","skewness_before = df_aapl[['Open', 'High', 'Low', 'Adj Close', 'Volume']].skew()\n","skewness_after = df_aapl[['Open_log', 'High_log', 'Low_log', 'Adj Close_log',\n","                          'Open_sqrt', 'High_sqrt', 'Low_sqrt', 'Adj Close_sqrt', 'Volume_sqrt',\n","                          'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox']].skew()\n","\n","print(\"Skewness Before Transformation:\\n\", skewness_before)\n","print(\"\\nSkewness After Transformation:\\n\", skewness_after)\n"]},{"cell_type":"markdown","source":["- Applied Box-Cox transformation to the 'Open', 'High', 'Low', 'Adj Close', and 'Close' columns.\n","- Recalculated skewness after the transformation to reduce skew and normalize the data for modeling."],"metadata":{"id":"zfEokf4iAmnv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1741461363229,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"},"user_tz":-330},"id":"s9oEP05csI66","outputId":"7fcfb4d0-9ad0-416b-e1d7-cd3dea7ef426"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness After Box-Cox Transformation:\n","Open_boxcox         0.435237\n","High_boxcox         0.433381\n","Low_boxcox          0.437331\n","Adj Close_boxcox    0.458762\n","Close_boxcox        0.435275\n","dtype: float64\n"]}],"source":["from scipy import stats\n","\n","df_aapl['Open_boxcox'], _ = stats.boxcox(df_aapl['Open'] + 1)\n","df_aapl['High_boxcox'], _ = stats.boxcox(df_aapl['High'] + 1)\n","df_aapl['Low_boxcox'], _ = stats.boxcox(df_aapl['Low'] + 1)\n","df_aapl['Adj Close_boxcox'], _ = stats.boxcox(df_aapl['Adj Close'] + 1)\n","df_aapl['Close_boxcox'], _ = stats.boxcox(df_aapl['Close'] + 1)\n","\n","skewness_after_boxcox = df_aapl[['Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox', 'Close_boxcox']].skew()\n","\n","print(\"Skewness After Box-Cox Transformation:\")\n","print(skewness_after_boxcox)\n"]},{"cell_type":"markdown","source":["Feature Selection"],"metadata":{"id":"uvZe7IzRAwHu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1741461366014,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"},"user_tz":-330},"id":"aczNHUI4rk8x","outputId":"62dbde65-5509-469b-956f-37b65e896877"},"outputs":[{"output_type":"stream","name":"stdout","text":["         Date      Open      High       Low  Adj Close     Close     Volume  \\\n","0  1980-12-12  0.128348  0.128906  0.128348   0.098943  0.128348  469033600   \n","1  1980-12-15  0.122210  0.122210  0.121652   0.093781  0.121652  175884800   \n","2  1980-12-16  0.113281  0.113281  0.112723   0.086898  0.112723  105728000   \n","3  1980-12-17  0.115513  0.116071  0.115513   0.089049  0.115513   86441600   \n","4  1980-12-18  0.118862  0.119420  0.118862   0.091630  0.118862   73449600   \n","\n","   Open_boxcox  High_boxcox  Low_boxcox  Adj Close_boxcox  Close_boxcox  \n","0     0.117689     0.118173    0.117674          0.092374      0.117689  \n","1     0.112503     0.112516    0.112016          0.087857      0.112030  \n","2     0.104886     0.104897    0.104395          0.081785      0.104407  \n","3     0.106798     0.107287    0.106786          0.083688      0.106798  \n","4     0.109657     0.110145    0.109644          0.085966      0.109657  \n"]}],"source":["\n","df_aapl_cleaned = df_aapl[['Date', 'Open', 'High', 'Low', 'Adj Close', 'Close', 'Volume',\n","                           'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox',\n","                           'Close_boxcox']]\n","\n","print(df_aapl_cleaned.head())\n"]},{"cell_type":"markdown","source":["### Train Validation Test Split\n","\n","The code splits the data into training, validation, and test sets. The features `X` and target `Y` are split as follows:\n","\n","- 70% for training (`X_train`, `Y_train`)\n","- 15% for validation (`X_val`, `Y_val`)\n","- 15% for testing (`X_test`, `Y_test`)\n","\n","The split is done using a 30% test size, followed by splitting the remaining 70% into validation and test sets without shuffling (time series data)."],"metadata":{"id":"chw5ijVT_JRM"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df_aapl_cleaned[['Open_boxcox', 'High_boxcox', 'Low_boxcox']]\n","Y = df_aapl_cleaned['Close_boxcox']\n","\n","X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, shuffle=False)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, shuffle=False)\n","\n","print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSztwxnoy8-U","executionInfo":{"status":"ok","timestamp":1741461369066,"user_tz":-330,"elapsed":8,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"}},"outputId":"ff9a5975-caf6-41d7-ee35-240f9ee7c6ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (7736, 3), Validation set: (1658, 3), Test set: (1658, 3)\n"]}]},{"cell_type":"markdown","source":["## Random Forest Regressor"],"metadata":{"id":"aj0JYwhXNyOI"}},{"cell_type":"code","source":["!pip install hpbandster\n","!pip install ConfigSpace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nl-Fy9J9Ntxg","executionInfo":{"status":"ok","timestamp":1734348350777,"user_tz":-330,"elapsed":20608,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"6636ebb9-ea22-4adb-9cc4-330a7db78397"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hpbandster\n","  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Pyro4 (from hpbandster)\n","  Downloading Pyro4-4.82-py2.py3-none-any.whl.metadata (2.2 kB)\n","Collecting serpent (from hpbandster)\n","  Downloading serpent-1.41-py3-none-any.whl.metadata (5.8 kB)\n","Collecting ConfigSpace (from hpbandster)\n","  Downloading configspace-1.2.1.tar.gz (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.26.4)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.13.1)\n","Collecting netifaces (from hpbandster)\n","  Downloading netifaces-0.11.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (3.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (10.5.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n","Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading serpent-1.41-py3-none-any.whl (9.6 kB)\n","Building wheels for collected packages: hpbandster, ConfigSpace, netifaces\n","  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=79986 sha256=344eebb5ab57d41d5d00f96f93b9ddacbf89a1eeafba29fc93df1b5dea31754e\n","  Stored in directory: /root/.cache/pip/wheels/79/51/18/33d6ba8c55cc8401bffbccb1b87b21e0c68f40edc4ce3c1f99\n","  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ConfigSpace: filename=ConfigSpace-1.2.1-py3-none-any.whl size=115941 sha256=22f902c76222510e87d134990b7318ff2f07cd82ffd8cf3d29572542462f4c30\n","  Stored in directory: /root/.cache/pip/wheels/75/e4/b7/23c23eb4a1c3b1adfeb8bd11366f48c805cbf3ba347237fea6\n","  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for netifaces: filename=netifaces-0.11.0-cp310-cp310-linux_x86_64.whl size=35005 sha256=9b390fbc3dcf38035d5ef1580d3ce75eda623744a9ce5bb96eb726baab17ced2\n","  Stored in directory: /root/.cache/pip/wheels/48/65/b3/4c4cc6038b81ff21cc9df69f2b6774f5f52e23d3c275ed15aa\n","Successfully built hpbandster ConfigSpace netifaces\n","Installing collected packages: netifaces, serpent, Pyro4, ConfigSpace, hpbandster\n","Successfully installed ConfigSpace-1.2.1 Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.10/dist-packages (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.26.4)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (3.2.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.13.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (10.5.0)\n"]}]},{"cell_type":"markdown","source":["###**Initial**"],"metadata":{"id":"LHaeb180N5RZ"}},{"cell_type":"code","source":["import time\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","# Initialize RandomForestRegressor\n","rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n","\n","# Start timer for training\n","start_time = time.time()\n","\n","# Train the model\n","rf_regressor.fit(X_train, Y_train)\n","\n","# End timer for training\n","training_time = time.time() - start_time\n","\n","# Make predictions for train, validation, and test sets\n","Y_train_pred = rf_regressor.predict(X_train)\n","Y_val_pred = rf_regressor.predict(X_val)\n","Y_test_pred = rf_regressor.predict(X_test)\n","\n","# Calculate metrics for training set\n","train_mae = mean_absolute_error(Y_train, Y_train_pred)\n","train_mse = mean_squared_error(Y_train, Y_train_pred)\n","train_rmse = np.sqrt(train_mse)\n","train_r2 = r2_score(Y_train, Y_train_pred)\n","train_mape = np.mean(np.abs((Y_train - Y_train_pred) / Y_train)) * 100\n","\n","# Calculate metrics for validation set\n","val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","val_mse = mean_squared_error(Y_val, Y_val_pred)\n","val_rmse = np.sqrt(val_mse)\n","val_r2 = r2_score(Y_val, Y_val_pred)\n","val_mape = np.mean(np.abs((Y_val - Y_val_pred) / Y_val)) * 100\n","\n","# Calculate metrics for test set\n","test_mae = mean_absolute_error(Y_test, Y_test_pred)\n","test_mse = mean_squared_error(Y_test, Y_test_pred)\n","test_rmse = np.sqrt(test_mse)\n","test_r2 = r2_score(Y_test, Y_test_pred)\n","test_mape = np.mean(np.abs((Y_test - Y_test_pred) / Y_test)) * 100\n","\n","# Calculate accuracy as R² for simplicity\n","train_accuracy = train_r2\n","val_accuracy = val_r2\n","test_accuracy = test_r2\n","\n","# Print results\n","print(f\"Training time: {training_time:.4f} seconds\\n\")\n","print(f\"Training Metrics: MAE={train_mae:.4f}, MSE={train_mse:.4f}, RMSE={train_rmse:.4f}, R²={train_r2:.4f}, MAPE={train_mape:.4f}%\")\n","print(f\"Validation Metrics: MAE={val_mae:.4f}, MSE={val_mse:.4f}, RMSE={val_rmse:.4f}, R²={val_r2:.4f}, MAPE={val_mape:.4f}%\")\n","print(f\"Test Metrics: MAE={test_mae:.4f}, MSE={test_mse:.4f}, RMSE={test_rmse:.4f}, R²={test_r2:.4f}, MAPE={test_mape:.4f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LUWNMRDOpMa","executionInfo":{"status":"ok","timestamp":1734113672622,"user_tz":-330,"elapsed":7222,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"c052af4a-4184-41b6-ea4f-a4b4e87dbc2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training time: 6.2235 seconds\n","\n","Training Metrics: MAE=0.0009, MSE=0.0000, RMSE=0.0014, R²=1.0000, MAPE=0.2555%\n","Validation Metrics: MAE=0.1380, MSE=0.0247, RMSE=0.1573, R²=-3.2077, MAPE=7.7269%\n","Test Metrics: MAE=0.4064, MSE=0.1712, RMSE=0.4138, R²=-27.3699, MAPE=20.0423%\n"]}]},{"cell_type":"markdown","source":["###**Cross-Validation**"],"metadata":{"id":"OMJTwHjXSyEB"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score, cross_val_predict\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","import time\n","\n","# Initialize RandomForestRegressor\n","rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n","\n","# Start timer for cross-validation\n","start_time = time.time()\n","\n","# Perform cross-validation (5-fold cross-validation)\n","cv_predictions = cross_val_predict(rf_regressor, X, Y, cv=5)\n","\n","# End timer for cross-validation\n","cv_time = time.time() - start_time\n","\n","# Calculate metrics for cross-validation\n","cv_mae = mean_absolute_error(Y, cv_predictions)\n","cv_mse = mean_squared_error(Y, cv_predictions)\n","cv_rmse = np.sqrt(cv_mse)\n","cv_r2 = r2_score(Y, cv_predictions)\n","cv_mape = np.mean(np.abs((Y - cv_predictions) / Y)) * 100\n","\n","# Split the dataset into train, validation, and test sets\n","X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, shuffle=False)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, shuffle=False)\n","\n","# Train the model on the training set\n","rf_regressor.fit(X_train, Y_train)\n","\n","# Make predictions for train, validation, and test sets\n","Y_train_pred = rf_regressor.predict(X_train)\n","Y_val_pred = rf_regressor.predict(X_val)\n","Y_test_pred = rf_regressor.predict(X_test)\n","\n","# Calculate metrics for training set\n","train_mae = mean_absolute_error(Y_train, Y_train_pred)\n","train_mse = mean_squared_error(Y_train, Y_train_pred)\n","train_rmse = np.sqrt(train_mse)\n","train_r2 = r2_score(Y_train, Y_train_pred)\n","train_mape = np.mean(np.abs((Y_train - Y_train_pred) / Y_train)) * 100\n","\n","# Calculate metrics for validation set\n","val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","val_mse = mean_squared_error(Y_val, Y_val_pred)\n","val_rmse = np.sqrt(val_mse)\n","val_r2 = r2_score(Y_val, Y_val_pred)\n","val_mape = np.mean(np.abs((Y_val - Y_val_pred) / Y_val)) * 100\n","\n","# Calculate metrics for test set\n","test_mae = mean_absolute_error(Y_test, Y_test_pred)\n","test_mse = mean_squared_error(Y_test, Y_test_pred)\n","test_rmse = np.sqrt(test_mse)\n","test_r2 = r2_score(Y_test, Y_test_pred)\n","test_mape = np.mean(np.abs((Y_test - Y_test_pred) / Y_test)) * 100\n","\n","# Print results\n","print(f\"Cross-validation time: {cv_time:.4f} seconds\\n\")\n","print(f\"Cross-validation Metrics: MAE={cv_mae:.4f}, MSE={cv_mse:.4f}, RMSE={cv_rmse:.4f}, R²={cv_r2:.4f}, MAPE={cv_mape:.4f}%\")\n","print(\"\\nTraining Metrics:\")\n","print(f\"MAE={train_mae:.4f}, MSE={train_mse:.4f}, RMSE={train_rmse:.4f}, R²={train_r2:.4f}, MAPE={train_mape:.4f}%\")\n","print(\"\\nValidation Metrics:\")\n","print(f\"MAE={val_mae:.4f}, MSE={val_mse:.4f}, RMSE={val_rmse:.4f}, R²={val_r2:.4f}, MAPE={val_mape:.4f}%\")\n","print(\"\\nTest Metrics:\")\n","print(f\"MAE={test_mae:.4f}, MSE={test_mse:.4f}, RMSE={test_rmse:.4f}, R²={test_r2:.4f}, MAPE={test_mape:.4f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNXoPtWNRK4m","executionInfo":{"status":"ok","timestamp":1734114449637,"user_tz":-330,"elapsed":23557,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"698e7cc3-ba03-4b31-ddc6-28b0eec7088a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross-validation time: 20.5600 seconds\n","\n","Cross-validation Metrics: MAE=0.0643, MSE=0.0127, RMSE=0.1128, R²=0.9772, MAPE=7.2271%\n","\n","Training Metrics:\n","MAE=0.0009, MSE=0.0000, RMSE=0.0014, R²=1.0000, MAPE=0.2555%\n","\n","Validation Metrics:\n","MAE=0.1380, MSE=0.0247, RMSE=0.1573, R²=-3.2077, MAPE=7.7269%\n","\n","Test Metrics:\n","MAE=0.4064, MSE=0.1712, RMSE=0.4138, R²=-27.3699, MAPE=20.0423%\n"]}]},{"cell_type":"markdown","source":["Overfitting: The model is overfitting the training data (perfect fit on training but poor performance on validation and test sets). This results in a high R² on training and very poor R² on validation and test.\n","Cross-validation performance is good, but the model needs to be regularized and fine-tuned to prevent overfitting."],"metadata":{"id":"ekfkuq5sR6eR"}},{"cell_type":"markdown","source":["###**GridSearchCV**"],"metadata":{"id":"-RX7QdECgt3T"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","# Define the parameter grid to search over\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Initialize the RandomForestRegressor\n","rf_regressor = RandomForestRegressor(random_state=42)\n","\n","# Initialize GridSearchCV with cross-validation\n","grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n","\n","# Fit the grid search to the data\n","grid_search.fit(X_train, Y_train)\n","\n","# Get the best parameters and best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","# Get the best estimator from the grid search\n","best_rf_model = grid_search.best_estimator_\n","\n","# Print the best parameters and the best cross-validation score\n","print(f\"Best Parameters: {best_params}\")\n","print(f\"Best CV Score (Negative MSE): {best_score}\")\n","\n","# Make predictions using the best model\n","Y_train_pred = best_rf_model.predict(X_train)\n","Y_val_pred = best_rf_model.predict(X_val)\n","Y_test_pred = best_rf_model.predict(X_test)\n","\n","# Calculate metrics for training set\n","train_mae = mean_absolute_error(Y_train, Y_train_pred)\n","train_mse = mean_squared_error(Y_train, Y_train_pred)\n","train_rmse = np.sqrt(train_mse)\n","train_r2 = r2_score(Y_train, Y_train_pred)\n","train_mape = np.mean(np.abs((Y_train - Y_train_pred) / Y_train)) * 100\n","\n","# Calculate metrics for validation set\n","val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","val_mse = mean_squared_error(Y_val, Y_val_pred)\n","val_rmse = np.sqrt(val_mse)\n","val_r2 = r2_score(Y_val, Y_val_pred)\n","val_mape = np.mean(np.abs((Y_val - Y_val_pred) / Y_val)) * 100\n","\n","# Calculate metrics for test set\n","test_mae = mean_absolute_error(Y_test, Y_test_pred)\n","test_mse = mean_squared_error(Y_test, Y_test_pred)\n","test_rmse = np.sqrt(test_mse)\n","test_r2 = r2_score(Y_test, Y_test_pred)\n","test_mape = np.mean(np.abs((Y_test - Y_test_pred) / Y_test)) * 100\n","\n","# Print the results\n","print(\"\\nTraining Metrics:\")\n","print(f\"MAE={train_mae:.4f}, MSE={train_mse:.4f}, RMSE={train_rmse:.4f}, R²={train_r2:.4f}, MAPE={train_mape:.4f}%\")\n","print(\"\\nValidation Metrics:\")\n","print(f\"MAE={val_mae:.4f}, MSE={val_mse:.4f}, RMSE={val_rmse:.4f}, R²={val_r2:.4f}, MAPE={val_mape:.4f}%\")\n","print(\"\\nTest Metrics:\")\n","print(f\"MAE={test_mae:.4f}, MSE={test_mse:.4f}, RMSE={test_rmse:.4f}, R²={test_r2:.4f}, MAPE={test_mape:.4f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ovdqa3BRjns","executionInfo":{"status":"ok","timestamp":1734116403736,"user_tz":-330,"elapsed":1458923,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"c30a7238-0bb1-480c-c8f8-10c3f3f62871"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 108 candidates, totalling 540 fits\n","Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n","Best CV Score (Negative MSE): -0.05056964470131994\n","\n","Training Metrics:\n","MAE=0.0012, MSE=0.0000, RMSE=0.0018, R²=1.0000, MAPE=0.3490%\n","\n","Validation Metrics:\n","MAE=0.1391, MSE=0.0251, RMSE=0.1583, R²=-3.2602, MAPE=7.7872%\n","\n","Test Metrics:\n","MAE=0.4075, MSE=0.1721, RMSE=0.4149, R²=-27.5203, MAPE=20.0977%\n"]}]},{"cell_type":"markdown","source":["Overfitting: Despite tuning hyperparameters, the model still overfits the training data (R² = 1.0000 on training), resulting in poor performance on the validation and test sets.\n","Generalization Issue: The model fails to generalize to unseen data, as indicated by the negative R² values on validation and test sets.\n","Hyperparameter Tuning: The grid search was useful in improving the model's hyperparameters, but the model is still not robust enough to generalize well."],"metadata":{"id":"2149-0y0ZdGO"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KTN3uTFMTiSi","executionInfo":{"status":"ok","timestamp":1734117802463,"user_tz":-330,"elapsed":6538,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"3c6905cb-dbbc-437d-933e-60c191cff01c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"]}]},{"cell_type":"markdown","source":["###**Optuna**"],"metadata":{"id":"hRrB-svmgpm3"}},{"cell_type":"code","source":["import optuna\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","# Objective function to optimize\n","def objective(trial):\n","    # Suggest hyperparameters\n","    n_estimators = trial.suggest_int('n_estimators', 50, 500, step=50)\n","    max_depth = trial.suggest_categorical('max_depth', [None, 10, 20, 30, 40, 50])\n","    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n","    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n","\n","    # Initialize RandomForestRegressor with suggested hyperparameters\n","    model = RandomForestRegressor(\n","        n_estimators=n_estimators,\n","        max_depth=max_depth,\n","        min_samples_split=min_samples_split,\n","        min_samples_leaf=min_samples_leaf,\n","        random_state=42\n","    )\n","\n","    # Train the model\n","    model.fit(X_train, Y_train)\n","\n","    # Predictions on the validation set\n","    Y_val_pred = model.predict(X_val)\n","\n","    # Calculate metrics for validation\n","    val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","    val_mse = mean_squared_error(Y_val, Y_val_pred)\n","    val_rmse = np.sqrt(val_mse)\n","    val_r2 = r2_score(Y_val, Y_val_pred)\n","\n","    # Return the validation score (you could use any metric here, e.g., negative MSE)\n","    return val_r2  # We aim to maximize R²\n","\n","# Create the Optuna study object and optimize\n","study = optuna.create_study(direction='maximize')  # Maximizing R²\n","study.optimize(objective, n_trials=50)  # Number of trials can be adjusted\n","\n","# Print the best hyperparameters\n","print(\"Best Hyperparameters:\", study.best_params)\n","\n","# Evaluate the best model\n","best_model = RandomForestRegressor(**study.best_params, random_state=42)\n","best_model.fit(X_train, Y_train)\n","\n","# Predictions on training, validation, and test sets\n","Y_train_pred = best_model.predict(X_train)\n","Y_val_pred = best_model.predict(X_val)\n","Y_test_pred = best_model.predict(X_test)\n","\n","# Calculate metrics for training set\n","train_mae = mean_absolute_error(Y_train, Y_train_pred)\n","train_mse = mean_squared_error(Y_train, Y_train_pred)\n","train_rmse = np.sqrt(train_mse)\n","train_r2 = r2_score(Y_train, Y_train_pred)\n","train_mape = np.mean(np.abs((Y_train - Y_train_pred) / Y_train)) * 100\n","\n","# Calculate metrics for validation set\n","val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","val_mse = mean_squared_error(Y_val, Y_val_pred)\n","val_rmse = np.sqrt(val_mse)\n","val_r2 = r2_score(Y_val, Y_val_pred)\n","val_mape = np.mean(np.abs((Y_val - Y_val_pred) / Y_val)) * 100\n","\n","# Calculate metrics for test set\n","test_mae = mean_absolute_error(Y_test, Y_test_pred)\n","test_mse = mean_squared_error(Y_test, Y_test_pred)\n","test_rmse = np.sqrt(test_mse)\n","test_r2 = r2_score(Y_test, Y_test_pred)\n","test_mape = np.mean(np.abs((Y_test - Y_test_pred) / Y_test)) * 100\n","\n","# Print the results\n","print(\"\\nTraining Metrics:\")\n","print(f\"MAE={train_mae:.4f}, MSE={train_mse:.4f}, RMSE={train_rmse:.4f}, R²={train_r2:.4f}, MAPE={train_mape:.4f}%\")\n","print(\"\\nValidation Metrics:\")\n","print(f\"MAE={val_mae:.4f}, MSE={val_mse:.4f}, RMSE={val_rmse:.4f}, R²={val_r2:.4f}, MAPE={val_mape:.4f}%\")\n","print(\"\\nTest Metrics:\")\n","print(f\"MAE={test_mae:.4f}, MSE={test_mse:.4f}, RMSE={test_rmse:.4f}, R²={test_r2:.4f}, MAPE={test_mape:.4f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCHyUDqPeaWm","executionInfo":{"status":"ok","timestamp":1734118278592,"user_tz":-330,"elapsed":469423,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"b0cc3993-26e6-4ff3-dd44-1cb82a314a2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-12-13 19:23:30,185] A new study created in memory with name: no-name-0a56408b-955d-46d2-b35d-6809ba184623\n","[I 2024-12-13 19:23:56,222] Trial 0 finished with value: -3.2151817548749166 and parameters: {'n_estimators': 500, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:23:59,741] Trial 1 finished with value: -3.3905503089760893 and parameters: {'n_estimators': 150, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:03,431] Trial 2 finished with value: -3.2189466474525448 and parameters: {'n_estimators': 150, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:09,242] Trial 3 finished with value: -3.3929100194520636 and parameters: {'n_estimators': 350, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:17,631] Trial 4 finished with value: -3.41728340679993 and parameters: {'n_estimators': 400, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:20,146] Trial 5 finished with value: -3.4693835874235335 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:28,399] Trial 6 finished with value: -3.3919380833539696 and parameters: {'n_estimators': 400, 'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:36,638] Trial 7 finished with value: -3.365529793592925 and parameters: {'n_estimators': 350, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:40,156] Trial 8 finished with value: -3.3307296750846263 and parameters: {'n_estimators': 200, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:42,819] Trial 9 finished with value: -3.333975154542915 and parameters: {'n_estimators': 150, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: -3.2151817548749166.\n","[I 2024-12-13 19:24:56,191] Trial 10 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:25:09,337] Trial 11 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:25:22,681] Trial 12 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:25:23,692] Trial 13 finished with value: -3.253666321520158 and parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:25:38,355] Trial 14 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:25:48,062] Trial 15 finished with value: -3.258238696682704 and parameters: {'n_estimators': 450, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:25:53,472] Trial 16 finished with value: -3.4653228143845434 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:26:02,582] Trial 17 finished with value: -3.2875464515489625 and parameters: {'n_estimators': 450, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:26:08,142] Trial 18 finished with value: -3.330777198166108 and parameters: {'n_estimators': 250, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:26:16,812] Trial 19 finished with value: -3.2121919753249975 and parameters: {'n_estimators': 400, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:26:24,966] Trial 20 finished with value: -3.4647527850843414 and parameters: {'n_estimators': 450, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:26:38,422] Trial 21 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:26:51,611] Trial 22 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:27:00,424] Trial 23 finished with value: -3.258238696682704 and parameters: {'n_estimators': 450, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:27:10,449] Trial 24 finished with value: -3.2026559272999906 and parameters: {'n_estimators': 350, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:27:21,951] Trial 25 finished with value: -3.261612415345634 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:27:30,979] Trial 26 finished with value: -3.2296250599637446 and parameters: {'n_estimators': 450, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:27:40,284] Trial 27 finished with value: -3.257990520455505 and parameters: {'n_estimators': 400, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:27:45,142] Trial 28 finished with value: -3.1984635848893834 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:27:55,784] Trial 29 finished with value: -3.332199188173287 and parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:27:56,876] Trial 30 finished with value: -3.218436482083024 and parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:28:10,145] Trial 31 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:28:23,362] Trial 32 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:28:34,858] Trial 33 finished with value: -3.21275271454289 and parameters: {'n_estimators': 450, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:28:47,457] Trial 34 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:28:57,095] Trial 35 finished with value: -3.257990520455505 and parameters: {'n_estimators': 400, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:29:07,890] Trial 36 finished with value: -3.2127531019292004 and parameters: {'n_estimators': 450, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:29:16,970] Trial 37 finished with value: -3.3169303521074855 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:29:27,248] Trial 38 finished with value: -3.2152376135931853 and parameters: {'n_estimators': 400, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:29:33,045] Trial 39 finished with value: -3.3929100194520636 and parameters: {'n_estimators': 350, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:29:43,246] Trial 40 finished with value: -3.258238696682704 and parameters: {'n_estimators': 450, 'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:29:56,548] Trial 41 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:30:09,857] Trial 42 finished with value: -3.195506047225444 and parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: -3.195506047225444.\n","[I 2024-12-13 19:30:20,760] Trial 43 finished with value: -3.1944411303454823 and parameters: {'n_estimators': 450, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 43 with value: -3.1944411303454823.\n","[I 2024-12-13 19:30:32,277] Trial 44 finished with value: -3.1944411303454823 and parameters: {'n_estimators': 450, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 43 with value: -3.1944411303454823.\n","[I 2024-12-13 19:30:42,754] Trial 45 finished with value: -3.2152376135931853 and parameters: {'n_estimators': 400, 'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 43 with value: -3.1944411303454823.\n","[I 2024-12-13 19:30:52,648] Trial 46 finished with value: -3.258238696682704 and parameters: {'n_estimators': 450, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 43 with value: -3.1944411303454823.\n","[I 2024-12-13 19:30:55,152] Trial 47 finished with value: -3.3944278944883566 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 43 with value: -3.1944411303454823.\n","[I 2024-12-13 19:31:00,523] Trial 48 finished with value: -3.2187137762517777 and parameters: {'n_estimators': 250, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 43 with value: -3.1944411303454823.\n","[I 2024-12-13 19:31:06,562] Trial 49 finished with value: -3.3929091368143425 and parameters: {'n_estimators': 350, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 43 with value: -3.1944411303454823.\n"]},{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'n_estimators': 450, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}\n","\n","Training Metrics:\n","MAE=0.0009, MSE=0.0000, RMSE=0.0013, R²=1.0000, MAPE=0.2541%\n","\n","Validation Metrics:\n","MAE=0.1378, MSE=0.0247, RMSE=0.1571, R²=-3.1944, MAPE=7.7116%\n","\n","Test Metrics:\n","MAE=0.4061, MSE=0.1710, RMSE=0.4135, R²=-27.3318, MAPE=20.0282%\n"]}]},{"cell_type":"markdown","source":["Overfitting: The model is still overfitting the training data, as indicated by the perfect fit (R² = 1) on the training set and poor performance on the validation and test sets.\n","Generalization Issue: The validation and test metrics still show significant errors and negative R² values, signaling that the model is not generalizing well.\n","Hyperparameter Adjustments: While Optuna improved the hyperparameters, the selected configuration still leads to overfitting."],"metadata":{"id":"d9QxaO4lgnkl"}},{"cell_type":"markdown","source":["###**BOHB**"],"metadata":{"id":"BDpabPjnPPVj"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","from sklearn.datasets import make_regression\n","\n","# Define the ConfigSpace for hyperparameter optimization\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"n_estimators\", 50, 500, default_value=100))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"max_depth\", 5, 50, default_value=10))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"max_features\", 0.1, 1.0, default_value=0.5))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"min_samples_split\", 0.01, 0.1, default_value=0.02))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"min_samples_leaf\", 0.01, 0.1, default_value=0.02))\n","    return cs\n","\n","# Define the Worker for BOHB optimization\n","class RandomForestWorker(Worker):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","    def compute(self, config, budget, **kwargs):\n","        # Create the RandomForestRegressor with hyperparameters from BOHB\n","        model = RandomForestRegressor(\n","            n_estimators=config[\"n_estimators\"],\n","            max_depth=config[\"max_depth\"],\n","            max_features=config[\"max_features\"],\n","            min_samples_split=config[\"min_samples_split\"],\n","            min_samples_leaf=config[\"min_samples_leaf\"],\n","            random_state=42\n","        )\n","        model.fit(X_train, Y_train)\n","        Y_val_pred = model.predict(X_val)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Set up BOHB\n","NS = hpns.NameServer(run_id=\"randomforest_bohb\", host=\"127.0.0.1\", port=None)\n","NS.start()\n","\n","worker = RandomForestWorker(nameserver=\"127.0.0.1\", run_id=\"randomforest_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(\n","    configspace=get_config_space(),\n","    run_id=\"randomforest_bohb\",\n","    nameserver=\"127.0.0.1\",\n","    min_budget=1,\n","    max_budget=3  # Iterative refinement\n",")\n","\n","# Perform optimization\n","res = bohb.run(n_iterations=50)\n","\n","# Shutdown\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Retrieve the best configuration\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","# Build the model with the best hyperparameters\n","best_model = RandomForestRegressor(\n","    n_estimators=best_params[\"n_estimators\"],\n","    max_depth=best_params[\"max_depth\"],\n","    max_features=best_params[\"max_features\"],\n","    min_samples_split=best_params[\"min_samples_split\"],\n","    min_samples_leaf=best_params[\"min_samples_leaf\"],\n","    random_state=42\n",")\n","\n","best_model.fit(X_train, Y_train)\n","\n","# Predict and evaluate\n","Y_train_pred = best_model.predict(X_train)\n","Y_val_pred = best_model.predict(X_val)\n","Y_test_pred = best_model.predict(X_test)\n","\n","# Performance metrics calculation\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    return mae, mse, rmse, r2, mape\n","\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print the results\n","print(\"Best Parameters Found by BOHB:\")\n","print(best_params)\n","\n","print(\"\\nTraining set metrics:\")\n","print(f\"MAE: {train_metrics[0]}, MSE: {train_metrics[1]}, RMSE: {train_metrics[2]}, R²: {train_metrics[3]}, MAPE: {train_metrics[4]}\")\n","\n","print(\"\\nValidation set metrics:\")\n","print(f\"MAE: {val_metrics[0]}, MSE: {val_metrics[1]}, RMSE: {val_metrics[2]}, R²: {val_metrics[3]}, MAPE: {val_metrics[4]}\")\n","\n","print(\"\\nTest set metrics:\")\n","print(f\"MAE: {test_metrics[0]}, MSE: {test_metrics[1]}, RMSE: {test_metrics[2]}, R²: {test_metrics[3]}, MAPE: {test_metrics[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfrEBQRWOC4a","executionInfo":{"status":"ok","timestamp":1734348614279,"user_tz":-330,"elapsed":214864,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"3680904d-3edb-476d-99cf-58ef52fd533a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters Found by BOHB:\n","{'max_depth': 44, 'max_features': 0.1331040315185, 'min_samples_leaf': 0.0134845915735, 'min_samples_split': 0.0190895237016, 'n_estimators': 243}\n","\n","Training set metrics:\n","MAE: 0.008538951524444633, MSE: 0.00027390893466607664, RMSE: 0.016550194399646084, R²: 0.9984349939446888, MAPE: 0.0191005767241095\n","\n","Validation set metrics:\n","MAE: 0.18540480805151813, MSE: 0.04025648628418333, RMSE: 0.2006401910988507, R²: -5.844544586846098, MAPE: 0.10441007106927991\n","\n","Test set metrics:\n","MAE: 0.45444189407922575, MSE: 0.21255250548531232, RMSE: 0.4610341695420333, R²: -34.21955697523539, MAPE: 0.22428362209647368\n"]}]},{"cell_type":"markdown","source":["## XGBoost"],"metadata":{"id":"3vXqGreXhjYs"}},{"cell_type":"code","source":["!pip install xgboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dB9Z82fChvzI","executionInfo":{"status":"ok","timestamp":1741461379208,"user_tz":-330,"elapsed":2708,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"}},"outputId":"81c2117b-517e-46c7-890c-8f6c7c0a5407"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n"]}]},{"cell_type":"markdown","source":["###**Initial**"],"metadata":{"id":"P-WgjctUhuKW"}},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","import time\n","\n","# Initialize the XGBoost model\n","model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n","\n","# Training the model\n","start_time = time.time()\n","model.fit(X_train, Y_train)\n","\n","# Calculate training time\n","training_time = time.time() - start_time\n","\n","# Make predictions\n","Y_train_pred = model.predict(X_train)\n","Y_val_pred = model.predict(X_val)\n","Y_test_pred = model.predict(X_test)\n","\n","# Calculate metrics for training set\n","train_mae = mean_absolute_error(Y_train, Y_train_pred)\n","train_mse = mean_squared_error(Y_train, Y_train_pred)\n","train_rmse = np.sqrt(train_mse)\n","train_r2 = r2_score(Y_train, Y_train_pred)\n","train_mape = np.mean(np.abs((Y_train - Y_train_pred) / Y_train)) * 100\n","\n","# Calculate metrics for validation set\n","val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","val_mse = mean_squared_error(Y_val, Y_val_pred)\n","val_rmse = np.sqrt(val_mse)\n","val_r2 = r2_score(Y_val, Y_val_pred)\n","val_mape = np.mean(np.abs((Y_val - Y_val_pred) / Y_val)) * 100\n","\n","# Calculate metrics for test set\n","test_mae = mean_absolute_error(Y_test, Y_test_pred)\n","test_mse = mean_squared_error(Y_test, Y_test_pred)\n","test_rmse = np.sqrt(test_mse)\n","test_r2 = r2_score(Y_test, Y_test_pred)\n","test_mape = np.mean(np.abs((Y_test - Y_test_pred) / Y_test)) * 100\n","\n","# Print the results\n","print(f\"Training time: {training_time:.4f} seconds\\n\")\n","\n","print(\"\\nTraining Metrics:\")\n","print(f\"MAE={train_mae:.4f}, MSE={train_mse:.4f}, RMSE={train_rmse:.4f}, R²={train_r2:.4f}, MAPE={train_mape:.4f}%\")\n","\n","print(\"\\nValidation Metrics:\")\n","print(f\"MAE={val_mae:.4f}, MSE={val_mse:.4f}, RMSE={val_rmse:.4f}, R²={val_r2:.4f}, MAPE={val_mape:.4f}%\")\n","\n","print(\"\\nTest Metrics:\")\n","print(f\"MAE={test_mae:.4f}, MSE={test_mse:.4f}, RMSE={test_rmse:.4f}, R²={test_r2:.4f}, MAPE={test_mape:.4f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJuQvzyQedlP","executionInfo":{"status":"ok","timestamp":1734118712670,"user_tz":-330,"elapsed":1640,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"2c3b0219-8e2a-4353-e69f-b545344a4173"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training time: 0.8969 seconds\n","\n","\n","Training Metrics:\n","MAE=0.0024, MSE=0.0000, RMSE=0.0037, R²=0.9999, MAPE=0.6854%\n","\n","Validation Metrics:\n","MAE=0.1364, MSE=0.0242, RMSE=0.1555, R²=-3.1115, MAPE=7.6376%\n","\n","Test Metrics:\n","MAE=0.4043, MSE=0.1695, RMSE=0.4117, R²=-27.0890, MAPE=19.9384%\n"]}]},{"cell_type":"markdown","source":["Overfitting: As expected, the model is heavily overfitting the training data, as seen by the high training R² and the large drop in performance on validation and test sets.\n","Generalization Issue: The poor R², high MAE, and MAPE on the validation and test sets indicate that the model is not generalizing well to unseen data."],"metadata":{"id":"2B4xCHDkiEF-"}},{"cell_type":"markdown","source":["###**Early Stopping**"],"metadata":{"id":"ptLHlITYjIGO"}},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","\n","# Convert the dataset into DMatrix format\n","dtrain = xgb.DMatrix(X_train, label=Y_train)\n","dval = xgb.DMatrix(X_val, label=Y_val)\n","dtest = xgb.DMatrix(X_test, label=Y_test)\n","\n","# Set up the parameters for XGBoost\n","params = {\n","    'objective': 'reg:squarederror',\n","    'eval_metric': 'rmse',  # You can change this to 'mae', 'logloss', etc.\n","    'max_depth': 5,\n","    'learning_rate': 0.1,\n","    'n_estimators': 1000\n","}\n","\n","# List of evaluation sets\n","evals = [(dtrain, 'train'), (dval, 'eval')]\n","\n","# Start time for training\n","start_time = time.time()\n","\n","# Train the model with early stopping\n","model = xgb.train(params, dtrain, num_boost_round=1000, evals=evals, early_stopping_rounds=50, verbose_eval=False)\n","\n","# Calculate training time\n","training_time = time.time() - start_time\n","\n","# Make predictions using the best model\n","Y_train_pred = model.predict(dtrain)\n","Y_val_pred = model.predict(dval)\n","Y_test_pred = model.predict(dtest)\n","\n","# Calculate metrics for each set\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Metrics\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print metrics\n","print(f\"Training time: {training_time:.4f} seconds\")\n","print(\"\\nTraining Metrics: MAE=%.4f, MSE=%.4f, RMSE=%.4f, R²=%.4f, MAPE=%.4f%%\" % train_metrics)\n","print(\"\\nValidation Metrics: MAE=%.4f, MSE=%.4f, RMSE=%.4f, R²=%.4f, MAPE=%.4f%%\" % val_metrics)\n","print(\"\\nTest Metrics: MAE=%.4f, MSE=%.4f, RMSE=%.4f, R²=%.4f, MAPE=%.4f%%\" % test_metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSKHv8sMh5xF","executionInfo":{"status":"ok","timestamp":1734118925376,"user_tz":-330,"elapsed":1503,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"a9d39c48-8a00-4936-92e1-0d51e9cf690f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training time: 0.7951 seconds\n","\n","Training Metrics: MAE=0.0026, MSE=0.0000, RMSE=0.0039, R²=0.9999, MAPE=0.7377%\n","\n","Validation Metrics: MAE=0.1365, MSE=0.0242, RMSE=0.1556, R²=-3.1141, MAPE=7.6408%\n","\n","Test Metrics: MAE=0.4044, MSE=0.1696, RMSE=0.4118, R²=-27.0966, MAPE=19.9412%\n"]}]},{"cell_type":"markdown","source":["Overfitting: The model is overfitting the training data. It performs exceptionally well on the training set but fails to generalize to unseen data (validation and test sets).\n","Validation and Test Performance: The validation and test R² values being negative indicate that the model is worse than a simple mean prediction. The high MAPE values further support this, showing that the model's predictions are significantly off for unseen data."],"metadata":{"id":"xVlI1JZui-Bb"}},{"cell_type":"markdown","source":["###**GridSearchCV**"],"metadata":{"id":"h38GR_zyjMN6"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","import xgboost as xgb\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","\n","# Initialize the XGBoost model\n","model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n","\n","# Define hyperparameter grid\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [3, 5, 7, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'learning_rate': [0.01, 0.1, 0.2]\n","}\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n","\n","# Start grid search\n","start_time = time.time()\n","grid_search.fit(X_train, Y_train)\n","\n","# Calculate training time\n","training_time = time.time() - start_time\n","\n","# Best parameters and best score\n","print(f\"Best Parameters: {grid_search.best_params_}\")\n","print(f\"Best CV Score (Negative MSE): {grid_search.best_score_}\")\n","\n","# Make predictions using the best model\n","best_model = grid_search.best_estimator_\n","\n","Y_train_pred = best_model.predict(X_train)\n","Y_val_pred = best_model.predict(X_val)\n","Y_test_pred = best_model.predict(X_test)\n","\n","# Calculate metrics for each set\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print metrics\n","print(f\"Training time: {training_time:.4f} seconds\")\n","print(\"\\nTraining Metrics: MAE=%.4f, MSE=%.4f, RMSE=%.4f, R²=%.4f, MAPE=%.4f%%\" % train_metrics)\n","print(\"\\nValidation Metrics: MAE=%.4f, MSE=%.4f, RMSE=%.4f, R²=%.4f, MAPE=%.4f%%\" % val_metrics)\n","print(\"\\nTest Metrics: MAE=%.4f, MSE=%.4f, RMSE=%.4f, R²=%.4f, MAPE=%.4f%%\" % test_metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Y38KrAwiXrH","executionInfo":{"status":"ok","timestamp":1734119113316,"user_tz":-330,"elapsed":168310,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"3d2b4383-9400-4dff-bed5-08e855262a49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 324 candidates, totalling 972 fits\n","Best Parameters: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n","Best CV Score (Negative MSE): -0.0674339439943407\n","Training time: 167.9940 seconds\n","\n","Training Metrics: MAE=0.0027, MSE=0.0000, RMSE=0.0041, R²=0.9999, MAPE=0.8093%\n","\n","Validation Metrics: MAE=0.1304, MSE=0.0225, RMSE=0.1499, R²=-2.8190, MAPE=7.2956%\n","\n","Test Metrics: MAE=0.3979, MSE=0.1643, RMSE=0.4054, R²=-26.2284, MAPE=19.6166%\n"]}]},{"cell_type":"markdown","source":["Improvement in Hyperparameters: The choice of learning_rate = 0.2, max_depth = 3, and n_estimators = 300 seems to have marginally improved the model, as the validation R² is now closer to 0 than before.\n","Still Overfitting: Despite improvements in hyperparameter tuning, the model is still significantly overfitting to the training data. The performance on the validation and test sets remains much lower than on the training set.\n","Training Time: The training time has increased significantly (167.9940 seconds), likely due to the expanded search space during GridSearchCV. While this might yield better hyperparameters, it doesn't seem to solve the overfitting problem."],"metadata":{"id":"_0HVXIjcj7Rn"}},{"cell_type":"markdown","source":["####Learning Curve"],"metadata":{"id":"MwVSKVvAmoWQ"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import xgboost as xgb\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","# Prepare DMatrix\n","dtrain = xgb.DMatrix(X_train, label=Y_train)\n","dval = xgb.DMatrix(X_val, label=Y_val)\n","\n","# Set the parameters for XGBoost\n","params = {\n","    'objective': 'reg:squarederror',\n","    'eval_metric': 'rmse',\n","    'max_depth': 3,\n","    'learning_rate': 0.2,\n","    'n_estimators': 300\n","}\n","\n","# List of evaluation sets for monitoring\n","evals = [(dtrain, 'train'), (dval, 'eval')]\n","\n","# Train the model while storing performance metrics at each boosting round\n","evals_result = {}  # This will store the evaluation results\n","model = xgb.train(\n","    params,\n","    dtrain,\n","    num_boost_round=300,\n","    evals=evals,\n","    early_stopping_rounds=50,\n","    evals_result=evals_result,  # Capture the evaluation result\n","    verbose_eval=False\n",")\n","\n","# Plotting the learning curves\n","plt.figure(figsize=(10, 6))\n","plt.plot(evals_result['train']['rmse'], label='Train RMSE', color='blue')\n","plt.plot(evals_result['eval']['rmse'], label='Validation RMSE', color='red')\n","plt.xlabel('Number of Boosting Rounds')\n","plt.ylabel('RMSE')\n","plt.title('Learning Curve for XGBoost Model')\n","plt.legend(loc='upper right')\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"0-QKCmOliyxA","executionInfo":{"status":"ok","timestamp":1734119307460,"user_tz":-330,"elapsed":2513,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"173fc08b-9376-4df9-e79c-9b483d3daa6f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["###**Cross Validation**"],"metadata":{"id":"5XPy19jpmjyf"}},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","import xgboost as xgb\n","\n","param_dist = {\n","    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n","    'max_depth': [3, 5, 7, 9],\n","    'min_child_weight': [1, 3, 5],\n","    'subsample': [0.6, 0.7, 0.8, 1.0],\n","    'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n","    'n_estimators': [100, 200, 300, 400]\n","}\n","\n","xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n","\n","random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=100, cv=3, verbose=2)\n","random_search.fit(X_train, Y_train)\n","\n","print(f\"Best Hyperparameters: {random_search.best_params_}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mDgiePskEgG","executionInfo":{"status":"ok","timestamp":1734119644765,"user_tz":-330,"elapsed":93829,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"743fac3e-c351-4d28-b357-876e9ffb8da9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 100 candidates, totalling 300 fits\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.6; total time=   0.8s\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.6; total time=   1.0s\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.6; total time=   0.7s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.9s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.9s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=300, subsample=0.7; total time=   1.6s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=300, subsample=0.7; total time=   2.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=300, subsample=0.7; total time=   1.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=300, subsample=0.6; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=300, subsample=0.6; total time=   0.6s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=300, subsample=0.6; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.6; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.6; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=300, subsample=0.7; total time=   0.5s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=300, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=300, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=200, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=200, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=200, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=9, min_child_weight=1, n_estimators=400, subsample=0.6; total time=   0.7s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=9, min_child_weight=1, n_estimators=400, subsample=0.6; total time=   0.6s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=9, min_child_weight=1, n_estimators=400, subsample=0.6; total time=   0.8s\n","[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.6s\n","[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.5s\n","[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.9s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.8s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   1.5s\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=300, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=300, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=300, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=200, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=200, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=200, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=400, subsample=0.8; total time=   0.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=400, subsample=0.8; total time=   0.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=400, subsample=0.8; total time=   0.5s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   0.8s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.6; total time=   0.8s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.6; total time=   1.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.6; total time=   1.4s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.8; total time=   0.5s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.8; total time=   0.9s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.8; total time=   0.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.4s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.6; total time=   0.4s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.6; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.8; total time=   0.5s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.8; total time=   1.0s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.6s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.9s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.7s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   0.4s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=300, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=300, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=300, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=400, subsample=1.0; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=400, subsample=0.8; total time=   1.3s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=400, subsample=0.8; total time=   2.7s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=400, subsample=0.8; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=9, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=9, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=9, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=9, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, subsample=0.8; total time=   0.3s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=400, subsample=0.6; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.6s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.6s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.7; total time=   0.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=200, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=400, subsample=0.8; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.6; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.6; total time=   1.0s\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   1.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   0.8s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   1.0s\n","[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=400, subsample=0.7; total time=   0.4s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=400, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=400, subsample=0.7; total time=   0.3s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.6; total time=   0.4s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.6; total time=   0.4s\n","[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=400, subsample=0.6; total time=   0.5s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.6; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.7; total time=   0.2s\n","[CV] END colsample_bytree=0.6, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7; total time=   0.1s\n","[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7; total time=   0.2s\n","Best Hyperparameters: {'subsample': 0.8, 'n_estimators': 400, 'min_child_weight': 1, 'max_depth': 7, 'learning_rate': 0.2, 'colsample_bytree': 0.6}\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","import time\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","\n","# Prepare data\n","dtrain = xgb.DMatrix(X_train, label=Y_train)\n","dval = xgb.DMatrix(X_val, label=Y_val)\n","dtest = xgb.DMatrix(X_test, label=Y_test)\n","\n","# Set parameters for the model\n","params = {\n","    'subsample': 0.8,\n","    'n_estimators': 400,\n","    'min_child_weight': 1,\n","    'max_depth': 7,\n","    'learning_rate': 0.2,\n","    'colsample_bytree': 0.6,\n","    'objective': 'reg:squarederror',\n","    'eval_metric': 'rmse'\n","}\n","\n","# Prepare evals for early stopping\n","evals = [(dtrain, 'train'), (dval, 'eval')]\n","\n","# Train the model with early stopping\n","start_time = time.time()\n","model = xgb.train(params, dtrain, num_boost_round=1000, evals=evals, early_stopping_rounds=50, verbose_eval=False)\n","training_time = time.time() - start_time\n","\n","# Make predictions\n","train_pred = model.predict(dtrain)\n","val_pred = model.predict(dval)\n","test_pred = model.predict(dtest)\n","\n","# Calculate metrics\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = mean_squared_error(y_true, y_pred, squared=False)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Metrics for Training, Validation, and Test Sets\n","train_metrics = calculate_metrics(Y_train, train_pred)\n","val_metrics = calculate_metrics(Y_val, val_pred)\n","test_metrics = calculate_metrics(Y_test, test_pred)\n","\n","print(f\"Training time: {training_time:.4f} seconds\")\n","print(f\"Training Metrics: MAE={train_metrics[0]:.4f}, MSE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, R²={train_metrics[3]:.4f}, MAPE={train_metrics[4]:.4f}%\")\n","print(f\"Validation Metrics: MAE={val_metrics[0]:.4f}, MSE={val_metrics[1]:.4f}, RMSE={val_metrics[2]:.4f}, R²={val_metrics[3]:.4f}, MAPE={val_metrics[4]:.4f}%\")\n","print(f\"Test Metrics: MAE={test_metrics[0]:.4f}, MSE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, R²={test_metrics[3]:.4f}, MAPE={test_metrics[4]:.4f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQsJishFlG0y","executionInfo":{"status":"ok","timestamp":1734119878820,"user_tz":-330,"elapsed":1404,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"0868e164-181c-41de-c3d0-b2c2bd4517c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training time: 0.8974 seconds\n","Training Metrics: MAE=0.0035, MSE=0.0000, RMSE=0.0052, R²=0.9998, MAPE=1.0612%\n","Validation Metrics: MAE=0.1214, MSE=0.0200, RMSE=0.1414, R²=-2.3976, MAPE=6.7832%\n","Test Metrics: MAE=0.3880, MSE=0.1565, RMSE=0.3957, R²=-24.9387, MAPE=19.1245%\n"]}]},{"cell_type":"markdown","source":["Training Set: The model performs excellently on the training data with very low error metrics (MAE, MSE, RMSE, etc.), which suggests overfitting. The R² of 0.9998 means that almost all variance in the training data is explained by the model.\n","\n","Validation Set: The validation metrics show a notable drop in performance, with a negative R² value (-2.3976), which indicates that the model is not generalizing well to unseen data. The MAPE is lower than the test set, but it’s still considerable.\n","\n","Test Set: The model struggles on the test data with a high MAE and RMSE, indicating poor predictive performance. The R² is negative (-24.9387), which suggests the model is worse than a simple baseline (mean of the test labels). This is a classic sign of overfitting to the training data, where the model learned noise rather than generalizable patterns."],"metadata":{"id":"9eN_geNSmfXJ"}},{"cell_type":"markdown","source":["### Optuna"],"metadata":{"id":"Ooc1rYqHLKqF"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jc5HOrU9L_zu","executionInfo":{"status":"ok","timestamp":1741461404896,"user_tz":-330,"elapsed":11673,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"}},"outputId":"f320dc47-3624-4910-f263-b1e85ee79cb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import optuna\n","import time\n","\n","# Objective function for Optuna\n","def objective(trial):\n","    # Define the hyperparameter search space\n","    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n","    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n","    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n","    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n","\n","    # Initialize the XGBoost model\n","    model = xgb.XGBRegressor(\n","        n_estimators=n_estimators,\n","        learning_rate=learning_rate,\n","        max_depth=max_depth,\n","        subsample=subsample,\n","        colsample_bytree=colsample_bytree,\n","        objective='reg:squarederror',\n","        random_state=42\n","    )\n","\n","    # Train the model\n","    model.fit(X_train, Y_train)\n","    Y_val_pred = model.predict(X_val)\n","\n","    # Calculate validation MAE\n","    mae = mean_absolute_error(Y_val, Y_val_pred)\n","    return mae\n","\n","# Run Optuna Optimization\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","# Get the best hyperparameters from Optuna\n","best_params = study.best_params\n","\n","# Initialize the model with the best parameters\n","best_model = xgb.XGBRegressor(\n","    n_estimators=best_params[\"n_estimators\"],\n","    learning_rate=best_params[\"learning_rate\"],\n","    max_depth=best_params[\"max_depth\"],\n","    subsample=best_params[\"subsample\"],\n","    colsample_bytree=best_params[\"colsample_bytree\"],\n","    objective='reg:squarederror',\n","    random_state=42\n",")\n","\n","# Training the model with best hyperparameters\n","start_time = time.time()\n","best_model.fit(X_train, Y_train)\n","\n","# Calculate training time\n","training_time = time.time() - start_time\n","\n","# Make predictions\n","Y_train_pred = best_model.predict(X_train)\n","Y_val_pred = best_model.predict(X_val)\n","Y_test_pred = best_model.predict(X_test)\n","\n","# Function to calculate metrics\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Calculate metrics\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print the best hyperparameters\n","print(\"Best Parameters Found by Optuna:\")\n","print(best_params)\n","\n","# Print training time\n","print(f\"\\nTraining time: {training_time:.4f} seconds\\n\")\n","\n","# Print Training Metrics\n","print(\"\\nTraining Metrics:\")\n","print(f\"MAE: {train_metrics[0]:.4f}, MSE: {train_metrics[1]:.4f}, RMSE: {train_metrics[2]:.4f}, R²: {train_metrics[3]:.4f}, MAPE: {train_metrics[4]:.4f}%\")\n","\n","# Print Validation Metrics\n","print(\"\\nValidation Metrics:\")\n","print(f\"MAE: {val_metrics[0]:.4f}, MSE: {val_metrics[1]:.4f}, RMSE: {val_metrics[2]:.4f}, R²: {val_metrics[3]:.4f}, MAPE: {val_metrics[4]:.4f}%\")\n","\n","# Print Test Metrics\n","print(\"\\nTest Metrics:\")\n","print(f\"MAE: {test_metrics[0]:.4f}, MSE: {test_metrics[1]:.4f}, RMSE: {test_metrics[2]:.4f}, R²: {test_metrics[3]:.4f}, MAPE: {test_metrics[4]:.4f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUIf107uLNDL","executionInfo":{"status":"ok","timestamp":1741461454778,"user_tz":-330,"elapsed":43360,"user":{"displayName":"ANOUSHKA SHRIVASTAVA (RA2211031010135)","userId":"06391903211264765596"}},"outputId":"c1f618e6-98b9-431d-9a0e-0f885191123b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-03-08 19:13:22,317] A new study created in memory with name: no-name-88402536-3bab-4187-b6e9-07003855ffd1\n","[I 2025-03-08 19:13:26,743] Trial 0 finished with value: 0.12706238866431505 and parameters: {'n_estimators': 301, 'learning_rate': 0.055222357231106245, 'max_depth': 8, 'subsample': 0.6843004162938959, 'colsample_bytree': 0.50584289706436}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:27,604] Trial 1 finished with value: 0.14405589318316717 and parameters: {'n_estimators': 59, 'learning_rate': 0.12438317558211401, 'max_depth': 8, 'subsample': 0.8897104453578305, 'colsample_bytree': 0.920007418878428}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:27,795] Trial 2 finished with value: 0.13911545426779362 and parameters: {'n_estimators': 98, 'learning_rate': 0.24729850520577232, 'max_depth': 3, 'subsample': 0.823936003302411, 'colsample_bytree': 0.844936316027527}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:29,134] Trial 3 finished with value: 0.12800912277862728 and parameters: {'n_estimators': 384, 'learning_rate': 0.22969869778823937, 'max_depth': 3, 'subsample': 0.5831628895394438, 'colsample_bytree': 0.843688734960157}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:30,253] Trial 4 finished with value: 0.3270513802406399 and parameters: {'n_estimators': 153, 'learning_rate': 0.013982430397182015, 'max_depth': 3, 'subsample': 0.8317527411523811, 'colsample_bytree': 0.8412630994798771}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:30,589] Trial 5 finished with value: 0.13431142235272656 and parameters: {'n_estimators': 178, 'learning_rate': 0.09005336062931468, 'max_depth': 4, 'subsample': 0.9360553181026493, 'colsample_bytree': 0.7851488622773288}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:31,360] Trial 6 finished with value: 0.129718465103963 and parameters: {'n_estimators': 283, 'learning_rate': 0.1818722246725287, 'max_depth': 4, 'subsample': 0.7647527474513856, 'colsample_bytree': 0.8087341182658079}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:31,498] Trial 7 finished with value: 0.13548070010897367 and parameters: {'n_estimators': 59, 'learning_rate': 0.206401393258565, 'max_depth': 6, 'subsample': 0.532716341196966, 'colsample_bytree': 0.6748621031268097}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:36,984] Trial 8 finished with value: 0.13124280425403304 and parameters: {'n_estimators': 396, 'learning_rate': 0.1540508455172189, 'max_depth': 6, 'subsample': 0.779131798272265, 'colsample_bytree': 0.8900591236118609}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:37,566] Trial 9 finished with value: 0.14491737320639825 and parameters: {'n_estimators': 160, 'learning_rate': 0.05266258923899659, 'max_depth': 3, 'subsample': 0.9334386247809128, 'colsample_bytree': 0.7136910092707336}. Best is trial 0 with value: 0.12706238866431505.\n","[I 2025-03-08 19:13:41,899] Trial 10 finished with value: 0.12096716394632102 and parameters: {'n_estimators': 491, 'learning_rate': 0.2966402536722594, 'max_depth': 10, 'subsample': 0.6548288658416733, 'colsample_bytree': 0.5143325883136327}. Best is trial 10 with value: 0.12096716394632102.\n","[I 2025-03-08 19:13:45,300] Trial 11 finished with value: 0.12095816206317202 and parameters: {'n_estimators': 500, 'learning_rate': 0.29104427662504023, 'max_depth': 10, 'subsample': 0.6256781528261725, 'colsample_bytree': 0.5013464562723158}. Best is trial 11 with value: 0.12095816206317202.\n","[I 2025-03-08 19:13:49,581] Trial 12 finished with value: 0.12080542227746523 and parameters: {'n_estimators': 489, 'learning_rate': 0.2994754423324719, 'max_depth': 10, 'subsample': 0.6621254863846429, 'colsample_bytree': 0.5055193666103863}. Best is trial 12 with value: 0.12080542227746523.\n","[I 2025-03-08 19:13:50,223] Trial 13 finished with value: 0.12091936626987107 and parameters: {'n_estimators': 497, 'learning_rate': 0.2952642570532898, 'max_depth': 10, 'subsample': 0.6616771977887105, 'colsample_bytree': 0.6118172341866003}. Best is trial 12 with value: 0.12080542227746523.\n","[I 2025-03-08 19:13:50,683] Trial 14 finished with value: 0.12138018075095887 and parameters: {'n_estimators': 425, 'learning_rate': 0.2605253218897016, 'max_depth': 9, 'subsample': 0.7065027879346472, 'colsample_bytree': 0.6057654016231625}. Best is trial 12 with value: 0.12080542227746523.\n","[I 2025-03-08 19:13:51,148] Trial 15 finished with value: 0.12169176336490788 and parameters: {'n_estimators': 452, 'learning_rate': 0.2681366462129329, 'max_depth': 8, 'subsample': 0.5164932397581634, 'colsample_bytree': 0.596247114658432}. Best is trial 12 with value: 0.12080542227746523.\n","[I 2025-03-08 19:13:51,528] Trial 16 finished with value: 0.12033859937220502 and parameters: {'n_estimators': 346, 'learning_rate': 0.2063540445564002, 'max_depth': 9, 'subsample': 0.5887367340155221, 'colsample_bytree': 0.5810214455826184}. Best is trial 16 with value: 0.12033859937220502.\n","[I 2025-03-08 19:13:51,884] Trial 17 finished with value: 0.11976365612020533 and parameters: {'n_estimators': 329, 'learning_rate': 0.21307044167442735, 'max_depth': 9, 'subsample': 0.581154308612588, 'colsample_bytree': 0.5848984388420901}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:52,212] Trial 18 finished with value: 0.12020561345647926 and parameters: {'n_estimators': 342, 'learning_rate': 0.1871312971190288, 'max_depth': 7, 'subsample': 0.5955996180441936, 'colsample_bytree': 0.6611498265499368}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:52,428] Trial 19 finished with value: 0.12190707502668205 and parameters: {'n_estimators': 234, 'learning_rate': 0.14871523947476328, 'max_depth': 7, 'subsample': 0.5754902549659671, 'colsample_bytree': 0.6614485599515746}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:52,757] Trial 20 finished with value: 0.13169780487850055 and parameters: {'n_estimators': 332, 'learning_rate': 0.18938777230520779, 'max_depth': 7, 'subsample': 0.724531485009196, 'colsample_bytree': 0.6999530678950607}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:53,144] Trial 21 finished with value: 0.12068648446086032 and parameters: {'n_estimators': 344, 'learning_rate': 0.20365400131934358, 'max_depth': 9, 'subsample': 0.579445712069708, 'colsample_bytree': 0.5654284655641717}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:53,435] Trial 22 finished with value: 0.12051463320214922 and parameters: {'n_estimators': 242, 'learning_rate': 0.225705781107666, 'max_depth': 9, 'subsample': 0.618903642685968, 'colsample_bytree': 0.5634685468492289}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:53,681] Trial 23 finished with value: 0.12119123663478175 and parameters: {'n_estimators': 357, 'learning_rate': 0.18794658238542264, 'max_depth': 5, 'subsample': 0.5031441458609257, 'colsample_bytree': 0.6438912886454771}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:54,057] Trial 24 finished with value: 0.1269335599091855 and parameters: {'n_estimators': 321, 'learning_rate': 0.12833073258000316, 'max_depth': 8, 'subsample': 0.5550917042023926, 'colsample_bytree': 0.7281859640682082}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:54,494] Trial 25 finished with value: 0.12107168100557611 and parameters: {'n_estimators': 376, 'learning_rate': 0.2289443077468472, 'max_depth': 9, 'subsample': 0.6100640406493312, 'colsample_bytree': 0.5641534693885135}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:54,753] Trial 26 finished with value: 0.12800830649248165 and parameters: {'n_estimators': 253, 'learning_rate': 0.17111069721747607, 'max_depth': 7, 'subsample': 0.6188571041448776, 'colsample_bytree': 0.985910433697089}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:55,069] Trial 27 finished with value: 0.1222969163832741 and parameters: {'n_estimators': 413, 'learning_rate': 0.21574748307506492, 'max_depth': 6, 'subsample': 0.5396125545100642, 'colsample_bytree': 0.6347539476367745}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:55,386] Trial 28 finished with value: 0.12988952246851196 and parameters: {'n_estimators': 207, 'learning_rate': 0.13213955030776545, 'max_depth': 9, 'subsample': 0.7257506632138124, 'colsample_bytree': 0.7688723927884793}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:55,698] Trial 29 finished with value: 0.12129425903777749 and parameters: {'n_estimators': 296, 'learning_rate': 0.10375735595757754, 'max_depth': 8, 'subsample': 0.6917646994034062, 'colsample_bytree': 0.5540643141963796}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:55,923] Trial 30 finished with value: 0.13331330534379268 and parameters: {'n_estimators': 311, 'learning_rate': 0.16546719718203384, 'max_depth': 8, 'subsample': 0.9963507341227681, 'colsample_bytree': 0.6766505013485042}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:56,242] Trial 31 finished with value: 0.1203169429782302 and parameters: {'n_estimators': 273, 'learning_rate': 0.2370276358824309, 'max_depth': 9, 'subsample': 0.6093307361327591, 'colsample_bytree': 0.5420382473519012}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:56,583] Trial 32 finished with value: 0.11988510790110506 and parameters: {'n_estimators': 269, 'learning_rate': 0.26285107937188595, 'max_depth': 9, 'subsample': 0.5901675932262411, 'colsample_bytree': 0.5373468398489349}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:56,842] Trial 33 finished with value: 0.12033405837429384 and parameters: {'n_estimators': 282, 'learning_rate': 0.24883660141866912, 'max_depth': 7, 'subsample': 0.646178038618764, 'colsample_bytree': 0.5370506304742925}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:57,135] Trial 34 finished with value: 0.12012205180308853 and parameters: {'n_estimators': 263, 'learning_rate': 0.2707334981289952, 'max_depth': 8, 'subsample': 0.5436477868774312, 'colsample_bytree': 0.5377003662152393}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:57,380] Trial 35 finished with value: 0.12158344797119833 and parameters: {'n_estimators': 201, 'learning_rate': 0.26901222117668255, 'max_depth': 8, 'subsample': 0.5541345413985971, 'colsample_bytree': 0.6274508316612178}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:57,697] Trial 36 finished with value: 0.12034797787290426 and parameters: {'n_estimators': 263, 'learning_rate': 0.2787476002661675, 'max_depth': 8, 'subsample': 0.501336459134409, 'colsample_bytree': 0.5318411202783293}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:57,907] Trial 37 finished with value: 0.12098118574095053 and parameters: {'n_estimators': 218, 'learning_rate': 0.25186511728276184, 'max_depth': 7, 'subsample': 0.5625131839209974, 'colsample_bytree': 0.5952550697266171}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:58,128] Trial 38 finished with value: 0.12125802250543045 and parameters: {'n_estimators': 303, 'learning_rate': 0.24144985622430587, 'max_depth': 5, 'subsample': 0.820614772032304, 'colsample_bytree': 0.6573770981768926}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:58,522] Trial 39 finished with value: 0.12208988845732952 and parameters: {'n_estimators': 362, 'learning_rate': 0.2792401042762692, 'max_depth': 8, 'subsample': 0.5303062287311187, 'colsample_bytree': 0.6202474323315647}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:58,696] Trial 40 finished with value: 0.1238012044319683 and parameters: {'n_estimators': 117, 'learning_rate': 0.22146658185832102, 'max_depth': 10, 'subsample': 0.5831804133490073, 'colsample_bytree': 0.5845223804179298}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:59,023] Trial 41 finished with value: 0.12000092058869705 and parameters: {'n_estimators': 274, 'learning_rate': 0.23856465209164965, 'max_depth': 9, 'subsample': 0.5943489161549927, 'colsample_bytree': 0.5185354557103015}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:59,388] Trial 42 finished with value: 0.12006452686931034 and parameters: {'n_estimators': 294, 'learning_rate': 0.25417461143767894, 'max_depth': 9, 'subsample': 0.5983671666988765, 'colsample_bytree': 0.5285190696189296}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:13:59,756] Trial 43 finished with value: 0.12124649335658319 and parameters: {'n_estimators': 183, 'learning_rate': 0.25550586431288774, 'max_depth': 9, 'subsample': 0.5459140226695438, 'colsample_bytree': 0.5268293463191882}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:14:01,090] Trial 44 finished with value: 0.12056229657042494 and parameters: {'n_estimators': 291, 'learning_rate': 0.27128970861493495, 'max_depth': 10, 'subsample': 0.6373112956589176, 'colsample_bytree': 0.5013224474977231}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:14:02,491] Trial 45 finished with value: 0.12074687863350576 and parameters: {'n_estimators': 229, 'learning_rate': 0.23716919404158907, 'max_depth': 9, 'subsample': 0.6854868698673714, 'colsample_bytree': 0.5272286417053579}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:14:03,260] Trial 46 finished with value: 0.11997736839429382 and parameters: {'n_estimators': 260, 'learning_rate': 0.28241636364203443, 'max_depth': 10, 'subsample': 0.5717024242598273, 'colsample_bytree': 0.5702836072777365}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:14:03,681] Trial 47 finished with value: 0.11979902886814876 and parameters: {'n_estimators': 318, 'learning_rate': 0.289215008071996, 'max_depth': 10, 'subsample': 0.6650256124340245, 'colsample_bytree': 0.5749536420191279}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:14:04,117] Trial 48 finished with value: 0.12032885986475815 and parameters: {'n_estimators': 329, 'learning_rate': 0.28047833893162327, 'max_depth': 10, 'subsample': 0.6664832953431388, 'colsample_bytree': 0.5775852695874273}. Best is trial 17 with value: 0.11976365612020533.\n","[I 2025-03-08 19:14:04,589] Trial 49 finished with value: 0.12135185677453816 and parameters: {'n_estimators': 384, 'learning_rate': 0.28266686258447243, 'max_depth': 10, 'subsample': 0.7900714004599699, 'colsample_bytree': 0.6103019268428743}. Best is trial 17 with value: 0.11976365612020533.\n"]},{"output_type":"stream","name":"stdout","text":["Best Parameters Found by Optuna:\n","{'n_estimators': 329, 'learning_rate': 0.21307044167442735, 'max_depth': 9, 'subsample': 0.581154308612588, 'colsample_bytree': 0.5848984388420901}\n","\n","Training time: 0.3293 seconds\n","\n","\n","Training Metrics:\n","MAE: 0.0031, MSE: 0.0000, RMSE: 0.0046, R²: 0.9999, MAPE: 0.9175%\n","\n","Validation Metrics:\n","MAE: 0.1198, MSE: 0.0195, RMSE: 0.1398, R²: -2.3216, MAPE: 6.6889%\n","\n","Test Metrics:\n","MAE: 0.3861, MSE: 0.1551, RMSE: 0.3938, R²: -24.6994, MAPE: 19.0317%\n"]}]},{"cell_type":"markdown","source":["###**BOHB**"],"metadata":{"id":"TtwxgGDiSNz0"}},{"cell_type":"code","source":["!pip install hpbandster\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjzJmZ5alx_s","executionInfo":{"status":"ok","timestamp":1734120205193,"user_tz":-330,"elapsed":6572,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"777f511b-df5c-4218-bd98-0eeb785de763"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: hpbandster in /usr/local/lib/python3.10/dist-packages (0.7.4)\n","Requirement already satisfied: Pyro4 in /usr/local/lib/python3.10/dist-packages (from hpbandster) (4.82)\n","Requirement already satisfied: serpent in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.41)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.26.4)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.13.1)\n","Requirement already satisfied: netifaces in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.11.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (3.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (10.5.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n"]}]},{"cell_type":"code","source":["!pip install hyperopt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9S-TOyWnkte","executionInfo":{"status":"ok","timestamp":1734120227910,"user_tz":-330,"elapsed":8791,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"741a2059-dff6-449f-9cfd-2c34bfd21c07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.13.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.17.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.4.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.6)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.1.0)\n","Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TmGlruzMozum"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","from sklearn.datasets import make_regression\n","\n","\n","# Define the ConfigSpace for hyperparameter optimization\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"n_estimators\", 50, 500, default_value=100))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"learning_rate\", 0.01, 0.3, default_value=0.1))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"max_depth\", 3, 10, default_value=6))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"subsample\", 0.5, 1.0, default_value=0.8))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"colsample_bytree\", 0.5, 1.0, default_value=0.8))\n","    return cs\n","\n","# Define the Worker for BOHB optimization\n","class XGBoostWorker(Worker):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","    def compute(self, config, budget, **kwargs):\n","        model = xgb.XGBRegressor(\n","            n_estimators=config[\"n_estimators\"],\n","            learning_rate=config[\"learning_rate\"],\n","            max_depth=config[\"max_depth\"],\n","            subsample=config[\"subsample\"],\n","            colsample_bytree=config[\"colsample_bytree\"],\n","            random_state=42\n","        )\n","        model.fit(X_train, Y_train)\n","        Y_val_pred = model.predict(X_val)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Set up BOHB\n","NS = hpns.NameServer(run_id=\"xgboost_bohb\", host=\"127.0.0.1\", port=None)\n","NS.start()\n","\n","worker = XGBoostWorker(nameserver=\"127.0.0.1\", run_id=\"xgboost_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(\n","    configspace=get_config_space(),\n","    run_id=\"xgboost_bohb\",\n","    nameserver=\"127.0.0.1\",\n","    min_budget=1,\n","    max_budget=3  # Iterative refinement\n",")\n","\n","# Perform optimization\n","res = bohb.run(n_iterations=50)\n","\n","# Shutdown\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Retrieve the best configuration\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","# Build the model with the best hyperparameters\n","best_model = xgb.XGBRegressor(\n","    n_estimators=best_params[\"n_estimators\"],\n","    learning_rate=best_params[\"learning_rate\"],\n","    max_depth=best_params[\"max_depth\"],\n","    subsample=best_params[\"subsample\"],\n","    colsample_bytree=best_params[\"colsample_bytree\"],\n","    random_state=42\n",")\n","\n","best_model.fit(X_train, Y_train)\n","\n","# Predict and evaluate\n","Y_train_pred = best_model.predict(X_train)\n","Y_val_pred = best_model.predict(X_val)\n","Y_test_pred = best_model.predict(X_test)\n","\n","# Performance metrics calculation\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    return mae, mse, rmse, r2, mape\n","\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print the results\n","print(\"Best Parameters Found by BOHB:\")\n","print(best_params)\n","\n","print(\"\\nTraining set metrics:\")\n","print(f\"MAE: {train_metrics[0]}, MSE: {train_metrics[1]}, RMSE: {train_metrics[2]}, R²: {train_metrics[3]}, MAPE: {train_metrics[4]}\")\n","\n","print(\"\\nValidation set metrics:\")\n","print(f\"MAE: {val_metrics[0]}, MSE: {val_metrics[1]}, RMSE: {val_metrics[2]}, R²: {val_metrics[3]}, MAPE: {val_metrics[4]}\")\n","\n","print(\"\\nTest set metrics:\")\n","print(f\"MAE: {test_metrics[0]}, MSE: {test_metrics[1]}, RMSE: {test_metrics[2]}, R²: {test_metrics[3]}, MAPE: {test_metrics[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QaHgjP8ARKjb","executionInfo":{"status":"ok","timestamp":1734349295007,"user_tz":-330,"elapsed":80266,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"5c0290f2-cdf0-4a5b-dad0-dc4d82a1bc9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters Found by BOHB:\n","{'colsample_bytree': 0.5112831376594, 'learning_rate': 0.2693315399863, 'max_depth': 5, 'n_estimators': 314, 'subsample': 0.7894433027817}\n","\n","Training set metrics:\n","MAE: 0.003212111401825395, MSE: 2.281315372705884e-05, RMSE: 0.004776311728421716, R²: 0.99986965476768, MAPE: 0.00982273540031956\n","\n","Validation set metrics:\n","MAE: 0.11970676982419194, MSE: 0.019513103928330975, RMSE: 0.13968931214781957, R²: -2.317684234098141, MAPE: 0.0668585931993794\n","\n","Test set metrics:\n","MAE: 0.3859855505044925, MSE: 0.15501991558925426, RMSE: 0.39372568571183447, R²: -24.686513254341275, MAPE: 0.19026736861832225\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1NhOLn-oZnqGNDPvM_Gy3KWNMAh2DypGX","timestamp":1734019638652},{"file_id":"18Gu3lcn4Li66MaqYzsvOVlNEV8a_ArEE","timestamp":1733939530379}],"gpuType":"T4","collapsed_sections":["5ebGneEwoKEe","aj0JYwhXNyOI","OMJTwHjXSyEB","-RX7QdECgt3T","BDpabPjnPPVj","ptLHlITYjIGO","h38GR_zyjMN6","5XPy19jpmjyf","TtwxgGDiSNz0"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}