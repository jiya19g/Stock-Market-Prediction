{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"15gPAmO_07XF9Wekf99lrTtNUVLC3U2-H","timestamp":1743328182176}],"collapsed_sections":["6MM-OJGXCCK2","MFeTjGxUCEpk","31Yn1i4585D5","M10Oo7qqLZgm","uUCh_YB9Vf7S","qUH36NvmtM2G","PnPul0h2lqPU","UA4RDkuZXHto"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Initial"],"metadata":{"id":"6MM-OJGXCCK2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7gOgVN8kW8r"},"outputs":[],"source":["# Importing necessary libraries for data analysis and manipulation\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# For handling warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93jX7ecsBi-o","executionInfo":{"status":"ok","timestamp":1743251810105,"user_tz":-330,"elapsed":21860,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"89a45516-17a8-440a-877d-215c27e2900f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["df_aapl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/stocks/AAPL.csv')"],"metadata":{"id":"SqkQs1FVBnLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from scipy.stats import boxcox\n","\n","df_aapl['Close_log'] = np.log(df_aapl['Close'] + 1)\n","df_aapl['Close_sqrt'] = np.sqrt(df_aapl['Close'])\n","df_aapl['Close_boxcox'], _ = boxcox(df_aapl['Close'] + 1)\n"],"metadata":{"id":"ttF4WNTkBxms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","skew_original = df_aapl['Close'].skew()\n","skew_log = df_aapl['Close_log'].skew()\n","skew_sqrt = df_aapl['Close_sqrt'].skew()\n","skew_boxcox = pd.Series(df_aapl['Close_boxcox']).skew()\n","\n","print(f\"Original Skewness: {skew_original}\")\n","print(f\"Log Transformation Skewness: {skew_log}\")\n","print(f\"Square Root Transformation Skewness: {skew_sqrt}\")\n","print(f\"Box-Cox Transformation Skewness: {skew_boxcox}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7rMhFf7B0Rr","executionInfo":{"status":"ok","timestamp":1743251811676,"user_tz":-330,"elapsed":33,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"70bb83ce-be56-4fac-a628-230bd75107aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Skewness: 2.5045276102319933\n","Log Transformation Skewness: 0.8535555176510303\n","Square Root Transformation Skewness: 1.6211545809555206\n","Box-Cox Transformation Skewness: 0.43527466713563334\n"]}]},{"cell_type":"code","source":["\n","df_aapl['Open_log'] = np.log(df_aapl['Open'])\n","df_aapl['High_log'] = np.log(df_aapl['High'])\n","df_aapl['Low_log'] = np.log(df_aapl['Low'])\n","df_aapl['Adj Close_log'] = np.log(df_aapl['Adj Close'])\n","df_aapl['Volume_log'] = np.log(df_aapl['Volume'])\n","\n","\n","df_aapl['Open_sqrt'] = np.sqrt(df_aapl['Open'])\n","df_aapl['High_sqrt'] = np.sqrt(df_aapl['High'])\n","df_aapl['Low_sqrt'] = np.sqrt(df_aapl['Low'])\n","df_aapl['Adj Close_sqrt'] = np.sqrt(df_aapl['Adj Close'])\n","df_aapl['Volume_sqrt'] = np.sqrt(df_aapl['Volume'])\n","\n","from scipy.stats import boxcox\n","df_aapl['Open_boxcox'], _ = boxcox(df_aapl['Open'])\n","df_aapl['High_boxcox'], _ = boxcox(df_aapl['High'])\n","df_aapl['Low_boxcox'], _ = boxcox(df_aapl['Low'])\n","df_aapl['Adj Close_boxcox'], _ = boxcox(df_aapl['Adj Close'])"],"metadata":{"id":"FEyv3BNQB3TB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","skewness_before = df_aapl[['Open', 'High', 'Low', 'Adj Close', 'Volume']].skew()\n","skewness_after = df_aapl[['Open_log', 'High_log', 'Low_log', 'Adj Close_log',\n","                          'Open_sqrt', 'High_sqrt', 'Low_sqrt', 'Adj Close_sqrt', 'Volume_sqrt',\n","                          'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox']].skew()\n","\n","print(\"Skewness Before Transformation:\\n\", skewness_before)\n","print(\"\\nSkewness After Transformation:\\n\", skewness_after)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8CzGUPAB4vn","executionInfo":{"status":"ok","timestamp":1743251813441,"user_tz":-330,"elapsed":73,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"e4a28985-73c5-48ba-a14e-08d1f318bc00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness Before Transformation:\n"," Open         2.504632\n","High         2.502208\n","Low          2.506714\n","Adj Close    2.550677\n","Volume       3.565699\n","dtype: float64\n","\n","Skewness After Transformation:\n"," Open_log            0.482872\n","High_log            0.481997\n","Low_log             0.484246\n","Adj Close_log       0.494009\n","Open_sqrt           1.620771\n","High_sqrt           1.621456\n","Low_sqrt            1.620661\n","Adj Close_sqrt      1.679402\n","Volume_sqrt         1.299776\n","Open_boxcox         0.181226\n","High_boxcox         0.179749\n","Low_boxcox          0.182882\n","Adj Close_boxcox    0.180085\n","dtype: float64\n"]}]},{"cell_type":"code","source":["from scipy import stats\n","\n","df_aapl['Open_boxcox'], _ = stats.boxcox(df_aapl['Open'] + 1)\n","df_aapl['High_boxcox'], _ = stats.boxcox(df_aapl['High'] + 1)\n","df_aapl['Low_boxcox'], _ = stats.boxcox(df_aapl['Low'] + 1)\n","df_aapl['Adj Close_boxcox'], _ = stats.boxcox(df_aapl['Adj Close'] + 1)\n","df_aapl['Close_boxcox'], _ = stats.boxcox(df_aapl['Close'] + 1)\n","\n","skewness_after_boxcox = df_aapl[['Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox', 'Close_boxcox']].skew()\n","\n","print(\"Skewness After Box-Cox Transformation:\")\n","print(skewness_after_boxcox)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSm4tARXB8Ys","executionInfo":{"status":"ok","timestamp":1743251815762,"user_tz":-330,"elapsed":2320,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"d7d422b0-28b8-4673-81a2-d5afb40894a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness After Box-Cox Transformation:\n","Open_boxcox         0.435237\n","High_boxcox         0.433381\n","Low_boxcox          0.437331\n","Adj Close_boxcox    0.458762\n","Close_boxcox        0.435275\n","dtype: float64\n"]}]},{"cell_type":"code","source":["\n","df_aapl_cleaned = df_aapl[['Date', 'Open', 'High', 'Low', 'Adj Close', 'Close', 'Volume',\n","                           'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox',\n","                           'Close_boxcox']]\n","\n","print(df_aapl_cleaned.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8jxBy1MB-AY","executionInfo":{"status":"ok","timestamp":1743251815892,"user_tz":-330,"elapsed":128,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"6fc2e30f-1130-4dd7-93e3-f5d6f64adfc8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["         Date      Open      High       Low  Adj Close     Close     Volume  \\\n","0  1980-12-12  0.128348  0.128906  0.128348   0.098943  0.128348  469033600   \n","1  1980-12-15  0.122210  0.122210  0.121652   0.093781  0.121652  175884800   \n","2  1980-12-16  0.113281  0.113281  0.112723   0.086898  0.112723  105728000   \n","3  1980-12-17  0.115513  0.116071  0.115513   0.089049  0.115513   86441600   \n","4  1980-12-18  0.118862  0.119420  0.118862   0.091630  0.118862   73449600   \n","\n","   Open_boxcox  High_boxcox  Low_boxcox  Adj Close_boxcox  Close_boxcox  \n","0     0.117689     0.118173    0.117674          0.092374      0.117689  \n","1     0.112503     0.112516    0.112016          0.087857      0.112030  \n","2     0.104886     0.104897    0.104395          0.081785      0.104407  \n","3     0.106798     0.107287    0.106786          0.083688      0.106798  \n","4     0.109657     0.110145    0.109644          0.085966      0.109657  \n"]}]},{"cell_type":"markdown","source":["#Train, Validation and Testing"],"metadata":{"id":"MFeTjGxUCEpk"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df_aapl_cleaned[['Open_boxcox', 'High_boxcox', 'Low_boxcox']]\n","Y = df_aapl_cleaned['Close_boxcox']\n","\n","X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, shuffle=False)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, shuffle=False)\n","\n","print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCaInU2aCJZJ","executionInfo":{"status":"ok","timestamp":1743251821430,"user_tz":-330,"elapsed":280,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"6bd320fb-67cf-46fb-b1a3-68b4bfbaf569"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (7736, 3), Validation set: (1658, 3), Test set: (1658, 3)\n"]}]},{"cell_type":"markdown","source":["# Extra tree"],"metadata":{"id":"Pk2BtMJuCPi9"}},{"cell_type":"markdown","source":["## Initial"],"metadata":{"id":"31Yn1i4585D5"}},{"cell_type":"code","source":["import time\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n","from sklearn.ensemble import ExtraTreesRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Enable GPU for TensorFlow\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","        print(\"GPU activated for TensorFlow!\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Function to define and train a Bi-LSTM model on GPU\n","def train_bi_lstm(X_train, Y_train, X_val, Y_val, layers):\n","    with tf.device('/GPU:0'):\n","        model = Sequential()\n","        model.add(Bidirectional(LSTM(64, return_sequences=(layers > 1)), input_shape=(X_train.shape[1], 1)))\n","        for _ in range(layers - 1):\n","            model.add(Bidirectional(LSTM(64, return_sequences=(_ < layers - 2))))\n","        model.add(Dense(1))\n","\n","        model.compile(optimizer='adam', loss='mse')\n","        model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=16, verbose=0)\n","        return model\n","\n","# Reshaping input for LSTM\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Initialize timing dictionary\n","times = {}\n","\n","# Train Phase (includes training all Bi-LSTMs and Extra Trees)\n","start_train_time = time.time()\n","\n","# Train 2, 3, and 5-layer Bi-LSTM models\n","bi_lstm_models = {}\n","bi_lstm_predictions = {}\n","\n","for layers in [2, 3, 5]:\n","    model = train_bi_lstm(X_train_r, Y_train, X_val_r, Y_val, layers)\n","    bi_lstm_models[layers] = model\n","\n","# Generate predictions from all Bi-LSTM models\n","for layers in [2, 3, 5]:\n","    Y_train_pred = bi_lstm_models[layers].predict(X_train_r)\n","    Y_val_pred = bi_lstm_models[layers].predict(X_val_r)\n","    Y_test_pred = bi_lstm_models[layers].predict(X_test_r)\n","    bi_lstm_predictions[layers] = (Y_train_pred, Y_val_pred, Y_test_pred)\n","\n","# Prepare input for Extra Trees\n","X_train_et = np.column_stack([bi_lstm_predictions[layers][0] for layers in [2, 3, 5]])\n","X_val_et = np.column_stack([bi_lstm_predictions[layers][1] for layers in [2, 3, 5]])\n","X_test_et = np.column_stack([bi_lstm_predictions[layers][2] for layers in [2, 3, 5]])\n","\n","# Train Extra Trees model\n","et_model = ExtraTreesRegressor(n_estimators=100, max_depth=None, min_samples_split=2,\n","                              min_samples_leaf=1, random_state=42, n_jobs=-1)\n","et_model.fit(X_train_et, Y_train)\n","\n","times['Total Train Time'] = time.time() - start_train_time\n","\n","# Validation Phase\n","start_val_time = time.time()\n","Y_val_pred_et = et_model.predict(X_val_et)\n","times['Total Validate Time'] = time.time() - start_val_time\n","\n","# Test Phase\n","start_test_time = time.time()\n","Y_test_pred_et = et_model.predict(X_test_et)\n","times['Total Test Time'] = time.time() - start_test_time\n","\n","# Function to calculate metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Compute and print metrics\n","metrics_train = compute_metrics(Y_train, et_model.predict(X_train_et))\n","metrics_val = compute_metrics(Y_val, Y_val_pred_et)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_et)\n","\n","print(\"\\nPerformance Metrics:\")\n","print(f\"Train Metrics: MAE={metrics_train[0]:.4f}, MSE={metrics_train[1]:.4f}, RMSE={metrics_train[2]:.4f}, R²={metrics_train[3]:.4f}, MAPE={metrics_train[4]:.2f}%\")\n","print(f\"Validation Metrics: MAE={metrics_val[0]:.4f}, MSE={metrics_val[1]:.4f}, RMSE={metrics_val[2]:.4f}, R²={metrics_val[3]:.4f}, MAPE={metrics_val[4]:.2f}%\")\n","print(f\"Test Metrics: MAE={metrics_test[0]:.4f}, MSE={metrics_test[1]:.4f}, RMSE={metrics_test[2]:.4f}, R²={metrics_test[3]:.4f}, MAPE={metrics_test[4]:.2f}%\")\n","\n","# Print timing information\n","print(\"\\nTiming Information:\")\n","for phase, t in times.items():\n","    print(f\"{phase}: {t:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-A4tWseQCSHW","executionInfo":{"status":"ok","timestamp":1743225526757,"user_tz":-330,"elapsed":515697,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"7de1a439-5731-4884-f330-6f6711206adb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU activated for TensorFlow!\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\n","Performance Metrics:\n","Train Metrics: MAE=0.0001, MSE=0.0000, RMSE=0.0003, R²=1.0000, MAPE=0.03%\n","Validation Metrics: MAE=0.1352, MSE=0.0239, RMSE=0.1546, R²=-3.0652, MAPE=7.56%\n","Test Metrics: MAE=0.4034, MSE=0.1687, RMSE=0.4108, R²=-26.9577, MAPE=19.89%\n","\n","Timing Information:\n","Total Train Time: 510.80 seconds\n","Total Validate Time: 0.03 seconds\n","Total Test Time: 0.03 seconds\n"]}]},{"cell_type":"markdown","source":["## Optuna"],"metadata":{"id":"M10Oo7qqLZgm"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhqC08wbIYOF","executionInfo":{"status":"ok","timestamp":1743234512350,"user_tz":-330,"elapsed":3158,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"a59a43a3-c56c-4685-b1bf-2f8714e8acbc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n","from sklearn.ensemble import ExtraTreesRegressor\n","import optuna\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","\n","# Early stopping callback\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Function to train Bi-LSTM model\n","def train_bi_lstm(X_train, Y_train, X_val, Y_val, units, layers, learning_rate, batch_size, epochs):\n","    model = keras.Sequential()\n","\n","    for _ in range(layers - 1):  # All except last layer have return_sequences=True\n","        model.add(Bidirectional(LSTM(units, return_sequences=True)))\n","\n","    model.add(Bidirectional(LSTM(units)))  # Last LSTM layer\n","    model.add(Dense(1))  # Output layer\n","\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n","\n","    # Early Stopping Callback\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","\n","    start_time = time.time()  # Start time tracking\n","    history = model.fit(X_train, Y_train,\n","                        validation_data=(X_val, Y_val),\n","                        epochs=epochs,\n","                        batch_size=batch_size,\n","                        verbose=0,\n","                        callbacks=[early_stopping])\n","    lstm_train_time = time.time() - start_time  # End time tracking\n","\n","    return model, history, lstm_train_time\n","\n","# Objective function for Optuna\n","def objective(trial):\n","    units = trial.suggest_int(\"lstm_units\", 32, 128, step=16)\n","    layers = trial.suggest_categorical(\"lstm_layers\", [2, 3, 5])\n","    learning_rate = trial.suggest_loguniform(\"lstm_learning_rate\", 1e-4, 1e-2)\n","    batch_size = trial.suggest_categorical(\"lstm_batch_size\", [16, 32, 64])\n","    epochs = trial.suggest_int(\"lstm_epochs\", 10, 50, step=10)\n","\n","    # Reshape input for LSTM\n","    X_train_r = np.expand_dims(X_train, axis=-1)\n","    X_val_r = np.expand_dims(X_val, axis=-1)\n","\n","    # Train Bi-LSTM\n","    model, _, lstm_train_time = train_bi_lstm(X_train_r, Y_train, X_val_r, Y_val, units, layers, learning_rate, batch_size, epochs)\n","    Y_val_pred_lstm = model.predict(X_val_r).flatten()\n","\n","    # Prepare data for Extra Trees\n","    X_val_et = np.column_stack([Y_val_pred_lstm])\n","\n","    et_params = {\n","        \"n_estimators\": trial.suggest_int(\"et_n_estimators\", 50, 200, step=50),\n","        \"max_depth\": trial.suggest_int(\"et_max_depth\", 3, 10),\n","        \"min_samples_split\": trial.suggest_int(\"et_min_samples_split\", 2, 10),\n","        \"min_samples_leaf\": trial.suggest_int(\"et_min_samples_leaf\", 1, 5),\n","        \"random_state\": 42,\n","        \"n_jobs\": -1\n","    }\n","\n","    # Train Extra Trees\n","    start_time = time.time()\n","    et_model = ExtraTreesRegressor(**et_params)\n","    et_model.fit(X_val_et, Y_val)\n","    et_train_time = time.time() - start_time\n","\n","    # Predict and evaluate\n","    Y_val_pred_et = et_model.predict(X_val_et)\n","    rmse = np.sqrt(mean_squared_error(Y_val, Y_val_pred_et))\n","\n","    # Print training times\n","    print(f\"Bi-LSTM Training Time: {lstm_train_time:.2f} seconds\")\n","    print(f\"Extra Trees Training Time: {et_train_time:.2f} seconds\")\n","\n","    return rmse\n","\n","# Run Optuna study\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","# Best hyperparameters\n","print(\"Best hyperparameters:\", study.best_params)\n","\n","# Final Model Implementation\n","best_params = study.best_params\n","units = best_params[\"lstm_units\"]\n","layers = best_params[\"lstm_layers\"]\n","learning_rate = best_params[\"lstm_learning_rate\"]\n","batch_size = best_params[\"lstm_batch_size\"]\n","epochs = best_params[\"lstm_epochs\"]\n","n_estimators = best_params[\"et_n_estimators\"]\n","max_depth = best_params[\"et_max_depth\"]\n","min_samples_split = best_params[\"et_min_samples_split\"]\n","min_samples_leaf = best_params[\"et_min_samples_leaf\"]\n","\n","# Reshape input for LSTM\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Train final Bi-LSTM model\n","final_lstm, lstm_train_time = train_bi_lstm(X_train_r, Y_train, X_val_r, Y_val, units, layers, learning_rate, batch_size, epochs)\n","\n","# Predictions with timing\n","start_time = time.time()\n","Y_train_pred_lstm = final_lstm.predict(X_train_r).flatten()\n","lstm_train_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_lstm = final_lstm.predict(X_val_r).flatten()\n","lstm_val_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_lstm = final_lstm.predict(X_test_r).flatten()\n","lstm_test_pred_time = time.time() - start_time\n","\n","# Prepare data for Extra Trees\n","X_train_et = np.column_stack([Y_train_pred_lstm])\n","X_val_et = np.column_stack([Y_val_pred_lstm])\n","X_test_et = np.column_stack([Y_test_pred_lstm])\n","\n","et_params = {\n","    \"n_estimators\": n_estimators,\n","    \"max_depth\": max_depth,\n","    \"min_samples_split\": min_samples_split,\n","    \"min_samples_leaf\": min_samples_leaf,\n","    \"random_state\": 42,\n","    \"n_jobs\": -1\n","}\n","\n","# Train final Extra Trees model\n","start_time = time.time()\n","final_et = ExtraTreesRegressor(**et_params)\n","final_et.fit(X_train_et, Y_train)\n","et_train_time = time.time() - start_time\n","\n","# Extra Trees Predictions with timing\n","start_time = time.time()\n","Y_train_pred_et = final_et.predict(X_train_et)\n","et_train_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_et = final_et.predict(X_val_et)\n","et_val_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_et = final_et.predict(X_test_et)\n","et_test_pred_time = time.time() - start_time\n","\n","# Compute Metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train, Y_train_pred_et)\n","metrics_val = compute_metrics(Y_val, Y_val_pred_et)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_et)\n","\n","# Print results\n","print(\"\\nFinal Model Performance:\")\n","print(f\"Bi-LSTM Training Time: {lstm_train_time:.2f} seconds\")\n","print(f\"Extra Trees Training Time: {et_train_time:.2f} seconds\\n\")\n","\n","print(f\"Bi-LSTM Train Prediction Time: {lstm_train_pred_time:.4f} seconds\")\n","print(f\"Bi-LSTM Validation Prediction Time: {lstm_val_pred_time:.4f} seconds\")\n","print(f\"Bi-LSTM Test Prediction Time: {lstm_test_pred_time:.4f} seconds\\n\")\n","\n","print(f\"Extra Trees Train Prediction Time: {et_train_pred_time:.4f} seconds\")\n","print(f\"Extra Trees Validation Prediction Time: {et_val_pred_time:.4f} seconds\")\n","print(f\"Extra Trees Test Prediction Time: {et_test_pred_time:.4f} seconds\\n\")\n","\n","print(\"Train Set Metrics:\")\n","print(f\"MAE: {metrics_train[0]:.4f}, MSE: {metrics_train[1]:.4f}, RMSE: {metrics_train[2]:.4f}, R²: {metrics_train[3]:.4f}, MAPE: {metrics_train[4]:.2f}%\")\n","\n","print(\"\\nValidation Set Metrics:\")\n","print(f\"MAE: {metrics_val[0]:.4f}, MSE: {metrics_val[1]:.4f}, RMSE: {metrics_val[2]:.4f}, R²: {metrics_val[3]:.4f}, MAPE: {metrics_val[4]:.2f}%\")\n","\n","print(\"\\nTest Set Metrics:\")\n","print(f\"MAE: {metrics_test[0]:.4f}, MSE: {metrics_test[1]:.4f}, RMSE: {metrics_test[2]:.4f}, R²: {metrics_test[3]:.4f}, MAPE: {metrics_test[4]:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5GxUPCeTCV_X","executionInfo":{"status":"error","timestamp":1743229155982,"user_tz":-330,"elapsed":3323760,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"c6da8df3-580f-43b3-f587-f0a3a051c895"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:23:57,229] A new study created in memory with name: no-name-c6498aa9-3ada-4020-b465-60eb207ebefa\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:24:45,067] Trial 0 finished with value: 0.0038101790707648943 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.00016797310720518288, 'lstm_batch_size': 32, 'lstm_epochs': 50, 'et_n_estimators': 200, 'et_max_depth': 9, 'et_min_samples_split': 8, 'et_min_samples_leaf': 3}. Best is trial 0 with value: 0.0038101790707648943.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 45.50 seconds\n","Extra Trees Training Time: 0.32 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:25:56,115] Trial 1 finished with value: 0.0022097374105448588 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0007132221058534201, 'lstm_batch_size': 16, 'lstm_epochs': 10, 'et_n_estimators': 150, 'et_max_depth': 8, 'et_min_samples_split': 3, 'et_min_samples_leaf': 2}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 69.49 seconds\n","Extra Trees Training Time: 0.16 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:26:30,255] Trial 2 finished with value: 0.012406920154156066 and parameters: {'lstm_units': 96, 'lstm_layers': 3, 'lstm_learning_rate': 0.00048370898478825676, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'et_n_estimators': 100, 'et_max_depth': 3, 'et_min_samples_split': 10, 'et_min_samples_leaf': 2}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 32.21 seconds\n","Extra Trees Training Time: 0.10 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:27:02,505] Trial 3 finished with value: 0.00335699510760215 and parameters: {'lstm_units': 112, 'lstm_layers': 2, 'lstm_learning_rate': 0.00036860966721222253, 'lstm_batch_size': 32, 'lstm_epochs': 30, 'et_n_estimators': 200, 'et_max_depth': 8, 'et_min_samples_split': 2, 'et_min_samples_leaf': 3}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 31.03 seconds\n","Extra Trees Training Time: 0.22 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:27:25,408] Trial 4 finished with value: 0.004111996662257487 and parameters: {'lstm_units': 64, 'lstm_layers': 2, 'lstm_learning_rate': 0.00031610634557483326, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'et_n_estimators': 200, 'et_max_depth': 6, 'et_min_samples_split': 10, 'et_min_samples_leaf': 3}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 21.68 seconds\n","Extra Trees Training Time: 0.20 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:28:04,888] Trial 5 finished with value: 0.01020198441652607 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0004006257963176837, 'lstm_batch_size': 32, 'lstm_epochs': 50, 'et_n_estimators': 200, 'et_max_depth': 4, 'et_min_samples_split': 9, 'et_min_samples_leaf': 5}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 36.54 seconds\n","Extra Trees Training Time: 0.20 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:28:54,702] Trial 6 finished with value: 0.004780789403387846 and parameters: {'lstm_units': 64, 'lstm_layers': 2, 'lstm_learning_rate': 0.0037049712505505166, 'lstm_batch_size': 32, 'lstm_epochs': 50, 'et_n_estimators': 150, 'et_max_depth': 8, 'et_min_samples_split': 7, 'et_min_samples_leaf': 5}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 48.10 seconds\n","Extra Trees Training Time: 0.17 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:29:38,775] Trial 7 finished with value: 0.007384151786160809 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0003718874463085969, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'et_n_estimators': 50, 'et_max_depth': 5, 'et_min_samples_split': 9, 'et_min_samples_leaf': 5}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 41.80 seconds\n","Extra Trees Training Time: 0.06 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:30:08,483] Trial 8 finished with value: 0.004271379919831445 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.0038512375563478553, 'lstm_batch_size': 64, 'lstm_epochs': 30, 'et_n_estimators': 150, 'et_max_depth': 9, 'et_min_samples_split': 7, 'et_min_samples_leaf': 4}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 28.13 seconds\n","Extra Trees Training Time: 0.17 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:31:05,873] Trial 9 finished with value: 0.0043795402242472635 and parameters: {'lstm_units': 128, 'lstm_layers': 2, 'lstm_learning_rate': 0.00011010713741606614, 'lstm_batch_size': 16, 'lstm_epochs': 10, 'et_n_estimators': 200, 'et_max_depth': 6, 'et_min_samples_split': 2, 'et_min_samples_leaf': 3}. Best is trial 1 with value: 0.0022097374105448588.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 54.30 seconds\n","Extra Trees Training Time: 0.36 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:32:43,639] Trial 10 finished with value: 0.0018398794584571251 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0015032743561908517, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 4, 'et_min_samples_leaf': 1}. Best is trial 10 with value: 0.0018398794584571251.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 94.87 seconds\n","Extra Trees Training Time: 0.12 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:34:25,347] Trial 11 finished with value: 0.001829011822156893 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.001411514429544689, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 4, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 98.87 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:35:36,276] Trial 12 finished with value: 0.0018850398316251715 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0015653022820668228, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 4, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 69.38 seconds\n","Extra Trees Training Time: 0.12 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:36:57,584] Trial 13 finished with value: 0.0018696084183924043 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0016031062222551728, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 50, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 78.54 seconds\n","Extra Trees Training Time: 0.07 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:38:39,024] Trial 14 finished with value: 0.0018616249089128186 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.0017229495852647868, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 99.90 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:39:17,845] Trial 15 finished with value: 0.0026353659719958013 and parameters: {'lstm_units': 32, 'lstm_layers': 3, 'lstm_learning_rate': 0.009519266024818524, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 7, 'et_min_samples_split': 4, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 37.32 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:40:28,265] Trial 16 finished with value: 0.0020381908799213984 and parameters: {'lstm_units': 48, 'lstm_layers': 5, 'lstm_learning_rate': 0.0032221419552517813, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'et_n_estimators': 50, 'et_max_depth': 9, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 67.64 seconds\n","Extra Trees Training Time: 0.06 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:42:43,714] Trial 17 finished with value: 0.0023993975358875745 and parameters: {'lstm_units': 96, 'lstm_layers': 3, 'lstm_learning_rate': 0.0009679561292455399, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 7, 'et_min_samples_split': 3, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 133.91 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:44:39,489] Trial 18 finished with value: 0.002194355842632644 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.008096389191811522, 'lstm_batch_size': 16, 'lstm_epochs': 40, 'et_n_estimators': 150, 'et_max_depth': 10, 'et_min_samples_split': 6, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 112.87 seconds\n","Extra Trees Training Time: 0.18 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:45:19,423] Trial 19 finished with value: 0.002115061086514916 and parameters: {'lstm_units': 80, 'lstm_layers': 5, 'lstm_learning_rate': 0.0025411714769828187, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'et_n_estimators': 50, 'et_max_depth': 9, 'et_min_samples_split': 4, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 37.68 seconds\n","Extra Trees Training Time: 0.06 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:46:25,152] Trial 20 finished with value: 0.005085302755102837 and parameters: {'lstm_units': 32, 'lstm_layers': 3, 'lstm_learning_rate': 0.005713049626077479, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 8, 'et_min_samples_split': 3, 'et_min_samples_leaf': 4}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 62.91 seconds\n","Extra Trees Training Time: 0.10 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:47:25,398] Trial 21 finished with value: 0.0018850049121369539 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.001730148555877826, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 57.28 seconds\n","Extra Trees Training Time: 0.19 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:48:25,266] Trial 22 finished with value: 0.001908029598614063 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0008907153179492488, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 6, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 57.05 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:49:26,844] Trial 23 finished with value: 0.0020339644007209947 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.0021528287054481394, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 9, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 60.05 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:51:05,889] Trial 24 finished with value: 0.00195405917694549 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.001221769189279924, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'et_n_estimators': 150, 'et_max_depth': 10, 'et_min_samples_split': 4, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 97.40 seconds\n","Extra Trees Training Time: 0.18 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:52:37,776] Trial 25 finished with value: 0.0019660609582446485 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.0006265474486061307, 'lstm_batch_size': 16, 'lstm_epochs': 10, 'et_n_estimators': 50, 'et_max_depth': 9, 'et_min_samples_split': 3, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 89.12 seconds\n","Extra Trees Training Time: 0.06 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:52:59,092] Trial 26 finished with value: 0.001998108443416155 and parameters: {'lstm_units': 96, 'lstm_layers': 3, 'lstm_learning_rate': 0.0013239038792304681, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 6, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 18.39 seconds\n","Extra Trees Training Time: 0.18 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:54:34,263] Trial 27 finished with value: 0.0023600720004464193 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0026141623752185205, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'et_n_estimators': 150, 'et_max_depth': 7, 'et_min_samples_split': 4, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 93.53 seconds\n","Extra Trees Training Time: 0.15 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:55:12,557] Trial 28 finished with value: 0.004756333931930492 and parameters: {'lstm_units': 80, 'lstm_layers': 2, 'lstm_learning_rate': 0.0009922894046245367, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 8, 'et_min_samples_split': 6, 'et_min_samples_leaf': 4}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 36.77 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:56:25,635] Trial 29 finished with value: 0.0021645326393317844 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.004593659027722187, 'lstm_batch_size': 16, 'lstm_epochs': 10, 'et_n_estimators': 50, 'et_max_depth': 9, 'et_min_samples_split': 7, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 68.36 seconds\n","Extra Trees Training Time: 0.06 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n","Bi-LSTM Training Time: 29.41 seconds\n","Extra Trees Training Time: 0.11 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:56:56,617] Trial 30 finished with value: 0.0018743963806793643 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.00024128236162109442, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 05:59:02,287] Trial 31 finished with value: 0.0019078682969716479 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.001788011075958323, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 50, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 124.20 seconds\n","Extra Trees Training Time: 0.06 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:01:55,133] Trial 32 finished with value: 0.0019057711377291607 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0006950313509177043, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 50, 'et_max_depth': 9, 'et_min_samples_split': 3, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 170.01 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:03:00,171] Trial 33 finished with value: 0.0018967825248102487 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.0012798941344392158, 'lstm_batch_size': 16, 'lstm_epochs': 10, 'et_n_estimators': 50, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 62.19 seconds\n","Extra Trees Training Time: 0.10 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:04:05,337] Trial 34 finished with value: 0.0021672625850212655 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.002416673805695201, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 8, 'et_min_samples_split': 4, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 62.22 seconds\n","Extra Trees Training Time: 0.17 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:05:28,430] Trial 35 finished with value: 0.012792452703277281 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.0018539908343243835, 'lstm_batch_size': 16, 'lstm_epochs': 10, 'et_n_estimators': 150, 'et_max_depth': 3, 'et_min_samples_split': 2, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 81.50 seconds\n","Extra Trees Training Time: 0.14 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:07:28,174] Trial 36 finished with value: 0.0018815064447977238 and parameters: {'lstm_units': 32, 'lstm_layers': 3, 'lstm_learning_rate': 0.0006884877671736725, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 118.22 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:07:50,294] Trial 37 finished with value: 0.003359739766840375 and parameters: {'lstm_units': 48, 'lstm_layers': 2, 'lstm_learning_rate': 0.001180378269151619, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'et_n_estimators': 50, 'et_max_depth': 9, 'et_min_samples_split': 6, 'et_min_samples_leaf': 3}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 21.00 seconds\n","Extra Trees Training Time: 0.06 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:11:04,227] Trial 38 finished with value: 0.004120705734670634 and parameters: {'lstm_units': 32, 'lstm_layers': 3, 'lstm_learning_rate': 0.0005511409503389648, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'et_n_estimators': 150, 'et_max_depth': 5, 'et_min_samples_split': 8, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 192.31 seconds\n","Extra Trees Training Time: 0.17 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:12:29,105] Trial 39 finished with value: 0.0028231989718157375 and parameters: {'lstm_units': 64, 'lstm_layers': 5, 'lstm_learning_rate': 0.0008812740290877398, 'lstm_batch_size': 32, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 9, 'et_min_samples_split': 4, 'et_min_samples_leaf': 3}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 82.01 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:13:08,932] Trial 40 finished with value: 0.0019844445379917685 and parameters: {'lstm_units': 96, 'lstm_layers': 2, 'lstm_learning_rate': 0.0031763503358379747, 'lstm_batch_size': 16, 'lstm_epochs': 10, 'et_n_estimators': 50, 'et_max_depth': 10, 'et_min_samples_split': 2, 'et_min_samples_leaf': 2}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 38.74 seconds\n","Extra Trees Training Time: 0.06 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:13:37,185] Trial 41 finished with value: 0.0019163223940568887 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.00018702982694532758, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 25.42 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:14:02,905] Trial 42 finished with value: 0.0019038908673453584 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.00021223596255582535, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 5, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 24.14 seconds\n","Extra Trees Training Time: 0.13 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:14:36,347] Trial 43 finished with value: 0.001963121891114881 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.00046233553385470905, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 9, 'et_min_samples_split': 4, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 30.53 seconds\n","Extra Trees Training Time: 0.18 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:15:05,118] Trial 44 finished with value: 0.0018965672309339604 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.0002975778803272477, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'et_n_estimators': 100, 'et_max_depth': 10, 'et_min_samples_split': 6, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 27.27 seconds\n","Extra Trees Training Time: 0.11 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:15:38,953] Trial 45 finished with value: 0.0020036202033863917 and parameters: {'lstm_units': 128, 'lstm_layers': 3, 'lstm_learning_rate': 0.00010964424654808109, 'lstm_batch_size': 64, 'lstm_epochs': 30, 'et_n_estimators': 100, 'et_max_depth': 9, 'et_min_samples_split': 7, 'et_min_samples_leaf': 1}. Best is trial 11 with value: 0.001829011822156893.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 30.98 seconds\n","Extra Trees Training Time: 0.13 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:16:23,819] Trial 46 finished with value: 0.0017924266861338214 and parameters: {'lstm_units': 112, 'lstm_layers': 3, 'lstm_learning_rate': 0.0014903255024381803, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'et_n_estimators': 150, 'et_max_depth': 10, 'et_min_samples_split': 3, 'et_min_samples_leaf': 1}. Best is trial 46 with value: 0.0017924266861338214.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 43.16 seconds\n","Extra Trees Training Time: 0.18 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:17:12,843] Trial 47 finished with value: 0.004542593704657025 and parameters: {'lstm_units': 128, 'lstm_layers': 3, 'lstm_learning_rate': 0.0014729253921915207, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'et_n_estimators': 200, 'et_max_depth': 5, 'et_min_samples_split': 3, 'et_min_samples_leaf': 2}. Best is trial 46 with value: 0.0017924266861338214.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 46.68 seconds\n","Extra Trees Training Time: 0.32 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:18:07,854] Trial 48 finished with value: 0.0020218910432661824 and parameters: {'lstm_units': 112, 'lstm_layers': 5, 'lstm_learning_rate': 0.0018711155568935571, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'et_n_estimators': 150, 'et_max_depth': 8, 'et_min_samples_split': 3, 'et_min_samples_leaf': 1}. Best is trial 46 with value: 0.0017924266861338214.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 49.47 seconds\n","Extra Trees Training Time: 0.17 seconds\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 06:18:38,685] Trial 49 finished with value: 0.004193345348317924 and parameters: {'lstm_units': 112, 'lstm_layers': 2, 'lstm_learning_rate': 0.0030476758772507084, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'et_n_estimators': 150, 'et_max_depth': 9, 'et_min_samples_split': 2, 'et_min_samples_leaf': 4}. Best is trial 46 with value: 0.0017924266861338214.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 29.23 seconds\n","Extra Trees Training Time: 0.15 seconds\n","Best hyperparameters: {'lstm_units': 112, 'lstm_layers': 3, 'lstm_learning_rate': 0.0014903255024381803, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'et_n_estimators': 150, 'et_max_depth': 10, 'et_min_samples_split': 3, 'et_min_samples_leaf': 1}\n"]},{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-3fc7789d707b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Train final Bi-LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mfinal_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_train_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_bi_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m# Predictions with timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n","from sklearn.ensemble import ExtraTreesRegressor\n","import optuna\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","\n","# Early stopping callback\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Function to train Bi-LSTM model\n","def train_bi_lstm(X_train, Y_train, X_val, Y_val, units, layers, learning_rate, batch_size, epochs):\n","    model = keras.Sequential()\n","    for _ in range(layers - 1):\n","        model.add(Bidirectional(LSTM(units, return_sequences=True)))\n","    model.add(Bidirectional(LSTM(units)))\n","    model.add(Dense(1))\n","\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","\n","    start_time = time.time()\n","    history = model.fit(X_train, Y_train,\n","                       validation_data=(X_val, Y_val),\n","                       epochs=epochs,\n","                       batch_size=batch_size,\n","                       verbose=0,\n","                       callbacks=[early_stopping])\n","    train_time = time.time() - start_time\n","\n","    return model, history, train_time\n","\n","# If you already have best_params from previous run, use these:\n","best_params = {\n","    'lstm_units': 112,\n","    'lstm_layers': 3,\n","    'lstm_learning_rate': 0.0014903255024381803,\n","    'lstm_batch_size': 32,\n","    'lstm_epochs': 10,\n","    'et_n_estimators': 150,\n","    'et_max_depth': 10,\n","    'et_min_samples_split': 3,\n","    'et_min_samples_leaf': 1\n","}\n","\n","# Extract parameters\n","units = best_params[\"lstm_units\"]\n","layers = best_params[\"lstm_layers\"]\n","learning_rate = best_params[\"lstm_learning_rate\"]\n","batch_size = best_params[\"lstm_batch_size\"]\n","epochs = best_params[\"lstm_epochs\"]\n","n_estimators = best_params[\"et_n_estimators\"]\n","max_depth = best_params[\"et_max_depth\"]\n","min_samples_split = best_params[\"et_min_samples_split\"]\n","min_samples_leaf = best_params[\"et_min_samples_leaf\"]\n","\n","# Reshape input for LSTM\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Initialize timing dictionary\n","timing_metrics = {}\n","\n","# Train final Bi-LSTM model\n","start_time = time.time()\n","final_lstm, _, lstm_train_time = train_bi_lstm(\n","    X_train_r, Y_train, X_val_r, Y_val,\n","    units, layers, learning_rate, batch_size, epochs\n",")\n","timing_metrics['bi_lstm_train'] = time.time() - start_time\n","\n","# Prediction timings\n","start_time = time.time()\n","Y_train_pred_lstm = final_lstm.predict(X_train_r).flatten()\n","timing_metrics['bi_lstm_train_pred'] = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_lstm = final_lstm.predict(X_val_r).flatten()\n","timing_metrics['bi_lstm_val_pred'] = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_lstm = final_lstm.predict(X_test_r).flatten()\n","timing_metrics['bi_lstm_test_pred'] = time.time() - start_time\n","\n","# Prepare data for Extra Trees\n","X_train_et = np.column_stack([Y_train_pred_lstm])\n","X_val_et = np.column_stack([Y_val_pred_lstm])\n","X_test_et = np.column_stack([Y_test_pred_lstm])\n","\n","# Train final Extra Trees model\n","et_params = {\n","    \"n_estimators\": n_estimators,\n","    \"max_depth\": max_depth,\n","    \"min_samples_split\": min_samples_split,\n","    \"min_samples_leaf\": min_samples_leaf,\n","    \"random_state\": 42,\n","    \"n_jobs\": -1\n","}\n","\n","start_time = time.time()\n","final_et = ExtraTreesRegressor(**et_params)\n","final_et.fit(X_train_et, Y_train)\n","timing_metrics['et_train'] = time.time() - start_time\n","\n","# Extra Trees prediction timings\n","start_time = time.time()\n","Y_train_pred_et = final_et.predict(X_train_et)\n","timing_metrics['et_train_pred'] = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_et = final_et.predict(X_val_et)\n","timing_metrics['et_val_pred'] = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_et = final_et.predict(X_test_et)\n","timing_metrics['et_test_pred'] = time.time() - start_time\n","\n","# Compute Metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train, Y_train_pred_et)\n","metrics_val = compute_metrics(Y_val, Y_val_pred_et)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_et)\n","\n","# Print comprehensive results\n","print(\"\\n=== Model Performance Metrics ===\")\n","print(\"\\nTraining Metrics:\")\n","print(f\"MAE: {metrics_train[0]:.4f}, MSE: {metrics_train[1]:.4f}, RMSE: {metrics_train[2]:.4f}\")\n","print(f\"R²: {metrics_train[3]:.4f}, MAPE: {metrics_train[4]:.2f}%\")\n","\n","print(\"\\nValidation Metrics:\")\n","print(f\"MAE: {metrics_val[0]:.4f}, MSE: {metrics_val[1]:.4f}, RMSE: {metrics_val[2]:.4f}\")\n","print(f\"R²: {metrics_val[3]:.4f}, MAPE: {metrics_val[4]:.2f}%\")\n","\n","print(\"\\nTest Metrics:\")\n","print(f\"MAE: {metrics_test[0]:.4f}, MSE: {metrics_test[1]:.4f}, RMSE: {metrics_test[2]:.4f}\")\n","print(f\"R²: {metrics_test[3]:.4f}, MAPE: {metrics_test[4]:.2f}%\")\n","\n","print(\"\\n=== Timing Metrics (seconds) ===\")\n","print(f\"\\nBi-LSTM Training Time: {timing_metrics['bi_lstm_train']:.2f}\")\n","print(f\"Bi-LSTM Train Prediction Time: {timing_metrics['bi_lstm_train_pred']:.4f}\")\n","print(f\"Bi-LSTM Validation Prediction Time: {timing_metrics['bi_lstm_val_pred']:.4f}\")\n","print(f\"Bi-LSTM Test Prediction Time: {timing_metrics['bi_lstm_test_pred']:.4f}\")\n","\n","print(f\"\\nExtra Trees Training Time: {timing_metrics['et_train']:.2f}\")\n","print(f\"Extra Trees Train Prediction Time: {timing_metrics['et_train_pred']:.4f}\")\n","print(f\"Extra Trees Validation Prediction Time: {timing_metrics['et_val_pred']:.4f}\")\n","print(f\"Extra Trees Test Prediction Time: {timing_metrics['et_test_pred']:.4f}\")\n","\n","print(\"\\n=== Best Parameters Used ===\")\n","print(best_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prsk7nepjzx4","executionInfo":{"status":"ok","timestamp":1743236481476,"user_tz":-330,"elapsed":42100,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"cf42b31b-324a-4134-db46-cfa6ba6cff19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\n","=== Model Performance Metrics ===\n","\n","Training Metrics:\n","MAE: 0.0030, MSE: 0.0000, RMSE: 0.0043\n","R²: 0.9999, MAPE: 0.97%\n","\n","Validation Metrics:\n","MAE: 0.1380, MSE: 0.0247, RMSE: 0.1572\n","R²: -3.2019, MAPE: 7.72%\n","\n","Test Metrics:\n","MAE: 0.4063, MSE: 0.1711, RMSE: 0.4137\n","R²: -27.3532, MAPE: 20.04%\n","\n","=== Timing Metrics (seconds) ===\n","\n","Bi-LSTM Training Time: 37.99\n","Bi-LSTM Train Prediction Time: 2.6140\n","Bi-LSTM Validation Prediction Time: 0.3747\n","Bi-LSTM Test Prediction Time: 0.3505\n","\n","Extra Trees Training Time: 0.23\n","Extra Trees Train Prediction Time: 0.0637\n","Extra Trees Validation Prediction Time: 0.0436\n","Extra Trees Test Prediction Time: 0.0543\n","\n","=== Best Parameters Used ===\n","{'lstm_units': 112, 'lstm_layers': 3, 'lstm_learning_rate': 0.0014903255024381803, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'et_n_estimators': 150, 'et_max_depth': 10, 'et_min_samples_split': 3, 'et_min_samples_leaf': 1}\n"]}]},{"cell_type":"markdown","source":["## BOHB"],"metadata":{"id":"eZRR2DI_T-8W"}},{"cell_type":"code","source":["!pip install ConfigSpace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXtRijg2ULai","executionInfo":{"status":"ok","timestamp":1743251839881,"user_tz":-330,"elapsed":13485,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"237bb672-ce58-4148-e1b7-2cbb737bcd5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ConfigSpace\n","  Downloading configspace-1.2.1.tar.gz (130 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/131.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (1.26.4)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (3.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (1.13.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (10.6.0)\n","Building wheels for collected packages: ConfigSpace\n","  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ConfigSpace: filename=configspace-1.2.1-py3-none-any.whl size=115990 sha256=91cc2f1b52a482238c14ac4c6d62458d6248d5802413b7be0702a81e8fff82f5\n","  Stored in directory: /root/.cache/pip/wheels/11/0f/36/d5027c3eeb038827889830f7efbe6a1bad8956b3eb44ab2f44\n","Successfully built ConfigSpace\n","Installing collected packages: ConfigSpace\n","Successfully installed ConfigSpace-1.2.1\n"]}]},{"cell_type":"code","source":["!pip install hpbandster"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptsnU6gQUVYy","executionInfo":{"status":"ok","timestamp":1743251860359,"user_tz":-330,"elapsed":20476,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"53d21152-7ac9-4126-c0bd-a008a47fefc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hpbandster\n","  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Pyro4 (from hpbandster)\n","  Downloading Pyro4-4.82-py2.py3-none-any.whl.metadata (2.2 kB)\n","Collecting serpent (from hpbandster)\n","  Downloading serpent-1.41-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.26.4)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.13.1)\n","Collecting netifaces (from hpbandster)\n","  Downloading netifaces-0.11.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (3.2.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (10.6.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n","Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading serpent-1.41-py3-none-any.whl (9.6 kB)\n","Building wheels for collected packages: hpbandster, netifaces\n","  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=79986 sha256=6a58ad5481541bc5aeb8887cc6f01713b299d5c45ae1577a0899f138cca8114a\n","  Stored in directory: /root/.cache/pip/wheels/fb/da/7d/af80a6b0a6898aaf2e1e93ab00cdf03251624e67f0641e9f0b\n","  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for netifaces: filename=netifaces-0.11.0-cp311-cp311-linux_x86_64.whl size=35187 sha256=c16e9bedf52497ef1208aff1c060ab8478ed26b3fbba85889c7e54630ccb97bc\n","  Stored in directory: /root/.cache/pip/wheels/40/85/29/648c19bbbb5f1d30e33bfb343fd7fb54296b402f7205d8e46f\n","Successfully built hpbandster netifaces\n","Installing collected packages: netifaces, serpent, Pyro4, hpbandster\n","Successfully installed Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","from sklearn.ensemble import ExtraTreesRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import time\n","\n","# Check for GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define Bi-LSTM Model\n","class BiLSTMModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super(BiLSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","# Function to calculate metrics\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Convert datasets to PyTorch tensors and move to GPU\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# Bi-LSTM Configurations\n","lstm_layers = [2, 3, 5]\n","hidden_dim = 64\n","output_dim = 1\n","input_dim = X_train.shape[1]\n","\n","# Dictionary to store LSTM feature representations\n","lstm_features = []\n","\n","for num_layers in lstm_layers:\n","    print(f\"Training Bi-LSTM with {num_layers} layers...\")\n","\n","    lstm_model = BiLSTMModel(input_dim, hidden_dim, num_layers, output_dim).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n","    num_epochs = 35\n","\n","    start_time = time.time()\n","    for epoch in range(num_epochs):\n","        lstm_model.train()\n","        optimizer.zero_grad()\n","        outputs = lstm_model(X_train_torch)\n","        loss = criterion(outputs, Y_train_torch)\n","        loss.backward()\n","        optimizer.step()\n","    train_time = time.time() - start_time\n","\n","    # Extract Feature Representations\n","    lstm_model.eval()\n","    with torch.no_grad():\n","        val_start = time.time()\n","        train_features = lstm_model(X_train_torch).cpu().numpy()\n","        val_features = lstm_model(X_val_torch).cpu().numpy()\n","        val_time = time.time() - val_start\n","\n","        test_start = time.time()\n","        test_features = lstm_model(X_test_torch).cpu().numpy()\n","        test_time = time.time() - test_start\n","\n","    lstm_features.append((train_features, val_features, test_features, train_time, val_time, test_time))\n","\n","# Concatenate Features from All Layers\n","final_train_features = np.hstack([feat[0] for feat in lstm_features])\n","final_val_features = np.hstack([feat[1] for feat in lstm_features])\n","final_test_features = np.hstack([feat[2] for feat in lstm_features])\n","\n","# Record Time for Each Stage\n","total_train_time = sum([feat[3] for feat in lstm_features])\n","total_val_time = sum([feat[4] for feat in lstm_features])\n","total_test_time = sum([feat[5] for feat in lstm_features])\n","\n","# Define ConfigSpace for BOHB\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"n_estimators\", 50, 500, default_value=100))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"max_depth\", 3, 15, default_value=6))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_split\", 2, 10, default_value=2))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 5, default_value=1))\n","    return cs\n","\n","# BOHB Worker for Extra Trees\n","class ETWorker(Worker):\n","    def compute(self, config, budget, **kwargs):\n","        model = ExtraTreesRegressor(\n","            n_estimators=config[\"n_estimators\"],\n","            max_depth=config[\"max_depth\"],\n","            min_samples_split=config[\"min_samples_split\"],\n","            min_samples_leaf=config[\"min_samples_leaf\"],\n","            random_state=42\n","        )\n","        model.fit(final_train_features, Y_train)\n","        Y_val_pred = model.predict(final_val_features)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Run BOHB\n","NS = hpns.NameServer(run_id=\"bilstm_et_bohb\", host=\"127.0.0.2\", port=None)\n","NS.start()\n","\n","worker = ETWorker(nameserver=\"127.0.0.2\", run_id=\"bilstm_et_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(configspace=get_config_space(), run_id=\"bilstm_et_bohb\", nameserver=\"127.0.0.2\", min_budget=1, max_budget=3)\n","res = bohb.run(n_iterations=50)\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Train Best Extra Trees Model\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","best_et_model = ExtraTreesRegressor(\n","    n_estimators=best_params[\"n_estimators\"],\n","    max_depth=best_params[\"max_depth\"],\n","    min_samples_split=best_params[\"min_samples_split\"],\n","    min_samples_leaf=best_params[\"min_samples_leaf\"],\n","    random_state=42\n",")\n","\n","best_et_model.fit(final_train_features, Y_train)\n","\n","# Predictions\n","Y_train_pred = best_et_model.predict(final_train_features)\n","Y_val_pred = best_et_model.predict(final_val_features)\n","Y_test_pred = best_et_model.predict(final_test_features)\n","\n","# Calculate Metrics\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print Results\n","print(\"Train Metrics:\", train_metrics, \"Time:\", total_train_time)\n","print(\"Validation Metrics:\", val_metrics, \"Time:\", total_val_time)\n","print(\"Test Metrics:\", test_metrics, \"Time:\", total_test_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQqF-QdwUBvx","executionInfo":{"status":"ok","timestamp":1743252262315,"user_tz":-330,"elapsed":324011,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"e93fd150-e212-4402-a058-4157ee1468bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Bi-LSTM with 2 layers...\n","Training Bi-LSTM with 3 layers...\n","Training Bi-LSTM with 5 layers...\n","Train Metrics: (0.0018717259544414507, 6.600947710420866e-06, 0.002569230957002672, 0.9999622848259763, 0.6435209971000355) Time: 76.76189351081848\n","Validation Metrics: (0.13518588362470813, 0.02390979443769331, 0.15462792256799324, -3.0652244941559887, 7.564641704189151) Time: 1.164679765701294\n","Test Metrics: (0.403350534172395, 0.16872672380815443, 0.4107635862733629, -26.95770602109762, 19.889610417803667) Time: 0.15404748916625977\n"]}]},{"cell_type":"markdown","source":["# RandomForest"],"metadata":{"id":"uUCh_YB9Vf7S"}},{"cell_type":"markdown","source":["## Intial"],"metadata":{"id":"qUH36NvmtM2G"}},{"cell_type":"code","source":["import time\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n","from sklearn.ensemble import RandomForestRegressor  # Changed from ExtraTreesRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Enable GPU for TensorFlow\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","        print(\"GPU activated for TensorFlow!\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Function to define and train a Bi-LSTM model on GPU (unchanged)\n","def train_bi_lstm(X_train, Y_train, X_val, Y_val, layers):\n","    with tf.device('/GPU:0'):\n","        model = Sequential()\n","        model.add(Bidirectional(LSTM(64, return_sequences=(layers > 1)), input_shape=(X_train.shape[1], 1)))\n","        for _ in range(layers - 1):\n","            model.add(Bidirectional(LSTM(64, return_sequences=(_ < layers - 2))))\n","        model.add(Dense(1))\n","\n","        model.compile(optimizer='adam', loss='mse')\n","        model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=16, verbose=0)\n","        return model\n","\n","# Reshaping input for LSTM (unchanged)\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Initialize timing dictionary (unchanged)\n","times = {}\n","\n","# Train Phase (includes training all Bi-LSTMs and Random Forest)\n","start_train_time = time.time()\n","\n","# Train 2, 3, and 5-layer Bi-LSTM models (unchanged)\n","bi_lstm_models = {}\n","bi_lstm_predictions = {}\n","\n","for layers in [2, 3, 5]:\n","    model = train_bi_lstm(X_train_r, Y_train, X_val_r, Y_val, layers)\n","    bi_lstm_models[layers] = model\n","\n","# Generate predictions from all Bi-LSTM models (unchanged)\n","for layers in [2, 3, 5]:\n","    Y_train_pred = bi_lstm_models[layers].predict(X_train_r)\n","    Y_val_pred = bi_lstm_models[layers].predict(X_val_r)\n","    Y_test_pred = bi_lstm_models[layers].predict(X_test_r)\n","    bi_lstm_predictions[layers] = (Y_train_pred, Y_val_pred, Y_test_pred)\n","\n","# Prepare input for Random Forest (unchanged except variable names)\n","X_train_rf = np.column_stack([bi_lstm_predictions[layers][0] for layers in [2, 3, 5]])\n","X_val_rf = np.column_stack([bi_lstm_predictions[layers][1] for layers in [2, 3, 5]])\n","X_test_rf = np.column_stack([bi_lstm_predictions[layers][2] for layers in [2, 3, 5]])\n","\n","# Train Random Forest model (modified)\n","rf_model = RandomForestRegressor(n_estimators=100,\n","                               max_depth=None,\n","                               min_samples_split=2,\n","                               min_samples_leaf=1,\n","                               random_state=42,\n","                               n_jobs=-1)  # Using all available cores\n","rf_model.fit(X_train_rf, Y_train)\n","\n","times['Total Train Time'] = time.time() - start_train_time\n","\n","# Validation Phase (unchanged except variable names)\n","start_val_time = time.time()\n","Y_val_pred_rf = rf_model.predict(X_val_rf)\n","times['Total Validate Time'] = time.time() - start_val_time\n","\n","# Test Phase (unchanged except variable names)\n","start_test_time = time.time()\n","Y_test_pred_rf = rf_model.predict(X_test_rf)\n","times['Total Test Time'] = time.time() - start_test_time\n","\n","# Function to calculate metrics (unchanged)\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Compute and print metrics (unchanged except variable names)\n","metrics_train = compute_metrics(Y_train, rf_model.predict(X_train_rf))\n","metrics_val = compute_metrics(Y_val, Y_val_pred_rf)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_rf)\n","\n","print(\"\\nPerformance Metrics:\")\n","print(f\"Train Metrics: MAE={metrics_train[0]:.4f}, MSE={metrics_train[1]:.4f}, RMSE={metrics_train[2]:.4f}, R²={metrics_train[3]:.4f}, MAPE={metrics_train[4]:.2f}%\")\n","print(f\"Validation Metrics: MAE={metrics_val[0]:.4f}, MSE={metrics_val[1]:.4f}, RMSE={metrics_val[2]:.4f}, R²={metrics_val[3]:.4f}, MAPE={metrics_val[4]:.2f}%\")\n","print(f\"Test Metrics: MAE={metrics_test[0]:.4f}, MSE={metrics_test[1]:.4f}, RMSE={metrics_test[2]:.4f}, R²={metrics_test[3]:.4f}, MAPE={metrics_test[4]:.2f}%\")\n","\n","# Print timing information (unchanged)\n","print(\"\\nTiming Information:\")\n","for phase, t in times.items():\n","    print(f\"{phase}: {t:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hcZDoVAPV2Gh","executionInfo":{"status":"ok","timestamp":1743237320907,"user_tz":-330,"elapsed":491489,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"1db636db-8bcc-41e1-9c3f-cde3722bbbd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Physical devices cannot be modified after being initialized\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n","\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","\n","Performance Metrics:\n","Train Metrics: MAE=0.0013, MSE=0.0000, RMSE=0.0019, R²=1.0000, MAPE=0.39%\n","Validation Metrics: MAE=0.1374, MSE=0.0245, RMSE=0.1567, R²=-3.1740, MAPE=7.69%\n","Test Metrics: MAE=0.4057, MSE=0.1706, RMSE=0.4131, R²=-27.2728, MAPE=20.01%\n","\n","Timing Information:\n","Total Train Time: 491.32 seconds\n","Total Validate Time: 0.03 seconds\n","Total Test Time: 0.03 seconds\n"]}]},{"cell_type":"markdown","source":["## Optuna"],"metadata":{"id":"PnPul0h2lqPU"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iaFt4LZ3mLdj","executionInfo":{"status":"ok","timestamp":1743245087306,"user_tz":-330,"elapsed":4340,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"eec623b9-2529-4503-8b79-6008855fa3f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n","from sklearn.ensemble import RandomForestRegressor\n","import optuna\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","\n","# Early stopping callback\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Function to train Bi-LSTM model\n","def train_bi_lstm(X_train, Y_train, X_val, Y_val, units, layers, learning_rate, batch_size, epochs):\n","    model = keras.Sequential()\n","    for _ in range(layers - 1):\n","        model.add(Bidirectional(LSTM(units, return_sequences=True)))\n","    model.add(Bidirectional(LSTM(units)))\n","    model.add(Dense(1))\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","    start_time = time.time()\n","    history = model.fit(X_train, Y_train,\n","                       validation_data=(X_val, Y_val),\n","                       epochs=epochs,\n","                       batch_size=batch_size,\n","                       verbose=0,\n","                       callbacks=[early_stopping])\n","    lstm_train_time = time.time() - start_time\n","    return model, history, lstm_train_time\n","\n","# Updated objective function for Random Forest\n","def objective(trial):\n","    # Bi-LSTM parameters\n","    units = trial.suggest_int(\"lstm_units\", 32, 128, step=16)\n","    layers = trial.suggest_categorical(\"lstm_layers\", [2, 3, 5])\n","    learning_rate = trial.suggest_float(\"lstm_learning_rate\", 1e-4, 1e-2, log=True)\n","    batch_size = trial.suggest_categorical(\"lstm_batch_size\", [16, 32, 64])\n","    epochs = trial.suggest_int(\"lstm_epochs\", 10, 50, step=10)\n","\n","    # Reshape and train Bi-LSTM\n","    X_train_r = np.expand_dims(X_train, axis=-1)\n","    X_val_r = np.expand_dims(X_val, axis=-1)\n","    model, _, lstm_train_time = train_bi_lstm(X_train_r, Y_train, X_val_r, Y_val,\n","                                            units, layers, learning_rate, batch_size, epochs)\n","    Y_val_pred_lstm = model.predict(X_val_r, verbose=0).flatten()\n","\n","    # Prepare data for Random Forest\n","    X_val_rf = np.column_stack([Y_val_pred_lstm])\n","\n","    # Random Forest hyperparameters\n","    rf_params = {\n","        \"n_estimators\": trial.suggest_int(\"rf_n_estimators\", 50, 200, step=50),\n","        \"max_depth\": trial.suggest_int(\"rf_max_depth\", 3, 10),\n","        \"min_samples_split\": trial.suggest_int(\"rf_min_samples_split\", 2, 10),\n","        \"min_samples_leaf\": trial.suggest_int(\"rf_min_samples_leaf\", 1, 5),\n","        \"max_features\": trial.suggest_categorical(\"rf_max_features\", ['sqrt', 'log2']),  # Removed 'auto'\n","        \"random_state\": 42,\n","        \"n_jobs\": -1\n","    }\n","\n","    # Train Random Forest\n","    start_time = time.time()\n","    rf_model = RandomForestRegressor(**rf_params)\n","    rf_model.fit(X_val_rf, Y_val)\n","    rf_train_time = time.time() - start_time\n","\n","    # Predict and evaluate\n","    Y_val_pred_rf = rf_model.predict(X_val_rf)\n","    rmse = np.sqrt(mean_squared_error(Y_val, Y_val_pred_rf))\n","\n","    print(f\"Bi-LSTM Training Time: {lstm_train_time:.2f} seconds\")\n","    print(f\"Random Forest Training Time: {rf_train_time:.2f} seconds\")\n","\n","    return rmse\n","\n","# Run Optuna study\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","print(\"Best hyperparameters:\", study.best_params)\n","\n","# Final Model Implementation with Random Forest\n","best_params = study.best_params\n","units = best_params[\"lstm_units\"]\n","layers = best_params[\"lstm_layers\"]\n","learning_rate = best_params[\"lstm_learning_rate\"]\n","batch_size = best_params[\"lstm_batch_size\"]\n","epochs = best_params[\"lstm_epochs\"]\n","n_estimators = best_params[\"rf_n_estimators\"]\n","max_depth = best_params[\"rf_max_depth\"]\n","min_samples_split = best_params[\"rf_min_samples_split\"]\n","min_samples_leaf = best_params[\"rf_min_samples_leaf\"]\n","max_features = best_params[\"rf_max_features\"]\n","\n","# Reshape input for LSTM\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Train final Bi-LSTM model\n","final_lstm, lstm_train_time = train_bi_lstm(X_train_r, Y_train, X_val_r, Y_val,\n","                                          units, layers, learning_rate, batch_size, epochs)\n","\n","# Predictions with timing\n","start_time = time.time()\n","Y_train_pred_lstm = final_lstm.predict(X_train_r, verbose=0).flatten()\n","lstm_train_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_lstm = final_lstm.predict(X_val_r, verbose=0).flatten()\n","lstm_val_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_lstm = final_lstm.predict(X_test_r, verbose=0).flatten()\n","lstm_test_pred_time = time.time() - start_time\n","\n","# Prepare data for Random Forest\n","X_train_rf = np.column_stack([Y_train_pred_lstm])\n","X_val_rf = np.column_stack([Y_val_pred_lstm])\n","X_test_rf = np.column_stack([Y_test_pred_lstm])\n","\n","# Random Forest parameters\n","rf_params = {\n","    \"n_estimators\": n_estimators,\n","    \"max_depth\": max_depth,\n","    \"min_samples_split\": min_samples_split,\n","    \"min_samples_leaf\": min_samples_leaf,\n","    \"max_features\": max_features,\n","    \"random_state\": 42,\n","    \"n_jobs\": -1\n","}\n","\n","# Train final Random Forest model\n","start_time = time.time()\n","final_rf = RandomForestRegressor(**rf_params)\n","final_rf.fit(X_train_rf, Y_train)\n","rf_train_time = time.time() - start_time\n","\n","# Random Forest Predictions with timing\n","start_time = time.time()\n","Y_train_pred_rf = final_rf.predict(X_train_rf)\n","rf_train_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_rf = final_rf.predict(X_val_rf)\n","rf_val_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_rf = final_rf.predict(X_test_rf)\n","rf_test_pred_time = time.time() - start_time\n","\n","# Compute Metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train, Y_train_pred_rf)\n","metrics_val = compute_metrics(Y_val, Y_val_pred_rf)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_rf)\n","\n","# Print results\n","print(\"\\nFinal Model Performance:\")\n","print(f\"Bi-LSTM Training Time: {lstm_train_time:.2f} seconds\")\n","print(f\"Random Forest Training Time: {rf_train_time:.2f} seconds\\n\")\n","\n","print(f\"Bi-LSTM Train Prediction Time: {lstm_train_pred_time:.4f} seconds\")\n","print(f\"Bi-LSTM Validation Prediction Time: {lstm_val_pred_time:.4f} seconds\")\n","print(f\"Bi-LSTM Test Prediction Time: {lstm_test_pred_time:.4f} seconds\\n\")\n","\n","print(f\"Random Forest Train Prediction Time: {rf_train_pred_time:.4f} seconds\")\n","print(f\"Random Forest Validation Prediction Time: {rf_val_pred_time:.4f} seconds\")\n","print(f\"Random Forest Test Prediction Time: {rf_test_pred_time:.4f} seconds\\n\")\n","\n","print(\"Train Set Metrics:\")\n","print(f\"MAE: {metrics_train[0]:.4f}, MSE: {metrics_train[1]:.4f}, RMSE: {metrics_train[2]:.4f}, R²: {metrics_train[3]:.4f}, MAPE: {metrics_train[4]:.2f}%\")\n","\n","print(\"\\nValidation Set Metrics:\")\n","print(f\"MAE: {metrics_val[0]:.4f}, MSE: {metrics_val[1]:.4f}, RMSE: {metrics_val[2]:.4f}, R²: {metrics_val[3]:.4f}, MAPE: {metrics_val[4]:.2f}%\")\n","\n","print(\"\\nTest Set Metrics:\")\n","print(f\"MAE: {metrics_test[0]:.4f}, MSE: {metrics_test[1]:.4f}, RMSE: {metrics_test[2]:.4f}, R²: {metrics_test[3]:.4f}, MAPE: {metrics_test[4]:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hJfg66lpWB8w","executionInfo":{"status":"error","timestamp":1743244587700,"user_tz":-330,"elapsed":3805943,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"0a339e5c-5f78-47dc-8f49-c0542c27dac3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:33:06,728] A new study created in memory with name: no-name-9299804b-bcfa-444a-bbdc-2d7f33f07cb6\n","[I 2025-03-29 09:33:57,182] Trial 0 finished with value: 0.009193934074283087 and parameters: {'lstm_units': 112, 'lstm_layers': 2, 'lstm_learning_rate': 0.0012711088017081313, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 50, 'rf_max_depth': 3, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 4, 'rf_max_features': 'sqrt'}. Best is trial 0 with value: 0.009193934074283087.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 48.90 seconds\n","Random Forest Training Time: 0.13 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:34:26,701] Trial 1 finished with value: 0.0017427090013743386 and parameters: {'lstm_units': 32, 'lstm_layers': 3, 'lstm_learning_rate': 0.00032810786405556853, 'lstm_batch_size': 32, 'lstm_epochs': 50, 'rf_n_estimators': 50, 'rf_max_depth': 8, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 26.71 seconds\n","Random Forest Training Time: 0.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:35:56,649] Trial 2 finished with value: 0.00909408973303574 and parameters: {'lstm_units': 128, 'lstm_layers': 5, 'lstm_learning_rate': 0.0005810291353783081, 'lstm_batch_size': 16, 'lstm_epochs': 50, 'rf_n_estimators': 200, 'rf_max_depth': 3, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 2, 'rf_max_features': 'sqrt'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 84.32 seconds\n","Random Forest Training Time: 0.32 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:36:10,960] Trial 3 finished with value: 0.001841048959770072 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.0015549538546389258, 'lstm_batch_size': 64, 'lstm_epochs': 10, 'rf_n_estimators': 150, 'rf_max_depth': 8, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 12.62 seconds\n","Random Forest Training Time: 0.29 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:36:34,466] Trial 4 finished with value: 0.0018422986747422775 and parameters: {'lstm_units': 112, 'lstm_layers': 2, 'lstm_learning_rate': 0.0027862282498927796, 'lstm_batch_size': 32, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 10, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 5, 'rf_max_features': 'log2'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 22.36 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:38:52,350] Trial 5 finished with value: 0.001778023992537672 and parameters: {'lstm_units': 128, 'lstm_layers': 5, 'lstm_learning_rate': 0.0007398783193122754, 'lstm_batch_size': 16, 'lstm_epochs': 50, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 134.88 seconds\n","Random Forest Training Time: 0.31 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:39:49,612] Trial 6 finished with value: 0.0018463316651191153 and parameters: {'lstm_units': 48, 'lstm_layers': 5, 'lstm_learning_rate': 0.004016287420586946, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 3, 'rf_max_features': 'sqrt'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 55.02 seconds\n","Random Forest Training Time: 0.19 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:40:11,972] Trial 7 finished with value: 0.004035952587199103 and parameters: {'lstm_units': 48, 'lstm_layers': 2, 'lstm_learning_rate': 0.00024505530107961484, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'rf_n_estimators': 200, 'rf_max_depth': 4, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 2, 'rf_max_features': 'sqrt'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 21.06 seconds\n","Random Forest Training Time: 0.31 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:40:56,697] Trial 8 finished with value: 0.0091444461822267 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.0017027207274942367, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'rf_n_estimators': 100, 'rf_max_depth': 3, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 43.27 seconds\n","Random Forest Training Time: 0.16 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:41:34,332] Trial 9 finished with value: 0.0023023800801147657 and parameters: {'lstm_units': 64, 'lstm_layers': 5, 'lstm_learning_rate': 0.00012951184072579954, 'lstm_batch_size': 64, 'lstm_epochs': 30, 'rf_n_estimators': 200, 'rf_max_depth': 5, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 1 with value: 0.0017427090013743386.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 34.58 seconds\n","Random Forest Training Time: 0.34 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:42:08,189] Trial 10 finished with value: 0.0017076820869094025 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.008419763579664171, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'rf_n_estimators': 50, 'rf_max_depth': 9, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 10 with value: 0.0017076820869094025.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 32.41 seconds\n","Random Forest Training Time: 0.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:42:37,791] Trial 11 finished with value: 0.0017052680782189296 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.009675598277492807, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'rf_n_estimators': 50, 'rf_max_depth': 9, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 11 with value: 0.0017052680782189296.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 28.10 seconds\n","Random Forest Training Time: 0.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:43:10,035] Trial 12 finished with value: 0.0017551675914292447 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.009988626280851457, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'rf_n_estimators': 50, 'rf_max_depth': 10, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 11 with value: 0.0017052680782189296.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 29.34 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:44:06,922] Trial 13 finished with value: 0.0019401708947283 and parameters: {'lstm_units': 96, 'lstm_layers': 3, 'lstm_learning_rate': 0.008757037833916738, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'rf_n_estimators': 50, 'rf_max_depth': 9, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 11 with value: 0.0017052680782189296.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 55.46 seconds\n","Random Forest Training Time: 0.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:44:53,368] Trial 14 finished with value: 0.0016777743710662014 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.0055719918660429415, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'rf_n_estimators': 150, 'rf_max_depth': 9, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 44.52 seconds\n","Random Forest Training Time: 0.27 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:45:40,013] Trial 15 finished with value: 0.0018976767455363762 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.00427293879017135, 'lstm_batch_size': 32, 'lstm_epochs': 30, 'rf_n_estimators': 150, 'rf_max_depth': 6, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 45.01 seconds\n","Random Forest Training Time: 0.26 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:46:14,084] Trial 16 finished with value: 0.0018332544734054297 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.005163270416193744, 'lstm_batch_size': 32, 'lstm_epochs': 40, 'rf_n_estimators': 150, 'rf_max_depth': 9, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 5, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 32.47 seconds\n","Random Forest Training Time: 0.27 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:46:50,132] Trial 17 finished with value: 0.0017947376100602417 and parameters: {'lstm_units': 96, 'lstm_layers': 3, 'lstm_learning_rate': 0.003018865761689106, 'lstm_batch_size': 32, 'lstm_epochs': 30, 'rf_n_estimators': 150, 'rf_max_depth': 8, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 34.37 seconds\n","Random Forest Training Time: 0.28 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:48:42,910] Trial 18 finished with value: 0.0018670334501252632 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.005884082666587911, 'lstm_batch_size': 32, 'lstm_epochs': 50, 'rf_n_estimators': 100, 'rf_max_depth': 10, 'rf_min_samples_split': 3, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 111.24 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:49:52,049] Trial 19 finished with value: 0.0018779617205661244 and parameters: {'lstm_units': 96, 'lstm_layers': 3, 'lstm_learning_rate': 0.002609511811848538, 'lstm_batch_size': 16, 'lstm_epochs': 40, 'rf_n_estimators': 150, 'rf_max_depth': 6, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 67.49 seconds\n","Random Forest Training Time: 0.27 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:50:37,932] Trial 20 finished with value: 0.0017072626405826195 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.005819967288471904, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 44.01 seconds\n","Random Forest Training Time: 0.35 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:51:08,759] Trial 21 finished with value: 0.0017275404229798036 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.006379731049436264, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 29.10 seconds\n","Random Forest Training Time: 0.37 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:51:44,403] Trial 22 finished with value: 0.0017495914195092615 and parameters: {'lstm_units': 64, 'lstm_layers': 3, 'lstm_learning_rate': 0.0022686177431459984, 'lstm_batch_size': 32, 'lstm_epochs': 10, 'rf_n_estimators': 200, 'rf_max_depth': 8, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 33.95 seconds\n","Random Forest Training Time: 0.35 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:52:15,218] Trial 23 finished with value: 0.001727333717539531 and parameters: {'lstm_units': 80, 'lstm_layers': 3, 'lstm_learning_rate': 0.006778427612544066, 'lstm_batch_size': 32, 'lstm_epochs': 30, 'rf_n_estimators': 150, 'rf_max_depth': 10, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 29.24 seconds\n","Random Forest Training Time: 0.26 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:53:05,949] Trial 24 finished with value: 0.0017015530070519276 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0034946832651093175, 'lstm_batch_size': 32, 'lstm_epochs': 20, 'rf_n_estimators': 200, 'rf_max_depth': 9, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 3, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 48.99 seconds\n","Random Forest Training Time: 0.37 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:53:58,792] Trial 25 finished with value: 0.0018514747129095563 and parameters: {'lstm_units': 48, 'lstm_layers': 3, 'lstm_learning_rate': 0.0036285201485950105, 'lstm_batch_size': 32, 'lstm_epochs': 20, 'rf_n_estimators': 150, 'rf_max_depth': 7, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 4, 'rf_max_features': 'log2'}. Best is trial 14 with value: 0.0016777743710662014.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 51.17 seconds\n","Random Forest Training Time: 0.28 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:54:36,675] Trial 26 finished with value: 0.0016729419239357596 and parameters: {'lstm_units': 32, 'lstm_layers': 3, 'lstm_learning_rate': 0.0021929396017048865, 'lstm_batch_size': 32, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 26 with value: 0.0016729419239357596.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 36.27 seconds\n","Random Forest Training Time: 0.19 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:55:39,393] Trial 27 finished with value: 0.0015715748016958174 and parameters: {'lstm_units': 32, 'lstm_layers': 3, 'lstm_learning_rate': 0.0020536376444786203, 'lstm_batch_size': 32, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 61.21 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:58:03,147] Trial 28 finished with value: 0.0015817934228926646 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0009690103056105344, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 141.38 seconds\n","Random Forest Training Time: 0.32 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 09:59:43,209] Trial 29 finished with value: 0.0018786058762792705 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0010129971925592922, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 6, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 97.13 seconds\n","Random Forest Training Time: 0.17 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:02:46,228] Trial 30 finished with value: 0.0017801989069794765 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0010277863149512683, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 180.10 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:04:53,375] Trial 31 finished with value: 0.0015739226027265724 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0018307766418657254, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 124.25 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:05:59,901] Trial 32 finished with value: 0.0016208758786149823 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.001965562487365699, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 64.26 seconds\n","Random Forest Training Time: 0.19 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:08:49,513] Trial 33 finished with value: 0.0015901712486074578 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.000643268697827448, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 166.70 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:11:03,719] Trial 34 finished with value: 0.00178134410988689 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0004537621729693796, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 132.01 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:13:40,554] Trial 35 finished with value: 0.0015818045878579848 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.001346208344694327, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 153.92 seconds\n","Random Forest Training Time: 0.19 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:14:59,682] Trial 36 finished with value: 0.0015902989150222533 and parameters: {'lstm_units': 48, 'lstm_layers': 5, 'lstm_learning_rate': 0.0013886289373190785, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'rf_n_estimators': 50, 'rf_max_depth': 8, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 76.23 seconds\n","Random Forest Training Time: 0.17 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:17:35,729] Trial 37 finished with value: 0.0017964838543452198 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0012659827644325022, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 153.59 seconds\n","Random Forest Training Time: 0.19 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:18:26,131] Trial 38 finished with value: 0.0017977308640955132 and parameters: {'lstm_units': 48, 'lstm_layers': 2, 'lstm_learning_rate': 0.0007884150451225468, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 48.79 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:20:11,905] Trial 39 finished with value: 0.0016811128603385866 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0004688816540658538, 'lstm_batch_size': 16, 'lstm_epochs': 10, 'rf_n_estimators': 50, 'rf_max_depth': 8, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 2, 'rf_max_features': 'sqrt'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 103.64 seconds\n","Random Forest Training Time: 0.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:21:57,634] Trial 40 finished with value: 0.0022762177342744746 and parameters: {'lstm_units': 48, 'lstm_layers': 5, 'lstm_learning_rate': 0.0012210838847022522, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 5, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 103.56 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:24:28,417] Trial 41 finished with value: 0.0016165513466282957 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0007370563146342471, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 147.87 seconds\n","Random Forest Training Time: 0.19 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:26:58,366] Trial 42 finished with value: 0.0016029022929078649 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.00029571041992242347, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 147.05 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:27:54,624] Trial 43 finished with value: 0.001605520331196916 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0017148853930341347, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'rf_n_estimators': 100, 'rf_max_depth': 8, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 53.35 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:28:31,093] Trial 44 finished with value: 0.001812006149186594 and parameters: {'lstm_units': 48, 'lstm_layers': 2, 'lstm_learning_rate': 0.0005723736391850592, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 35.30 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:29:49,661] Trial 45 finished with value: 0.0018325764522674466 and parameters: {'lstm_units': 32, 'lstm_layers': 5, 'lstm_learning_rate': 0.0008842661673053253, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 7, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 2, 'rf_max_features': 'sqrt'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 75.67 seconds\n","Random Forest Training Time: 0.17 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:30:18,079] Trial 46 finished with value: 0.0015969822813688818 and parameters: {'lstm_units': 128, 'lstm_layers': 5, 'lstm_learning_rate': 0.000652486155323684, 'lstm_batch_size': 64, 'lstm_epochs': 20, 'rf_n_estimators': 50, 'rf_max_depth': 9, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 2, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 25.50 seconds\n","Random Forest Training Time: 0.18 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:32:02,975] Trial 47 finished with value: 0.0018887373499411133 and parameters: {'lstm_units': 48, 'lstm_layers': 5, 'lstm_learning_rate': 0.001587553829945737, 'lstm_batch_size': 16, 'lstm_epochs': 30, 'rf_n_estimators': 100, 'rf_max_depth': 6, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 101.94 seconds\n","Random Forest Training Time: 0.17 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:32:48,492] Trial 48 finished with value: 0.001656200531021352 and parameters: {'lstm_units': 32, 'lstm_layers': 2, 'lstm_learning_rate': 0.00016830923853024038, 'lstm_batch_size': 16, 'lstm_epochs': 20, 'rf_n_estimators': 50, 'rf_max_depth': 8, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 1, 'rf_max_features': 'log2'}. Best is trial 27 with value: 0.0015715748016958174.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 44.41 seconds\n","Random Forest Training Time: 0.12 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-29 10:34:43,190] Trial 49 finished with value: 0.0012963706389375908 and parameters: {'lstm_units': 112, 'lstm_layers': 5, 'lstm_learning_rate': 0.0011037669069421693, 'lstm_batch_size': 16, 'lstm_epochs': 40, 'rf_n_estimators': 100, 'rf_max_depth': 10, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}. Best is trial 49 with value: 0.0012963706389375908.\n"]},{"output_type":"stream","name":"stdout","text":["Bi-LSTM Training Time: 111.60 seconds\n","Random Forest Training Time: 0.35 seconds\n","Best hyperparameters: {'lstm_units': 112, 'lstm_layers': 5, 'lstm_learning_rate': 0.0011037669069421693, 'lstm_batch_size': 16, 'lstm_epochs': 40, 'rf_n_estimators': 100, 'rf_max_depth': 10, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt'}\n"]},{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-63a643994400>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m# Train final Bi-LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m final_lstm, lstm_train_time = train_bi_lstm(X_train_r, Y_train, X_val_r, Y_val,\n\u001b[0m\u001b[1;32m    102\u001b[0m                                           units, layers, learning_rate, batch_size, epochs)\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import time\n","import joblib\n","\n","# Early stopping callback\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Function to train Bi-LSTM model\n","def train_bi_lstm(X_train, Y_train, X_val, Y_val, units, layers, learning_rate, batch_size, epochs):\n","    model = keras.Sequential()\n","    for _ in range(layers - 1):\n","        model.add(Bidirectional(LSTM(units, return_sequences=True)))\n","    model.add(Bidirectional(LSTM(units)))\n","    model.add(Dense(1))\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","    start_time = time.time()\n","    history = model.fit(X_train, Y_train,\n","                       validation_data=(X_val, Y_val),\n","                       epochs=epochs,\n","                       batch_size=batch_size,\n","                       verbose=0,\n","                       callbacks=[early_stopping])\n","    lstm_train_time = time.time() - start_time\n","    return model, history, lstm_train_time\n","\n","# Your best parameters from Optuna\n","best_params = {\n","    'lstm_units': 112,\n","    'lstm_layers': 5,\n","    'lstm_learning_rate': 0.0011037669069421693,\n","    'lstm_batch_size': 16,\n","    'lstm_epochs': 40,\n","    'rf_n_estimators': 100,\n","    'rf_max_depth': 10,\n","    'rf_min_samples_split': 4,\n","    'rf_min_samples_leaf': 1,\n","    'rf_max_features': 'sqrt'\n","}\n","\n","# Prepare your data (make sure these are defined)\n","# X_train, Y_train, X_val, Y_val, X_test, Y_test should be defined\n","\n","# Reshape input for LSTM\n","X_train_r = np.expand_dims(X_train, axis=-1)\n","X_val_r = np.expand_dims(X_val, axis=-1)\n","X_test_r = np.expand_dims(X_test, axis=-1)\n","\n","# Train final Bi-LSTM model with best parameters\n","final_lstm, _, lstm_train_time = train_bi_lstm(\n","    X_train_r, Y_train, X_val_r, Y_val,\n","    units=best_params['lstm_units'],\n","    layers=best_params['lstm_layers'],\n","    learning_rate=best_params['lstm_learning_rate'],\n","    batch_size=best_params['lstm_batch_size'],\n","    epochs=best_params['lstm_epochs']\n",")\n","\n","# Generate predictions from Bi-LSTM\n","start_time = time.time()\n","Y_train_pred_lstm = final_lstm.predict(X_train_r, verbose=0).flatten()\n","lstm_train_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_lstm = final_lstm.predict(X_val_r, verbose=0).flatten()\n","lstm_val_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_lstm = final_lstm.predict(X_test_r, verbose=0).flatten()\n","lstm_test_pred_time = time.time() - start_time\n","\n","# Prepare data for Random Forest\n","X_train_rf = np.column_stack([Y_train_pred_lstm])\n","X_val_rf = np.column_stack([Y_val_pred_lstm])\n","X_test_rf = np.column_stack([Y_test_pred_lstm])\n","\n","# Train final Random Forest model with best parameters\n","rf_params = {\n","    \"n_estimators\": best_params['rf_n_estimators'],\n","    \"max_depth\": best_params['rf_max_depth'],\n","    \"min_samples_split\": best_params['rf_min_samples_split'],\n","    \"min_samples_leaf\": best_params['rf_min_samples_leaf'],\n","    \"max_features\": best_params['rf_max_features'],\n","    \"random_state\": 42,\n","    \"n_jobs\": -1\n","}\n","\n","start_time = time.time()\n","final_rf = RandomForestRegressor(**rf_params)\n","final_rf.fit(X_train_rf, Y_train)\n","rf_train_time = time.time() - start_time\n","\n","# Generate predictions from Random Forest\n","start_time = time.time()\n","Y_train_pred_rf = final_rf.predict(X_train_rf)\n","rf_train_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_val_pred_rf = final_rf.predict(X_val_rf)\n","rf_val_pred_time = time.time() - start_time\n","\n","start_time = time.time()\n","Y_test_pred_rf = final_rf.predict(X_test_rf)\n","rf_test_pred_time = time.time() - start_time\n","\n","# Compute Metrics\n","def compute_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / np.abs(y_true))) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","metrics_train = compute_metrics(Y_train, Y_train_pred_rf)\n","metrics_val = compute_metrics(Y_val, Y_val_pred_rf)\n","metrics_test = compute_metrics(Y_test, Y_test_pred_rf)\n","\n","# Print results\n","print(\"\\n=== Final Model Performance ===\")\n","print(f\"Bi-LSTM Training Time: {lstm_train_time:.2f} seconds\")\n","print(f\"Random Forest Training Time: {rf_train_time:.2f} seconds\")\n","\n","print(\"\\n=== Prediction Times ===\")\n","print(f\"Bi-LSTM Train: {lstm_train_pred_time:.4f}s\")\n","print(f\"Bi-LSTM Val: {lstm_val_pred_time:.4f}s\")\n","print(f\"Bi-LSTM Test: {lstm_test_pred_time:.4f}s\")\n","print(f\"RF Train: {rf_train_pred_time:.4f}s\")\n","print(f\"RF Val: {rf_val_pred_time:.4f}s\")\n","print(f\"RF Test: {rf_test_pred_time:.4f}s\")\n","\n","print(\"\\n=== Performance Metrics ===\")\n","print(\"\\nTrain Set:\")\n","print(f\"MAE: {metrics_train[0]:.4f}, MSE: {metrics_train[1]:.4f}, RMSE: {metrics_train[2]:.4f}\")\n","print(f\"R²: {metrics_train[3]:.4f}, MAPE: {metrics_train[4]:.2f}%\")\n","\n","print(\"\\nValidation Set:\")\n","print(f\"MAE: {metrics_val[0]:.4f}, MSE: {metrics_val[1]:.4f}, RMSE: {metrics_val[2]:.4f}\")\n","print(f\"R²: {metrics_val[3]:.4f}, MAPE: {metrics_val[4]:.2f}%\")\n","\n","print(\"\\nTest Set:\")\n","print(f\"MAE: {metrics_test[0]:.4f}, MSE: {metrics_test[1]:.4f}, RMSE: {metrics_test[2]:.4f}\")\n","print(f\"R²: {metrics_test[3]:.4f}, MAPE: {metrics_test[4]:.2f}%\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTpzlAEne_Nl","executionInfo":{"status":"ok","timestamp":1743245416621,"user_tz":-330,"elapsed":268994,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"cefaffe4-815d-444d-921e-829c8b253423"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Final Model Performance ===\n","Bi-LSTM Training Time: 249.82 seconds\n","Random Forest Training Time: 0.76 seconds\n","\n","=== Prediction Times ===\n","Bi-LSTM Train: 11.2661s\n","Bi-LSTM Val: 1.3353s\n","Bi-LSTM Test: 0.9244s\n","RF Train: 0.0753s\n","RF Val: 0.0451s\n","RF Test: 0.0458s\n","\n","=== Performance Metrics ===\n","\n","Train Set:\n","MAE: 0.0024, MSE: 0.0000, RMSE: 0.0034\n","R²: 0.9999, MAPE: 0.78%\n","\n","Validation Set:\n","MAE: 0.1377, MSE: 0.0246, RMSE: 0.1570\n","R²: -3.1897, MAPE: 7.71%\n","\n","Test Set:\n","MAE: 0.4060, MSE: 0.1709, RMSE: 0.4134\n","R²: -27.3182, MAPE: 20.02%\n"]}]},{"cell_type":"markdown","source":["## BOHB"],"metadata":{"id":"UA4RDkuZXHto"}},{"cell_type":"code","source":["!pip install ConfigSpace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHZKQWHJeO1O","executionInfo":{"status":"ok","timestamp":1743245949605,"user_tz":-330,"elapsed":10820,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"fce69942-eb20-49aa-d0b1-2362930bae32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ConfigSpace\n","  Downloading configspace-1.2.1.tar.gz (130 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/131.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (2.0.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (3.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (1.14.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace) (10.6.0)\n","Building wheels for collected packages: ConfigSpace\n","  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ConfigSpace: filename=configspace-1.2.1-py3-none-any.whl size=115990 sha256=5b2b296f16db77a4fe8fdc5a6d402a7964b08bb216683cd35607e8f00d0084e8\n","  Stored in directory: /root/.cache/pip/wheels/11/0f/36/d5027c3eeb038827889830f7efbe6a1bad8956b3eb44ab2f44\n","Successfully built ConfigSpace\n","Installing collected packages: ConfigSpace\n","Successfully installed ConfigSpace-1.2.1\n"]}]},{"cell_type":"code","source":["!pip install hpbandster"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2UHtYiTefE7","executionInfo":{"status":"ok","timestamp":1743245972213,"user_tz":-330,"elapsed":22605,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"652906cb-8d48-4e2c-9462-424146b4a1c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hpbandster\n","  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Pyro4 (from hpbandster)\n","  Downloading Pyro4-4.82-py2.py3-none-any.whl.metadata (2.2 kB)\n","Collecting serpent (from hpbandster)\n","  Downloading serpent-1.41-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hpbandster) (2.0.2)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hpbandster) (1.14.1)\n","Collecting netifaces (from hpbandster)\n","  Downloading netifaces-0.11.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (3.2.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->hpbandster) (10.6.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n","Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading serpent-1.41-py3-none-any.whl (9.6 kB)\n","Building wheels for collected packages: hpbandster, netifaces\n","  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=79986 sha256=cc864f829393e738fc109fda418dfc1794dd24be8b546bc195877553245639d0\n","  Stored in directory: /root/.cache/pip/wheels/fb/da/7d/af80a6b0a6898aaf2e1e93ab00cdf03251624e67f0641e9f0b\n","  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for netifaces: filename=netifaces-0.11.0-cp311-cp311-linux_x86_64.whl size=35184 sha256=60c99ea5be3c4c0ef6f0f5aa4d52e42c1eb7efe3fdfa2b5593d6aa38c89075a8\n","  Stored in directory: /root/.cache/pip/wheels/40/85/29/648c19bbbb5f1d30e33bfb343fd7fb54296b402f7205d8e46f\n","Successfully built hpbandster netifaces\n","Installing collected packages: netifaces, serpent, Pyro4, hpbandster\n","Successfully installed Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import time\n","\n","# Check for GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define Bi-LSTM Model\n","class BiLSTMModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super(BiLSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","# Function to calculate metrics\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Convert datasets to PyTorch tensors and move to device\n","Y_train_torch = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_val_torch = torch.tensor(Y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","Y_test_torch = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","X_train_torch = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_val_torch = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n","X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n","\n","# Bi-LSTM Configurations\n","lstm_layers = [2, 3, 5]\n","hidden_dim = 64\n","output_dim = 1\n","input_dim = X_train.shape[1]\n","\n","# Dictionary to store LSTM feature representations\n","lstm_features = []\n","\n","for num_layers in lstm_layers:\n","    print(f\"Training Bi-LSTM with {num_layers} layers...\")\n","\n","    lstm_model = BiLSTMModel(input_dim, hidden_dim, num_layers, output_dim).to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n","    num_epochs = 35\n","\n","    start_time = time.time()\n","    for epoch in range(num_epochs):\n","        lstm_model.train()\n","        optimizer.zero_grad()\n","        outputs = lstm_model(X_train_torch)\n","        loss = criterion(outputs, Y_train_torch)\n","        loss.backward()\n","        optimizer.step()\n","    train_time = time.time() - start_time\n","\n","    # Extract Feature Representations\n","    lstm_model.eval()\n","    with torch.no_grad():\n","        val_start = time.time()\n","        train_features = lstm_model(X_train_torch).cpu().numpy()\n","        val_features = lstm_model(X_val_torch).cpu().numpy()\n","        val_time = time.time() - val_start\n","\n","        test_start = time.time()\n","        test_features = lstm_model(X_test_torch).cpu().numpy()\n","        test_time = time.time() - test_start\n","\n","    lstm_features.append((train_features, val_features, test_features, train_time, val_time, test_time))\n","\n","# Concatenate Features from All Layers\n","final_train_features = np.hstack([feat[0] for feat in lstm_features])\n","final_val_features = np.hstack([feat[1] for feat in lstm_features])\n","final_test_features = np.hstack([feat[2] for feat in lstm_features])\n","\n","# Record Time for Each Stage\n","total_train_time = sum([feat[3] for feat in lstm_features])\n","total_val_time = sum([feat[4] for feat in lstm_features])\n","total_test_time = sum([feat[5] for feat in lstm_features])\n","\n","# Define ConfigSpace for BOHB\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"n_estimators\", 50, 500, default_value=100))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"max_depth\", 3, 15, default_value=6))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_split\", 2, 10, default_value=2))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 5, default_value=1))\n","    return cs\n","\n","# BOHB Worker for Random Forest\n","class RFWorker(Worker):\n","    def compute(self, config, budget, **kwargs):\n","        model = RandomForestRegressor(\n","            n_estimators=config[\"n_estimators\"],\n","            max_depth=config[\"max_depth\"],\n","            min_samples_split=config[\"min_samples_split\"],\n","            min_samples_leaf=config[\"min_samples_leaf\"],\n","            random_state=42\n","        )\n","        model.fit(final_train_features, Y_train)\n","        Y_val_pred = model.predict(final_val_features)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Run BOHB\n","NS = hpns.NameServer(run_id=\"bilstm_rf_bohb\", host=\"127.0.0.2\", port=None)\n","NS.start()\n","\n","worker = RFWorker(nameserver=\"127.0.0.2\", run_id=\"bilstm_rf_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(configspace=get_config_space(), run_id=\"bilstm_rf_bohb\", nameserver=\"127.0.0.2\", min_budget=1, max_budget=3)\n","res = bohb.run(n_iterations=50)\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Train Best Random Forest Model\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","best_rf_model = RandomForestRegressor(\n","    n_estimators=best_params[\"n_estimators\"],\n","    max_depth=best_params[\"max_depth\"],\n","    min_samples_split=best_params[\"min_samples_split\"],\n","    min_samples_leaf=best_params[\"min_samples_leaf\"],\n","    random_state=42\n",")\n","\n","best_rf_model.fit(final_train_features, Y_train)\n","\n","# Predictions\n","Y_train_pred = best_rf_model.predict(final_train_features)\n","Y_val_pred = best_rf_model.predict(final_val_features)\n","Y_test_pred = best_rf_model.predict(final_test_features)\n","\n","# Calculate Metrics\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print Results\n","print(\"Train Metrics:\", train_metrics, \"Time:\", total_train_time)\n","print(\"Validation Metrics:\", val_metrics, \"Time:\", total_val_time)\n","print(\"Test Metrics:\", test_metrics, \"Time:\", total_test_time)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YDjRPSqdPhUg","executionInfo":{"status":"ok","timestamp":1743253473146,"user_tz":-330,"elapsed":980496,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"9066a7a8-743e-46c3-abe8-55ea6d4a7336"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Bi-LSTM with 2 layers...\n","Training Bi-LSTM with 3 layers...\n","Training Bi-LSTM with 5 layers...\n","Train Metrics: (0.001837063582687255, 6.381967954927262e-06, 0.002526255718435341, 0.9999635359886802, 0.5868025059427056) Time: 78.8131046295166\n","Validation Metrics: (0.13749478751172917, 0.024583993566702475, 0.1567928364648796, -3.179854120953027, 7.696239102805483) Time: 0.9832754135131836\n","Test Metrics: (0.40582703452842817, 0.1707306523451361, 0.4131956586716953, -27.28975327277023, 20.012668792602188) Time: 0.1340954303741455\n"]}]}]}