{"cells":[{"cell_type":"markdown","source":["## Initial Code"],"metadata":{"id":"5ebGneEwoKEe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WY7I5C1zqFJt"},"outputs":[],"source":["# Importing necessary libraries for data analysis and manipulation\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# For handling warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3422,"status":"ok","timestamp":1734285385047,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"},"user_tz":-330},"id":"3RKq8vfwqVHB","outputId":"d8483db4-602f-478e-90a9-af23d46947ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4yeLMDyqd2o"},"outputs":[],"source":["df_aapl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/stocks/AAPL.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHvcgRGPruCy"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import boxcox\n","\n","df_aapl['Close_log'] = np.log(df_aapl['Close'] + 1)\n","df_aapl['Close_sqrt'] = np.sqrt(df_aapl['Close'])\n","df_aapl['Close_boxcox'], _ = boxcox(df_aapl['Close'] + 1)\n"]},{"cell_type":"markdown","metadata":{"id":"lLz5cmQlryah"},"source":["This code calculates the skewness of the 'Close' column in the `df_aapl` DataFrame before and after applying various transformations:\n","\n","1. **Original Skewness**: Calculates the skewness of the original 'Close' data.\n","2. **Log Transformation Skewness**: Calculates the skewness of the 'Close_log' column after applying the log transformation.\n","3. **Square Root Transformation Skewness**: Calculates the skewness of the 'Close_sqrt' column after applying the square root transformation.\n","4. **Box-Cox Transformation Skewness**: Calculates the skewness of the 'Close_boxcox' column after applying the Box-Cox transformation.\n","\n","The printed results help assess how each transformation affects the distribution's symmetry and the success of skewness correction.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1734285385048,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"},"user_tz":-330},"id":"DIPGiQydr2K0","outputId":"102c14c0-2576-4c90-da0f-9164b93a4e27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Skewness: 2.5045276102319933\n","Log Transformation Skewness: 0.8535555176510303\n","Square Root Transformation Skewness: 1.6211545809555206\n","Box-Cox Transformation Skewness: 0.43527466713563334\n"]}],"source":["\n","skew_original = df_aapl['Close'].skew()\n","skew_log = df_aapl['Close_log'].skew()\n","skew_sqrt = df_aapl['Close_sqrt'].skew()\n","skew_boxcox = pd.Series(df_aapl['Close_boxcox']).skew()\n","\n","print(f\"Original Skewness: {skew_original}\")\n","print(f\"Log Transformation Skewness: {skew_log}\")\n","print(f\"Square Root Transformation Skewness: {skew_sqrt}\")\n","print(f\"Box-Cox Transformation Skewness: {skew_boxcox}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"De4W27wEr9-p"},"outputs":[],"source":["\n","df_aapl['Open_log'] = np.log(df_aapl['Open'])\n","df_aapl['High_log'] = np.log(df_aapl['High'])\n","df_aapl['Low_log'] = np.log(df_aapl['Low'])\n","df_aapl['Adj Close_log'] = np.log(df_aapl['Adj Close'])\n","df_aapl['Volume_log'] = np.log(df_aapl['Volume'])\n","\n","\n","df_aapl['Open_sqrt'] = np.sqrt(df_aapl['Open'])\n","df_aapl['High_sqrt'] = np.sqrt(df_aapl['High'])\n","df_aapl['Low_sqrt'] = np.sqrt(df_aapl['Low'])\n","df_aapl['Adj Close_sqrt'] = np.sqrt(df_aapl['Adj Close'])\n","df_aapl['Volume_sqrt'] = np.sqrt(df_aapl['Volume'])\n","\n","from scipy.stats import boxcox\n","df_aapl['Open_boxcox'], _ = boxcox(df_aapl['Open'])\n","df_aapl['High_boxcox'], _ = boxcox(df_aapl['High'])\n","df_aapl['Low_boxcox'], _ = boxcox(df_aapl['Low'])\n","df_aapl['Adj Close_boxcox'], _ = boxcox(df_aapl['Adj Close'])"]},{"cell_type":"markdown","source":["This helps compare how the transformations reduce skewness in the data, aiming for a more normal distribution."],"metadata":{"id":"2XrZQHaDAigS"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1734285385739,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"},"user_tz":-330},"id":"of1KONYmsC8t","outputId":"d482a09d-8993-4c50-a554-183a92b02d74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness Before Transformation:\n"," Open         2.504632\n","High         2.502208\n","Low          2.506714\n","Adj Close    2.550677\n","Volume       3.565699\n","dtype: float64\n","\n","Skewness After Transformation:\n"," Open_log            0.482872\n","High_log            0.481997\n","Low_log             0.484246\n","Adj Close_log       0.494009\n","Open_sqrt           1.620771\n","High_sqrt           1.621456\n","Low_sqrt            1.620661\n","Adj Close_sqrt      1.679402\n","Volume_sqrt         1.299776\n","Open_boxcox         0.181226\n","High_boxcox         0.179749\n","Low_boxcox          0.182882\n","Adj Close_boxcox    0.180085\n","dtype: float64\n"]}],"source":["\n","skewness_before = df_aapl[['Open', 'High', 'Low', 'Adj Close', 'Volume']].skew()\n","skewness_after = df_aapl[['Open_log', 'High_log', 'Low_log', 'Adj Close_log',\n","                          'Open_sqrt', 'High_sqrt', 'Low_sqrt', 'Adj Close_sqrt', 'Volume_sqrt',\n","                          'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox']].skew()\n","\n","print(\"Skewness Before Transformation:\\n\", skewness_before)\n","print(\"\\nSkewness After Transformation:\\n\", skewness_after)\n"]},{"cell_type":"markdown","source":["- Applied Box-Cox transformation to the 'Open', 'High', 'Low', 'Adj Close', and 'Close' columns.\n","- Recalculated skewness after the transformation to reduce skew and normalize the data for modeling."],"metadata":{"id":"zfEokf4iAmnv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1734285385739,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"},"user_tz":-330},"id":"s9oEP05csI66","outputId":"eba85ede-d4e5-4615-c737-4794c34c5ee0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness After Box-Cox Transformation:\n","Open_boxcox         0.435237\n","High_boxcox         0.433381\n","Low_boxcox          0.437331\n","Adj Close_boxcox    0.458762\n","Close_boxcox        0.435275\n","dtype: float64\n"]}],"source":["from scipy import stats\n","\n","df_aapl['Open_boxcox'], _ = stats.boxcox(df_aapl['Open'] + 1)\n","df_aapl['High_boxcox'], _ = stats.boxcox(df_aapl['High'] + 1)\n","df_aapl['Low_boxcox'], _ = stats.boxcox(df_aapl['Low'] + 1)\n","df_aapl['Adj Close_boxcox'], _ = stats.boxcox(df_aapl['Adj Close'] + 1)\n","df_aapl['Close_boxcox'], _ = stats.boxcox(df_aapl['Close'] + 1)\n","\n","skewness_after_boxcox = df_aapl[['Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox', 'Close_boxcox']].skew()\n","\n","print(\"Skewness After Box-Cox Transformation:\")\n","print(skewness_after_boxcox)\n"]},{"cell_type":"markdown","source":["Feature Selection"],"metadata":{"id":"uvZe7IzRAwHu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1734285385739,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"},"user_tz":-330},"id":"aczNHUI4rk8x","outputId":"6133d925-1d7b-43b3-f32e-2d9bb39fffc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["         Date      Open      High       Low  Adj Close     Close     Volume  \\\n","0  1980-12-12  0.128348  0.128906  0.128348   0.098943  0.128348  469033600   \n","1  1980-12-15  0.122210  0.122210  0.121652   0.093781  0.121652  175884800   \n","2  1980-12-16  0.113281  0.113281  0.112723   0.086898  0.112723  105728000   \n","3  1980-12-17  0.115513  0.116071  0.115513   0.089049  0.115513   86441600   \n","4  1980-12-18  0.118862  0.119420  0.118862   0.091630  0.118862   73449600   \n","\n","   Open_boxcox  High_boxcox  Low_boxcox  Adj Close_boxcox  Close_boxcox  \n","0     0.117689     0.118173    0.117674          0.092374      0.117689  \n","1     0.112503     0.112516    0.112016          0.087857      0.112030  \n","2     0.104886     0.104897    0.104395          0.081785      0.104407  \n","3     0.106798     0.107287    0.106786          0.083688      0.106798  \n","4     0.109657     0.110145    0.109644          0.085966      0.109657  \n"]}],"source":["\n","df_aapl_cleaned = df_aapl[['Date', 'Open', 'High', 'Low', 'Adj Close', 'Close', 'Volume',\n","                           'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox',\n","                           'Close_boxcox']]\n","\n","print(df_aapl_cleaned.head())\n"]},{"cell_type":"markdown","source":["### Train Validation Test Split\n","\n","The code splits the data into training, validation, and test sets. The features `X` and target `Y` are split as follows:\n","\n","- 70% for training (`X_train`, `Y_train`)\n","- 15% for validation (`X_val`, `Y_val`)\n","- 15% for testing (`X_test`, `Y_test`)\n","\n","The split is done using a 30% test size, followed by splitting the remaining 70% into validation and test sets without shuffling (time series data)."],"metadata":{"id":"chw5ijVT_JRM"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df_aapl_cleaned[['Open_boxcox', 'High_boxcox', 'Low_boxcox']]\n","Y = df_aapl_cleaned['Close_boxcox']\n","\n","X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, shuffle=False)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, shuffle=False)\n","\n","print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSztwxnoy8-U","executionInfo":{"status":"ok","timestamp":1734285385739,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"fe1119f6-33d3-4b61-9310-140de403c395"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (7736, 3), Validation set: (1658, 3), Test set: (1658, 3)\n"]}]},{"cell_type":"markdown","source":["## Decision Tree Regressor\n","\n","\n"],"metadata":{"id":"dcopnPrb15WC"}},{"cell_type":"markdown","source":["###**Initial Basic DTR**"],"metadata":{"id":"P9zGvbDMFoFA"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","def compute_metrics(actual, predicted, label):\n","    mae = mean_absolute_error(actual, predicted)\n","    mse = mean_squared_error(actual, predicted)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(actual, predicted)\n","    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n","    accuracy = 1 - (mape / 100)\n","\n","    print(f\"{label} MAE: {mae}\")\n","    print(f\"{label} MSE: {mse}\")\n","    print(f\"{label} RMSE: {rmse}\")\n","    print(f\"{label} R²: {r2}\")\n","    print(f\"{label} MAPE: {mape}%\")\n","    print(f\"{label} Accuracy: {accuracy * 100}%\\n\")\n","\n","dt_regressor = DecisionTreeRegressor(random_state=42)\n","\n","dt_regressor.fit(X_train, Y_train)\n","\n","Y_train_pred = dt_regressor.predict(X_train)\n","Y_val_pred = dt_regressor.predict(X_val)\n","Y_test_pred = dt_regressor.predict(X_test)\n","\n","compute_metrics(Y_train, Y_train_pred, \"Training\")\n","compute_metrics(Y_val, Y_val_pred, \"Validation\")\n","compute_metrics(Y_test, Y_test_pred, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdsOeqGt13_C","executionInfo":{"status":"ok","timestamp":1734285402940,"user_tz":-330,"elapsed":927,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"f3bbc71a-7c98-4ba7-ca53-ec175984feee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training MAE: 6.294350837355037e-05\n","Training MSE: 1.0289611088082219e-07\n","Training RMSE: 0.0003207742366226162\n","Training R²: 0.9999994120927935\n","Training MAPE: 0.025296519708453247%\n","Training Accuracy: 99.97470348029155%\n","\n","Validation MAE: 0.13517441496303997\n","Validation MSE: 0.02390980530996259\n","Validation RMSE: 0.15462795772421814\n","Validation R²: -3.065226342696154\n","Validation MAPE: 7.563909101395194%\n","Validation Accuracy: 92.4360908986048%\n","\n","Test MAE: 0.4033505341723914\n","Test MSE: 0.16872672380815157\n","Test RMSE: 0.4107635862733594\n","Test R²: -26.95770602109714\n","Test MAPE: 19.889610417803492%\n","Test Accuracy: 80.1103895821965%\n","\n"]}]},{"cell_type":"markdown","source":[" **Conclusion:**\n","- The model performs **exceptionally well on the training data** (with near-perfect R² and minimal error metrics), but **fails to generalize well to validation and test datasets**, as reflected by high error metrics and low R² values on both.\n","- The **overfitting issue** is evident, where the model fits the training data very well but struggles to generalize to unseen data."],"metadata":{"id":"zxR6tVIg2MJq"}},{"cell_type":"markdown","source":["###**Pruning**"],"metadata":{"id":"fk2b_mq05OwC"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","# Define the metrics function\n","def compute_metrics(actual, predicted, label):\n","    mae = mean_absolute_error(actual, predicted)\n","    mse = mean_squared_error(actual, predicted)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(actual, predicted)\n","    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n","    accuracy = 1 - (mape / 100)\n","\n","    print(f\"{label} MAE: {mae}\")\n","    print(f\"{label} MSE: {mse}\")\n","    print(f\"{label} RMSE: {rmse}\")\n","    print(f\"{label} R²: {r2}\")\n","    print(f\"{label} MAPE: {mape}%\")\n","    print(f\"{label} Accuracy: {accuracy * 100}%\\n\")\n","\n","\n","dt_regressor_pruned = DecisionTreeRegressor(\n","    random_state=42,\n","    max_depth=5,\n","    min_samples_split=10,\n","    min_samples_leaf=5,\n","    max_features='sqrt'\n",")\n","\n","dt_regressor_pruned.fit(X_train, Y_train)\n","\n","Y_train_pred = dt_regressor_pruned.predict(X_train)\n","Y_val_pred = dt_regressor_pruned.predict(X_val)\n","Y_test_pred = dt_regressor_pruned.predict(X_test)\n","\n","compute_metrics(Y_train, Y_train_pred, \"Training\")\n","compute_metrics(Y_val, Y_val_pred, \"Validation\")\n","compute_metrics(Y_test, Y_test_pred, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMTyQ0AG1-qz","executionInfo":{"status":"ok","timestamp":1734285402940,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"4605be46-ab84-4fcc-de3b-42f8b69a143a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training MAE: 0.010289240712896866\n","Training MSE: 0.00016927183542729895\n","Training RMSE: 0.013010451007835929\n","Training R²: 0.9990328484619886\n","Training MAPE: 3.661852663100275%\n","Training Accuracy: 96.33814733689972%\n","\n","Validation MAE: 0.17345221636020575\n","Validation MSE: 0.03596721479583069\n","Validation RMSE: 0.18965024333185204\n","Validation R²: -5.115268073742864\n","Validation MAPE: 9.755296125375532%\n","Validation Accuracy: 90.24470387462446%\n","\n","Test MAE: 0.4424893023879134\n","Test MSE: 0.20183185311874033\n","Test RMSE: 0.4492570011905661\n","Test R²: -32.443164709361746\n","Test MAPE: 21.834432754083227%\n","Test Accuracy: 78.16556724591676%\n","\n"]}]},{"cell_type":"markdown","source":["**Conclusion:**\n","- The model performs well on the **training data** (with a high R² and low error metrics), but struggles to generalize on both **validation** and **test data**.\n","- Despite using **pruning**, the model suffers from **overfitting**. It fits the training data extremely well, but its performance drops significantly on unseen data."],"metadata":{"id":"Xx_mTg1-2kh8"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","def compute_metrics(actual, predicted, label):\n","    mae = mean_absolute_error(actual, predicted)\n","    mse = mean_squared_error(actual, predicted)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(actual, predicted)\n","    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n","    accuracy = 1 - (mape / 100)\n","\n","    print(f\"{label} MAE: {mae}\")\n","    print(f\"{label} MSE: {mse}\")\n","    print(f\"{label} RMSE: {rmse}\")\n","    print(f\"{label} R²: {r2}\")\n","    print(f\"{label} MAPE: {mape}%\")\n","    print(f\"{label} Accuracy: {accuracy * 100}%\\n\")\n","\n","dt_regressor_pruned = DecisionTreeRegressor(\n","    random_state=42,\n","    max_depth=10,\n","    min_samples_split=2,\n","    min_samples_leaf=1,\n",")\n","\n","dt_regressor_pruned.fit(X_train, Y_train)\n","\n","Y_train_pred = dt_regressor_pruned.predict(X_train)\n","Y_val_pred = dt_regressor_pruned.predict(X_val)\n","Y_test_pred = dt_regressor_pruned.predict(X_test)\n","\n","compute_metrics(Y_train, Y_train_pred, \"Training\")\n","compute_metrics(Y_val, Y_val_pred, \"Validation\")\n","compute_metrics(Y_test, Y_test_pred, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xPpeZny82aLj","executionInfo":{"status":"ok","timestamp":1734285402940,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"3695851c-e42d-4725-c1a7-bdcb83cebed1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training MAE: 0.0016280691676729513\n","Training MSE: 5.646074075619677e-06\n","Training RMSE: 0.0023761468968941453\n","Training R²: 0.9999677405918582\n","Training MAPE: 0.5614076380114963%\n","Training Accuracy: 99.43859236198851%\n","\n","Validation MAE: 0.1351520248106317\n","Validation MSE: 0.023909535081898445\n","Validation RMSE: 0.15462708392095625\n","Validation R²: -3.0651803976024716\n","Validation MAPE: 7.562522311292043%\n","Validation Accuracy: 92.43747768870796%\n","\n","Test MAE: 0.4033505341723914\n","Test MSE: 0.16872672380815157\n","Test RMSE: 0.4107635862733594\n","Test R²: -26.95770602109714\n","Test MAPE: 19.889610417803492%\n","Test Accuracy: 80.1103895821965%\n","\n"]}]},{"cell_type":"markdown","source":["**Conclusion:**\n","- **Training performance** is outstanding, with very low error metrics and almost perfect R², but the model struggles significantly with **validation** and **test data**.\n","- Loosening the pruning parameters has allowed the model to fit the **training data** even more accurately but at the cost of generalizing well to unseen data, as indicated by the large discrepancy in validation and test metrics."],"metadata":{"id":"JwlW4GjH3Oh0"}},{"cell_type":"markdown","source":["###**Cross Validation**"],"metadata":{"id":"ttCtLoLa5Jvb"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import cross_val_score, KFold\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","def compute_metrics(actual, predicted, label):\n","    mae = mean_absolute_error(actual, predicted)\n","    mse = mean_squared_error(actual, predicted)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(actual, predicted)\n","    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n","    accuracy = 1 - (mape / 100)\n","\n","    print(f\"{label} MAE: {mae}\")\n","    print(f\"{label} MSE: {mse}\")\n","    print(f\"{label} RMSE: {rmse}\")\n","    print(f\"{label} R²: {r2}\")\n","    print(f\"{label} MAPE: {mape}%\")\n","    print(f\"{label} Accuracy: {accuracy * 100}%\\n\")\n","\n","dt_regressor = DecisionTreeRegressor(\n","    random_state=42,\n","    max_depth=10,\n","    min_samples_split=5,\n","    min_samples_leaf=3,\n","    max_features='sqrt'\n",")\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","train_mae_list, train_mse_list, train_rmse_list, train_r2_list, train_mape_list, train_accuracy_list = [], [], [], [], [], []\n","val_mae_list, val_mse_list, val_rmse_list, val_r2_list, val_mape_list, val_accuracy_list = [], [], [], [], [], []\n","\n","for train_index, val_index in kf.split(X):\n","    X_train_cv, X_val_cv = X.iloc[train_index], X.iloc[val_index]\n","    Y_train_cv, Y_val_cv = Y.iloc[train_index], Y.iloc[val_index]\n","\n","    dt_regressor.fit(X_train_cv, Y_train_cv)\n","\n","    Y_train_pred_cv = dt_regressor.predict(X_train_cv)\n","    Y_val_pred_cv = dt_regressor.predict(X_val_cv)\n","\n","    compute_metrics(Y_train_cv, Y_train_pred_cv, \"Train (CV)\")\n","\n","    compute_metrics(Y_val_cv, Y_val_pred_cv, \"Validation (CV)\")\n","\n","    train_mae_list.append(mean_absolute_error(Y_train_cv, Y_train_pred_cv))\n","    train_mse_list.append(mean_squared_error(Y_train_cv, Y_train_pred_cv))\n","    train_rmse_list.append(np.sqrt(mean_squared_error(Y_train_cv, Y_train_pred_cv)))\n","    train_r2_list.append(r2_score(Y_train_cv, Y_train_pred_cv))\n","    train_mape_list.append(np.mean(np.abs((Y_train_cv - Y_train_pred_cv) / Y_train_cv)) * 100)\n","    train_accuracy_list.append(1 - (np.mean(np.abs((Y_train_cv - Y_train_pred_cv) / Y_train_cv)) * 100) / 100)\n","\n","    val_mae_list.append(mean_absolute_error(Y_val_cv, Y_val_pred_cv))\n","    val_mse_list.append(mean_squared_error(Y_val_cv, Y_val_pred_cv))\n","    val_rmse_list.append(np.sqrt(mean_squared_error(Y_val_cv, Y_val_pred_cv)))\n","    val_r2_list.append(r2_score(Y_val_cv, Y_val_pred_cv))\n","    val_mape_list.append(np.mean(np.abs((Y_val_cv - Y_val_pred_cv) / Y_val_cv)) * 100)\n","    val_accuracy_list.append(1 - (np.mean(np.abs((Y_val_cv - Y_val_pred_cv) / Y_val_cv)) * 100) / 100)\n","\n","print(\"\\nAverage Cross-Validation Metrics:\")\n","\n","# Train metrics\n","print(\"\\nTraining Metrics:\")\n","print(f\"Average MAE (Train): {np.mean(train_mae_list)}\")\n","print(f\"Average MSE (Train): {np.mean(train_mse_list)}\")\n","print(f\"Average RMSE (Train): {np.mean(train_rmse_list)}\")\n","print(f\"Average R² (Train): {np.mean(train_r2_list)}\")\n","print(f\"Average MAPE (Train): {np.mean(train_mape_list)}%\")\n","print(f\"Average Accuracy (Train): {np.mean(train_accuracy_list) * 100}%\")\n","\n","# Validation metrics\n","print(\"\\nValidation Metrics:\")\n","print(f\"Average MAE (Validation): {np.mean(val_mae_list)}\")\n","print(f\"Average MSE (Validation): {np.mean(val_mse_list)}\")\n","print(f\"Average RMSE (Validation): {np.mean(val_rmse_list)}\")\n","print(f\"Average R² (Validation): {np.mean(val_r2_list)}\")\n","print(f\"Average MAPE (Validation): {np.mean(val_mape_list)}%\")\n","print(f\"Average Accuracy (Validation): {np.mean(val_accuracy_list) * 100}%\")\n","\n","# Test metrics (use your actual test set here)\n","print(\"\\nTest Metrics:\")\n","compute_metrics(Y_test, dt_regressor.predict(X_test), \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44AKa8yi4FqE","executionInfo":{"status":"ok","timestamp":1734285403693,"user_tz":-330,"elapsed":761,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"a986f0b7-4e84-4cb2-8c42-7399e8758721"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train (CV) MAE: 0.002139978806416879\n","Train (CV) MSE: 1.0324806171414852e-05\n","Train (CV) RMSE: 0.003213223641674331\n","Train (CV) R²: 0.9999813982055806\n","Train (CV) MAPE: 0.6222887665286777%\n","Train (CV) Accuracy: 99.37771123347132%\n","\n","Validation (CV) MAE: 0.0029264363730980734\n","Validation (CV) MSE: 2.205618993019325e-05\n","Validation (CV) RMSE: 0.004696401806723234\n","Validation (CV) R²: 0.9999610789933855\n","Validation (CV) MAPE: 0.7917693243148141%\n","Validation (CV) Accuracy: 99.20823067568519%\n","\n","Train (CV) MAE: 0.0021166976118361432\n","Train (CV) MSE: 1.0419272443285559e-05\n","Train (CV) RMSE: 0.003227889781774706\n","Train (CV) R²: 0.9999813723243124\n","Train (CV) MAPE: 0.6019936836674006%\n","Train (CV) Accuracy: 99.3980063163326%\n","\n","Validation (CV) MAE: 0.002811897664986526\n","Validation (CV) MSE: 1.961151698506994e-05\n","Validation (CV) RMSE: 0.004428489244095546\n","Validation (CV) R²: 0.9999642647902678\n","Validation (CV) MAPE: 0.7642266338052603%\n","Validation (CV) Accuracy: 99.23577336619473%\n","\n","Train (CV) MAE: 0.0021121307347430223\n","Train (CV) MSE: 9.826030194570049e-06\n","Train (CV) RMSE: 0.0031346499317419876\n","Train (CV) R²: 0.9999823876302305\n","Train (CV) MAPE: 0.6185247405356318%\n","Train (CV) Accuracy: 99.38147525946437%\n","\n","Validation (CV) MAE: 0.0029087588539874055\n","Validation (CV) MSE: 2.0358925960871147e-05\n","Validation (CV) RMSE: 0.004512086652633252\n","Validation (CV) R²: 0.9999633335653041\n","Validation (CV) MAPE: 0.7846763967412116%\n","Validation (CV) Accuracy: 99.21532360325878%\n","\n","Train (CV) MAE: 0.0021165596868443284\n","Train (CV) MSE: 9.989420462669509e-06\n","Train (CV) RMSE: 0.00316060444577766\n","Train (CV) R²: 0.9999820455876128\n","Train (CV) MAPE: 0.618529036501689%\n","Train (CV) Accuracy: 99.3814709634983%\n","\n","Validation (CV) MAE: 0.002951044774815073\n","Validation (CV) MSE: 2.1422100575074174e-05\n","Validation (CV) RMSE: 0.00462840151402989\n","Validation (CV) R²: 0.9999618243956004\n","Validation (CV) MAPE: 0.7944698511034808%\n","Validation (CV) Accuracy: 99.20553014889651%\n","\n","Train (CV) MAE: 0.0020912047454649607\n","Train (CV) MSE: 9.877813984382205e-06\n","Train (CV) RMSE: 0.003142898977756397\n","Train (CV) R²: 0.9999823025128728\n","Train (CV) MAPE: 0.6051553482118283%\n","Train (CV) Accuracy: 99.39484465178818%\n","\n","Validation (CV) MAE: 0.0029118067940831316\n","Validation (CV) MSE: 2.0675333754831173e-05\n","Validation (CV) RMSE: 0.00454701371834649\n","Validation (CV) R²: 0.999962690607797\n","Validation (CV) MAPE: 0.7432864846432672%\n","Validation (CV) Accuracy: 99.25671351535674%\n","\n","\n","Average Cross-Validation Metrics:\n","\n","Training Metrics:\n","Average MAE (Train): 0.0021153143170610663\n","Average MSE (Train): 1.0087468651264435e-05\n","Average RMSE (Train): 0.003175853355745017\n","Average R² (Train): 0.9999819012521218\n","Average MAPE (Train): 0.6132983150890454%\n","Average Accuracy (Train): 99.38670168491095%\n","\n","Validation Metrics:\n","Average MAE (Validation): 0.002901988892194042\n","Average MSE (Validation): 2.0824813441207936e-05\n","Average RMSE (Validation): 0.0045624785871656815\n","Average R² (Validation): 0.999962638470471\n","Average MAPE (Validation): 0.7756857381216068%\n","Average Accuracy (Validation): 99.22431426187839%\n","\n","Test Metrics:\n","Test MAE: 0.001036593479045731\n","Test MSE: 2.139734937428624e-06\n","Test RMSE: 0.0014627832845054746\n","Test R²: 0.9996454498789906\n","Test MAPE: 0.05198349169569901%\n","Test Accuracy: 99.9480165083043%\n","\n"]}]},{"cell_type":"markdown","source":["**Conclusion:**\n","- The model demonstrates **exceptional performance** across **training**, **validation**, and **test data**.\n","- K-fold cross-validation provides consistent and reliable metrics, showing the model's **ability to generalize well** to new data.\n","- **Test performance** is particularly strong, with near-perfect accuracy and very low error across all metrics."],"metadata":{"id":"HSrdgByHHUCC"}},{"cell_type":"markdown","source":["###**Hyperparameter tuning using GridSearchCV**"],"metadata":{"id":"7DDwcRmg6ij2"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","dt_regressor = DecisionTreeRegressor(random_state=42)\n","\n","param_grid = {\n","    'max_depth': [5, 10, 15, 20, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['auto', 'sqrt', 'log2', None]\n","}\n","\n","grid_search = GridSearchCV(estimator=dt_regressor, param_grid=param_grid,\n","                           cv=5, scoring='neg_mean_squared_error',\n","                           verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, Y_train)\n","\n","print(\"Best parameters found: \", grid_search.best_params_)\n","\n","best_dt_regressor = grid_search.best_estimator_\n","\n","Y_train_pred = best_dt_regressor.predict(X_train)\n","Y_val_pred = best_dt_regressor.predict(X_val)\n","Y_test_pred = best_dt_regressor.predict(X_test)\n","\n","def compute_metrics(actual, predicted, label):\n","    mae = mean_absolute_error(actual, predicted)\n","    mse = mean_squared_error(actual, predicted)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(actual, predicted)\n","    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n","    accuracy = 1 - (mape / 100)\n","\n","    print(f\"{label} MAE: {mae}\")\n","    print(f\"{label} MSE: {mse}\")\n","    print(f\"{label} RMSE: {rmse}\")\n","    print(f\"{label} R²: {r2}\")\n","    print(f\"{label} MAPE: {mape}%\")\n","    print(f\"{label} Accuracy: {accuracy * 100}%\\n\")\n","\n","print(\"Training Metrics:\")\n","compute_metrics(Y_train, Y_train_pred, \"Training\")\n","\n","print(\"Validation Metrics:\")\n","compute_metrics(Y_val, Y_val_pred, \"Validation\")\n","\n","print(\"Test Metrics:\")\n","compute_metrics(Y_test, Y_test_pred, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zs3fonHN4-ir","executionInfo":{"status":"ok","timestamp":1734285417649,"user_tz":-330,"elapsed":13962,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"60254c63-28b1-4909-b132-0555a36fddd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 180 candidates, totalling 900 fits\n","Best parameters found:  {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n","Training Metrics:\n","Training MAE: 0.001112201980807158\n","Training MSE: 3.423285795228113e-06\n","Training RMSE: 0.0018502123648998006\n","Training R²: 0.9999804407147028\n","Training MAPE: 0.34379328677675175%\n","Training Accuracy: 99.65620671322326%\n","\n","Validation Metrics:\n","Validation MAE: 0.13920448379915923\n","Validation MSE: 0.02507657173150102\n","Validation RMSE: 0.15835583895613392\n","Validation R²: -3.263603934279261\n","Validation MAPE: 7.793954154789697%\n","Validation Accuracy: 92.2060458452103%\n","\n","Test Metrics:\n","Test MAE: 0.40760882633414786\n","Test MSE: 0.1721800256964996\n","Test RMSE: 0.41494581055422114\n","Test R²: -27.529911756012677\n","Test MAPE: 20.10120679878782%\n","Test Accuracy: 79.89879320121219%\n","\n"]}]},{"cell_type":"markdown","source":["**Conclusion:**\n","- The model shows **excellent performance on training data** but suffers from **overfitting** as indicated by the substantial drop in performance on validation and test data.\n","- **Validation and test metrics** reveal that the model struggles with generalization, as evidenced by the negative R² and high error rates.\n","- While GridSearchCV helped in optimizing hyperparameters, the model may need further adjustments, such as **regularization or pruning**, to improve generalization and avoid overfitting."],"metadata":{"id":"sgpfJrQ8H9xL"}},{"cell_type":"markdown","source":["###**Hyperband optimization using optuna**"],"metadata":{"id":"p2Hl_Qqk8lFG"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDHrvQeF57Q1","executionInfo":{"status":"ok","timestamp":1734285426920,"user_tz":-330,"elapsed":9281,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"12a04abf-16d3-4662-8e49-84b76be5d98f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"]}]},{"cell_type":"code","source":["import optuna\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","# Define the objective function\n","def objective(trial):\n","    max_depth = trial.suggest_int('max_depth', 3, 20)\n","    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n","    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n","    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n","\n","    model = DecisionTreeRegressor(\n","        max_depth=max_depth,\n","        min_samples_split=min_samples_split,\n","        min_samples_leaf=min_samples_leaf,\n","        max_features=max_features,\n","        random_state=42\n","    )\n","\n","    model.fit(X_train, Y_train)\n","\n","    Y_val_pred = model.predict(X_val)\n","    mae_val = mean_absolute_error(Y_val, Y_val_pred)\n","    mse_val = mean_squared_error(Y_val, Y_val_pred)\n","    rmse_val = np.sqrt(mse_val)\n","    r2_val = r2_score(Y_val, Y_val_pred)\n","\n","    # Calculate MAPE for validation\n","    mape_val = np.mean(np.abs((Y_val - Y_val_pred) / Y_val)) * 100\n","\n","    # Return the validation MAPE for optimization\n","    return mape_val\n","\n","study = optuna.create_study(direction='minimize')\n","\n","study.optimize(objective, n_trials=50)\n","\n","print(f\"Best trial: {study.best_trial.params}\")\n","\n","best_params = study.best_trial.params\n","final_model = DecisionTreeRegressor(**best_params, random_state=42)\n","final_model.fit(X_train, Y_train)\n","\n","# Evaluate on Train, Validation, and Test sets\n","# Train metrics\n","Y_train_pred = final_model.predict(X_train)\n","mae_train = mean_absolute_error(Y_train, Y_train_pred)\n","mse_train = mean_squared_error(Y_train, Y_train_pred)\n","rmse_train = np.sqrt(mse_train)\n","r2_train = r2_score(Y_train, Y_train_pred)\n","\n","# Calculate MAPE for training\n","mape_train = np.mean(np.abs((Y_train - Y_train_pred) / Y_train)) * 100\n","\n","# Validation metrics\n","Y_val_pred = final_model.predict(X_val)\n","mae_val = mean_absolute_error(Y_val, Y_val_pred)\n","mse_val = mean_squared_error(Y_val, Y_val_pred)\n","rmse_val = np.sqrt(mse_val)\n","r2_val = r2_score(Y_val, Y_val_pred)\n","\n","# Calculate MAPE for validation\n","mape_val = np.mean(np.abs((Y_val - Y_val_pred) / Y_val)) * 100\n","\n","# Test metrics\n","Y_test_pred = final_model.predict(X_test)\n","mae_test = mean_absolute_error(Y_test, Y_test_pred)\n","mse_test = mean_squared_error(Y_test, Y_test_pred)\n","rmse_test = np.sqrt(mse_test)\n","r2_test = r2_score(Y_test, Y_test_pred)\n","\n","# Calculate MAPE for test\n","mape_test = np.mean(np.abs((Y_test - Y_test_pred) / Y_test)) * 100\n","\n","# Print final model performance on all sets\n","print(\"Final Model Performance:\")\n","print(f\"Train MAE: {mae_train}\")\n","print(f\"Train MSE: {mse_train}\")\n","print(f\"Train RMSE: {rmse_train}\")\n","print(f\"Train R²: {r2_train}\")\n","print(f\"Train MAPE: {mape_train}\")\n","\n","print(f\"\\nValidation MAE: {mae_val}\")\n","print(f\"Validation MSE: {mse_val}\")\n","print(f\"Validation RMSE: {rmse_val}\")\n","print(f\"Validation R²: {r2_val}\")\n","print(f\"Validation MAPE: {mape_val}\")\n","\n","print(f\"\\nTest MAE: {mae_test}\")\n","print(f\"Test MSE: {mse_test}\")\n","print(f\"Test RMSE: {rmse_test}\")\n","print(f\"Test R²: {r2_test}\")\n","print(f\"Test MAPE: {mape_test}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDiiDwdP6zcD","executionInfo":{"status":"ok","timestamp":1734285430789,"user_tz":-330,"elapsed":3876,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"b29cf7e3-0b43-431c-f051-921c7e205186"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-12-15 17:52:58,771] A new study created in memory with name: no-name-7fbded31-5c22-43f0-a323-303965065e00\n","[I 2024-12-15 17:52:58,791] Trial 0 finished with value: 7.954401789416821 and parameters: {'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 0 with value: 7.954401789416821.\n","[I 2024-12-15 17:52:58,813] Trial 1 finished with value: 7.6954014170205 and parameters: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 1 with value: 7.6954014170205.\n","[I 2024-12-15 17:52:58,851] Trial 2 finished with value: 7.56248569491893 and parameters: {'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:58,870] Trial 3 finished with value: 8.18403485801272 and parameters: {'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:58,902] Trial 4 finished with value: 7.7843386511520425 and parameters: {'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:58,921] Trial 5 finished with value: 7.953979104136484 and parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:58,935] Trial 6 finished with value: 12.769876222259164 and parameters: {'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:58,952] Trial 7 finished with value: 7.983207464989938 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:58,974] Trial 8 finished with value: 7.785649987063252 and parameters: {'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:58,996] Trial 9 finished with value: 7.79661486750063 and parameters: {'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:59,050] Trial 10 finished with value: 7.981684501007212 and parameters: {'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 2 with value: 7.56248569491893.\n","[I 2024-12-15 17:52:59,111] Trial 11 finished with value: 7.562475610585287 and parameters: {'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,163] Trial 12 finished with value: 7.563719690994411 and parameters: {'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,210] Trial 13 finished with value: 7.784262914126661 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,257] Trial 14 finished with value: 8.280201801222356 and parameters: {'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,316] Trial 15 finished with value: 7.783086434432684 and parameters: {'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,369] Trial 16 finished with value: 7.782801332167959 and parameters: {'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,416] Trial 17 finished with value: 7.981914017677831 and parameters: {'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,482] Trial 18 finished with value: 7.692963274485673 and parameters: {'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,545] Trial 19 finished with value: 7.955267842057852 and parameters: {'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,642] Trial 20 finished with value: 7.785972273666282 and parameters: {'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,723] Trial 21 finished with value: 7.562475610585287 and parameters: {'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 7.562475610585287.\n","[I 2024-12-15 17:52:59,788] Trial 22 finished with value: 7.562394499829038 and parameters: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:52:59,844] Trial 23 finished with value: 7.6928823455465425 and parameters: {'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:52:59,942] Trial 24 finished with value: 7.5629571147113355 and parameters: {'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,025] Trial 25 finished with value: 7.782801332167959 and parameters: {'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,097] Trial 26 finished with value: 7.693055775441604 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,172] Trial 27 finished with value: 7.85626875270224 and parameters: {'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,252] Trial 28 finished with value: 7.562446431487375 and parameters: {'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,293] Trial 29 finished with value: 7.952838045967568 and parameters: {'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,331] Trial 30 finished with value: 7.795678894779535 and parameters: {'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,387] Trial 31 finished with value: 7.562475610585287 and parameters: {'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,452] Trial 32 finished with value: 7.56289451265731 and parameters: {'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,519] Trial 33 finished with value: 7.693016740333418 and parameters: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,570] Trial 34 finished with value: 7.562497379851703 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,610] Trial 35 finished with value: 7.795095002961966 and parameters: {'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,713] Trial 36 finished with value: 7.56248569491893 and parameters: {'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,827] Trial 37 finished with value: 7.692860959207444 and parameters: {'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:00,957] Trial 38 finished with value: 7.782801332167959 and parameters: {'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,075] Trial 39 finished with value: 7.795593072014395 and parameters: {'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,171] Trial 40 finished with value: 10.609296210773152 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,305] Trial 41 finished with value: 7.562394499829038 and parameters: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,396] Trial 42 finished with value: 7.562394499829038 and parameters: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,495] Trial 43 finished with value: 7.562394499829038 and parameters: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,578] Trial 44 finished with value: 7.692963274485673 and parameters: {'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,666] Trial 45 finished with value: 7.562578212963639 and parameters: {'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,760] Trial 46 finished with value: 7.693016740333418 and parameters: {'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:01,943] Trial 47 finished with value: 7.567685107121028 and parameters: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:02,210] Trial 48 finished with value: 7.782801332167959 and parameters: {'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 22 with value: 7.562394499829038.\n","[I 2024-12-15 17:53:02,377] Trial 49 finished with value: 7.7847778178394345 and parameters: {'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 22 with value: 7.562394499829038.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n","Final Model Performance:\n","Train MAE: 0.0003019393345574231\n","Train MSE: 5.144382172160452e-07\n","Train RMSE: 0.0007172434853074967\n","Train R²: 0.9999970607058656\n","Train MAPE: 0.1151979917776878\n","\n","Validation MAE: 0.1351500764194551\n","Validation MSE: 0.023909540669195446\n","Validation RMSE: 0.1546271019879615\n","Validation R²: -3.0651813475736933\n","Validation MAPE: 7.562394499829038\n","\n","Test MAE: 0.4033505341723914\n","Test MSE: 0.16872672380815157\n","Test RMSE: 0.4107635862733594\n","Test R²: -26.95770602109714\n","Test MAPE: 19.889610417803492\n"]}]},{"cell_type":"markdown","source":["**Conclusion:**\n","- While the model performs **exceptionally well on training data**, it shows significant **generalization issues** on both validation and test sets.\n","- The **Optuna hyperparameter optimization** has helped to improve training metrics, but it may still overfit on the training set, leading to **poor performance on unseen data**.\n","- **Further tuning or regularization techniques** could improve generalization and mitigate overfitting."],"metadata":{"id":"BaAbmV4_Jcvh"}},{"cell_type":"markdown","source":["###**BOHB**"],"metadata":{"id":"EB432edpaTGc"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","from sklearn.datasets import make_regression\n","\n","\n","\n","# Define the ConfigSpace for hyperparameter optimization\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"max_depth\", 1, 50, default_value=10))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_split\", 2, 20, default_value=2))\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"min_samples_leaf\", 1, 10, default_value=1))\n","    return cs\n","\n","# Define the Worker for BOHB optimization\n","class DecisionTreeWorker(Worker):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","    def compute(self, config, budget, **kwargs):\n","        model = DecisionTreeRegressor(\n","            max_depth=config[\"max_depth\"],\n","            min_samples_split=config[\"min_samples_split\"],\n","            min_samples_leaf=config[\"min_samples_leaf\"],\n","            random_state=42\n","        )\n","        model.fit(X_train, Y_train)\n","        Y_val_pred = model.predict(X_val)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Set up BOHB\n","NS = hpns.NameServer(run_id=\"dt_bohb\", host=\"127.0.0.1\", port=None)\n","NS.start()\n","\n","worker = DecisionTreeWorker(nameserver=\"127.0.0.1\", run_id=\"dt_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(\n","    configspace=get_config_space(),\n","    run_id=\"dt_bohb\",\n","    nameserver=\"127.0.0.1\",\n","    min_budget=1,\n","    max_budget=3  # Iterative refinement\n",")\n","\n","# Perform optimization\n","res = bohb.run(n_iterations=50)\n","# Increase the number of iterations\n","res = bohb.run(n_iterations=100)  # Increased from 50 to 100\n","\n","# Shutdown\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Retrieve the best configuration\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","# Build the model with the best hyperparameters\n","best_model = DecisionTreeRegressor(\n","    max_depth=best_params[\"max_depth\"],\n","    min_samples_split=best_params[\"min_samples_split\"],\n","    min_samples_leaf=best_params[\"min_samples_leaf\"],\n","    random_state=42\n",")\n","\n","best_model.fit(X_train, Y_train)\n","\n","# Predict and evaluate\n","Y_train_pred = best_model.predict(X_train)\n","Y_val_pred = best_model.predict(X_val)\n","Y_test_pred = best_model.predict(X_test)\n","\n","# Performance metrics calculation\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    return mae, mse, rmse, r2, mape\n","\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print the results\n","print(\"Best Parameters Found by BOHB:\")\n","print(best_params)\n","\n","print(\"\\nTraining set metrics:\")\n","print(f\"MAE: {train_metrics[0]}, MSE: {train_metrics[1]}, RMSE: {train_metrics[2]}, R²: {train_metrics[3]}, MAPE: {train_metrics[4]}\")\n","\n","print(\"\\nValidation set metrics:\")\n","print(f\"MAE: {val_metrics[0]}, MSE: {val_metrics[1]}, RMSE: {val_metrics[2]}, R²: {val_metrics[3]}, MAPE: {val_metrics[4]}\")\n","\n","print(\"\\nTest set metrics:\")\n","print(f\"MAE: {test_metrics[0]}, MSE: {test_metrics[1]}, RMSE: {test_metrics[2]}, R²: {test_metrics[3]}, MAPE: {test_metrics[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8ucJOYztjr6","executionInfo":{"status":"ok","timestamp":1734286267991,"user_tz":-330,"elapsed":35666,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"b2bcae5b-1c82-4aa5-c260-739a1c0c5fb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters Found by BOHB:\n","{'max_depth': 26, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","\n","Training set metrics:\n","MAE: 0.0009153209772787285, MSE: 2.1194673858438413e-06, RMSE: 0.0014558390659148563, R²: 0.9999878902114058, MAPE: 0.0028521358010918426\n","\n","Validation set metrics:\n","MAE: 0.13743640925410125, MSE: 0.02456925420086118, RMSE: 0.15674582674145165, R²: -3.177348083889325, MAPE: 0.07692860959207444\n","\n","Test set metrics:\n","MAE: 0.4057736346996098, MSE: 0.17068731300833043, RMSE: 0.41314321125770714, R²: -27.282572024831467, MAPE: 0.20010015331990766\n"]}]},{"cell_type":"markdown","source":["Training Set\n","- **MAE, MSE, RMSE**: Relatively low, indicating good fit to the training data.\n","- **R²**: High (close to 1), suggesting the model explains a significant portion of the variance in the training data.\n","- **MAPE**: Low, meaning the model's predictions are accurate relative to the magnitude of the target values.\n","\n","Validation Set\n","- **MAE, MSE, RMSE**: Increased compared to the training set, indicating the model doesn't generalize perfectly and shows some overfitting.\n","- **R²**: Moderate, meaning the model captures some variance in the validation data but isn’t as effective as on the training set.\n","- **MAPE**: Still reasonably low, suggesting the predictions remain relatively accurate even on unseen data.\n","\n","Test Set\n","- **MAE, MSE, RMSE**: Similar to the validation set, indicating the model’s performance is consistent across unseen data.\n","- **R²**: Moderate, showing decent predictive power on the test set but not ideal.\n","- **MAPE**: Higher than the training and validation sets, suggesting that the model struggles more with some outliers or specific ranges in the test data.\n"],"metadata":{"id":"E87px1jXajx2"}},{"cell_type":"markdown","source":["## Bagging Regressor"],"metadata":{"id":"xEn62OvnMNVF"}},{"cell_type":"markdown","source":["###**Basic Model**"],"metadata":{"id":"79-DZCwjNMv_"}},{"cell_type":"code","source":["from sklearn.ensemble import BaggingRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import numpy as np\n","\n","bagging_model = BaggingRegressor(n_estimators=100, random_state=42)\n","\n","bagging_model.fit(X_train, Y_train)\n","\n","Y_train_pred = bagging_model.predict(X_train)\n","Y_val_pred = bagging_model.predict(X_val)\n","Y_test_pred = bagging_model.predict(X_test)\n","\n","def evaluate_model(Y_true, Y_pred):\n","    mae = mean_absolute_error(Y_true, Y_pred)\n","    mse = mean_squared_error(Y_true, Y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(Y_true, Y_pred)\n","    mape = mean_absolute_percentage_error(Y_true, Y_pred)\n","\n","    return mae, mse, rmse, r2, mape\n","\n","# Evaluate the model on all datasets\n","train_metrics = evaluate_model(Y_train, Y_train_pred)\n","val_metrics = evaluate_model(Y_val, Y_val_pred)\n","test_metrics = evaluate_model(Y_test, Y_test_pred)\n","\n","# Display the results\n","print(f\"Training set metrics: MAE={train_metrics[0]}, MSE={train_metrics[1]}, RMSE={train_metrics[2]}, R²={train_metrics[3]}, MAPE={train_metrics[4]}\")\n","print(f\"Validation set metrics: MAE={val_metrics[0]}, MSE={val_metrics[1]}, RMSE={val_metrics[2]}, R²={val_metrics[3]}, MAPE={val_metrics[4]}\")\n","print(f\"Test set metrics: MAE={test_metrics[0]}, MSE={test_metrics[1]}, RMSE={test_metrics[2]}, R²={test_metrics[3]}, MAPE={test_metrics[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UcY8_gVxMVn-","executionInfo":{"status":"ok","timestamp":1734285456689,"user_tz":-330,"elapsed":11341,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"320896df-971e-4213-a4a3-6a90d7a959bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics: MAE=0.0008732125022284934, MSE=1.8691580116169827e-06, RMSE=0.0013671715370124492, R²=0.9999893203790154, MAPE=0.0025500260474208424\n","Validation set metrics: MAE=0.13800668869839053, MSE=0.02474056021408138, RMSE=0.1572913227552028, R²=-3.2064741143432345, MAPE=0.07725309735866118\n","Test set metrics: MAE=0.4063966726089382, MSE=0.17119332589861455, RMSE=0.4137551521112632, R²=-27.366417424719245, MAPE=0.20040974355426008\n"]}]},{"cell_type":"markdown","source":["Overfitting: The model performs exceptionally well on the training set but poorly on the validation and test sets, indicated by the drastically worse R² and higher error metrics (MAE, MSE, etc.) on those datasets."],"metadata":{"id":"C2_kaZJ5NIOZ"}},{"cell_type":"markdown","source":["###**Regularization**"],"metadata":{"id":"Ti1QYI3uNmJs"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import BaggingRegressor\n","\n","# Define a regularized DecisionTreeRegressor as the base estimator\n","tree_regressor = DecisionTreeRegressor(max_depth=5, random_state=42)\n","\n","# Initialize the Bagging Regressor with the regularized base estimator\n","bagging_model_reg = BaggingRegressor(n_estimators=100,\n","                                    max_samples=0.8, max_features=0.8, random_state=42)\n","\n","# Train the model on the training data\n","bagging_model_reg.fit(X_train, Y_train)\n","\n","# Predictions on the training, validation, and test sets\n","Y_train_pred_reg = bagging_model_reg.predict(X_train)\n","Y_val_pred_reg = bagging_model_reg.predict(X_val)\n","Y_test_pred_reg = bagging_model_reg.predict(X_test)\n","\n","# Evaluate the model on all datasets\n","train_metrics_reg = evaluate_model(Y_train, Y_train_pred_reg)\n","val_metrics_reg = evaluate_model(Y_val, Y_val_pred_reg)\n","test_metrics_reg = evaluate_model(Y_test, Y_test_pred_reg)\n","\n","# Display the results\n","print(f\"Training set metrics (regularized): MAE={train_metrics_reg[0]}, MSE={train_metrics_reg[1]}, RMSE={train_metrics_reg[2]}, R²={train_metrics_reg[3]}, MAPE={train_metrics_reg[4]}\")\n","print(f\"Validation set metrics (regularized): MAE={val_metrics_reg[0]}, MSE={val_metrics_reg[1]}, RMSE={val_metrics_reg[2]}, R²={val_metrics_reg[3]}, MAPE={val_metrics_reg[4]}\")\n","print(f\"Test set metrics (regularized): MAE={test_metrics_reg[0]}, MSE={test_metrics_reg[1]}, RMSE={test_metrics_reg[2]}, R²={test_metrics_reg[3]}, MAPE={test_metrics_reg[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mssYmddVMt4X","executionInfo":{"status":"ok","timestamp":1734285460475,"user_tz":-330,"elapsed":3788,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"4e4c92b3-b3de-4bd1-96e3-48518b191c5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics (regularized): MAE=0.0013058228798433875, MSE=3.641757363067161e-06, RMSE=0.0019083389015233014, R²=0.9999791924555798, MAPE=0.004120529645240297\n","Validation set metrics (regularized): MAE=0.13815464235852487, MSE=0.02478106837704831, RMSE=0.15742003804169374, R²=-3.213361449854861, MAPE=0.07733803189986108\n","Test set metrics (regularized): MAE=0.4065432743934606, MSE=0.17131250434555467, RMSE=0.4138991475535492, R²=-27.386165072918654, MAPE=0.20048259061564627\n"]}]},{"cell_type":"markdown","source":["Despite adding regularization, the model still appears to be overfitting. This suggests the following possibilities:\n","\n","Base Estimator Complexity: The base DecisionTreeRegressor might still be too complex for the problem. You could try further reducing the tree's depth or introducing other constraints like min_samples_split or min_samples_leaf.\n","Model Choice: Bagging with decision trees may not be the best approach for this problem. You could experiment with other ensemble methods like Random Forest or Gradient Boosting, which have built-in regularization."],"metadata":{"id":"ubeVf0ISNvrz"}},{"cell_type":"markdown","source":["###**Cross-Validation**"],"metadata":{"id":"6D2QO2aON20j"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split, cross_val_predict\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import numpy as np\n","\n","# Train the model on the training set\n","bagging_model_reg.fit(X_train, Y_train)\n","\n","# Make predictions on the training, validation, and test sets\n","Y_train_pred = bagging_model_reg.predict(X_train)\n","Y_val_pred = bagging_model_reg.predict(X_val)\n","Y_test_pred = bagging_model_reg.predict(X_test)\n","\n","# Calculate metrics for training set\n","train_mae = mean_absolute_error(Y_train, Y_train_pred)\n","train_mse = mean_squared_error(Y_train, Y_train_pred)\n","train_rmse = np.sqrt(train_mse)\n","train_r2 = r2_score(Y_train, Y_train_pred)\n","train_mape = mean_absolute_percentage_error(Y_train, Y_train_pred)\n","\n","# Calculate metrics for validation set\n","val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","val_mse = mean_squared_error(Y_val, Y_val_pred)\n","val_rmse = np.sqrt(val_mse)\n","val_r2 = r2_score(Y_val, Y_val_pred)\n","val_mape = mean_absolute_percentage_error(Y_val, Y_val_pred)\n","\n","# Calculate metrics for test set\n","test_mae = mean_absolute_error(Y_test, Y_test_pred)\n","test_mse = mean_squared_error(Y_test, Y_test_pred)\n","test_rmse = np.sqrt(test_mse)\n","test_r2 = r2_score(Y_test, Y_test_pred)\n","test_mape = mean_absolute_percentage_error(Y_test, Y_test_pred)\n","\n","# Print all metrics for train, validation, and test sets\n","print(f\"Training set metrics:\")\n","print(f\"MAE: {train_mae}, MSE: {train_mse}, RMSE: {train_rmse}, R²: {train_r2}, MAPE: {train_mape}\")\n","print(f\"\\nValidation set metrics:\")\n","print(f\"MAE: {val_mae}, MSE: {val_mse}, RMSE: {val_rmse}, R²: {val_r2}, MAPE: {val_mape}\")\n","print(f\"\\nTest set metrics:\")\n","print(f\"MAE: {test_mae}, MSE: {test_mse}, RMSE: {test_rmse}, R²: {test_r2}, MAPE: {test_mape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPdrJNEUNa5d","executionInfo":{"status":"ok","timestamp":1734285463452,"user_tz":-330,"elapsed":2979,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"5ff12d21-10b6-4583-8bb1-b3b8726f493a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics:\n","MAE: 0.0013058228798433875, MSE: 3.641757363067161e-06, RMSE: 0.0019083389015233014, R²: 0.9999791924555798, MAPE: 0.004120529645240297\n","\n","Validation set metrics:\n","MAE: 0.13815464235852487, MSE: 0.02478106837704831, RMSE: 0.15742003804169374, R²: -3.213361449854861, MAPE: 0.07733803189986108\n","\n","Test set metrics:\n","MAE: 0.4065432743934606, MSE: 0.17131250434555467, RMSE: 0.4138991475535492, R²: -27.386165072918654, MAPE: 0.20048259061564627\n"]}]},{"cell_type":"markdown","source":["The model is overfitting the training data, as seen from the excellent training performance but poor validation and test results.\n","Regularization or model complexity reduction could help improve generalization.\n","You could try alternative models or further tweak hyperparameters (like reducing tree depth or changing the base estimator)."],"metadata":{"id":"zEnafSqeOtX2"}},{"cell_type":"markdown","source":["###**Hyperparameter tuning using GridSearchCV**"],"metadata":{"id":"iElLx0jZPtOB"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import BaggingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import numpy as np\n","\n","# Define the parameter grid for tuning\n","param_grid = {\n","    'n_estimators': [50, 100, 200],  # Number of trees\n","    'max_samples': [0.5, 0.7, 1.0],  # Fraction of samples to train each base estimator\n","    'max_features': [0.5, 0.7, 1.0],  # Fraction of features to train each base estimator\n","}\n","\n","# Create the Bagging Regressor without specifying the base_estimator explicitly\n","bagging_model = BaggingRegressor(random_state=42)\n","\n","# Perform grid search with 5-fold cross-validation\n","grid_search = GridSearchCV(bagging_model, param_grid, cv=5, n_jobs=-1, scoring='neg_mean_absolute_error')\n","\n","# Fit grid search to the training data\n","grid_search.fit(X_train, Y_train)\n","\n","# Print the best hyperparameters\n","print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","# Get the best model\n","best_bagging_model = grid_search.best_estimator_\n","\n","# Now manually set the base_estimator to DecisionTreeRegressor in the best model\n","best_bagging_model.base_estimator = DecisionTreeRegressor(random_state=42)\n","\n","# Evaluate the best model on the training, validation, and test sets\n","Y_train_pred = best_bagging_model.predict(X_train)\n","Y_val_pred = best_bagging_model.predict(X_val)\n","Y_test_pred = best_bagging_model.predict(X_test)\n","\n","# Calculate metrics for training set\n","train_mae = mean_absolute_error(Y_train, Y_train_pred)\n","train_mse = mean_squared_error(Y_train, Y_train_pred)\n","train_rmse = np.sqrt(train_mse)\n","train_r2 = r2_score(Y_train, Y_train_pred)\n","train_mape = mean_absolute_percentage_error(Y_train, Y_train_pred)\n","\n","# Calculate metrics for validation set\n","val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","val_mse = mean_squared_error(Y_val, Y_val_pred)\n","val_rmse = np.sqrt(val_mse)\n","val_r2 = r2_score(Y_val, Y_val_pred)\n","val_mape = mean_absolute_percentage_error(Y_val, Y_val_pred)\n","\n","# Calculate metrics for test set\n","test_mae = mean_absolute_error(Y_test, Y_test_pred)\n","test_mse = mean_squared_error(Y_test, Y_test_pred)\n","test_rmse = np.sqrt(test_mse)\n","test_r2 = r2_score(Y_test, Y_test_pred)\n","test_mape = mean_absolute_percentage_error(Y_test, Y_test_pred)\n","\n","# Print all metrics for train, validation, and test sets\n","print(f\"Training set metrics after hyperparameter tuning:\")\n","print(f\"MAE: {train_mae}, MSE: {train_mse}, RMSE: {train_rmse}, R²: {train_r2}, MAPE: {train_mape}\")\n","print(f\"\\nValidation set metrics after hyperparameter tuning:\")\n","print(f\"MAE: {val_mae}, MSE: {val_mse}, RMSE: {val_rmse}, R²: {val_r2}, MAPE: {val_mape}\")\n","print(f\"\\nTest set metrics after hyperparameter tuning:\")\n","print(f\"MAE: {test_mae}, MSE: {test_mse}, RMSE: {test_rmse}, R²: {test_r2}, MAPE: {test_mape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOY9OLQoOmHz","executionInfo":{"status":"ok","timestamp":1734285743728,"user_tz":-330,"elapsed":179380,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"ba6a1454-06c2-45ab-a2aa-0ebe9d6eece2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'max_features': 1.0, 'max_samples': 0.5, 'n_estimators': 100}\n","Training set metrics after hyperparameter tuning:\n","MAE: 0.0013970896700768508, MSE: 4.6881845516611124e-06, RMSE: 0.002165221594124055, R²: 0.9999732135893241, MAPE: 0.004070045623765808\n","\n","Validation set metrics after hyperparameter tuning:\n","MAE: 0.13939557603727515, MSE: 0.02514355082063873, RMSE: 0.1585671807803832, R²: -3.274991946604856, MAPE: 0.07804651993494914\n","\n","Test set metrics after hyperparameter tuning:\n","MAE: 0.407850385786475, MSE: 0.17237700757717447, RMSE: 0.4151831012663864, R²: -27.562551289259666, MAPE: 0.20113209992547984\n"]}]},{"cell_type":"markdown","source":["Training Set: The performance on the training set is excellent (R² close to 1, low MAE, MSE, RMSE), which indicates that the model fits the training data well.\n","Validation and Test Sets: The performance drops significantly (negative R² values, higher MAE, MSE, RMSE, and MAPE). This suggests that the model might be overfitting the training data and not generalizing well to unseen data."],"metadata":{"id":"ypPZN5fAQk58"}},{"cell_type":"markdown","source":["###**Using Optuna**"],"metadata":{"id":"D_ADADVkSmP3"}},{"cell_type":"code","source":["# Objective function for optimization\n","def objective(trial):\n","    # Hyperparameters to tune\n","    n_estimators = trial.suggest_int('n_estimators', 50, 200)  # Number of trees\n","    max_samples = trial.suggest_float('max_samples', 0.5, 1.0)  # Fraction of samples to train each base estimator\n","    max_features = trial.suggest_float('max_features', 0.5, 1.0)  # Fraction of features to train each base estimator\n","\n","    # Create the Bagging Regressor (no need for base_estimator argument)\n","    model = BaggingRegressor(\n","        n_estimators=n_estimators,\n","        max_samples=max_samples,\n","        max_features=max_features,\n","        random_state=42\n","    )\n","\n","    # Fit the model on the training set\n","    model.fit(X_train, Y_train)\n","\n","    # Predict on the validation set\n","    Y_val_pred = model.predict(X_val)\n","\n","    # Calculate validation metrics\n","    val_mae = mean_absolute_error(Y_val, Y_val_pred)\n","    val_mse = mean_squared_error(Y_val, Y_val_pred)\n","    val_rmse = np.sqrt(val_mse)\n","    val_r2 = r2_score(Y_val, Y_val_pred)\n","    val_mape = mean_absolute_percentage_error(Y_val, Y_val_pred)\n","\n","    # Return the validation MAE as the objective to minimize\n","    return val_mae\n"],"metadata":{"id":"P92HhZEqO4zM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import optuna\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","from sklearn.ensemble import BaggingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","import numpy as np\n","\n","# Create an Optuna study with Hyperband optimization (tune using early stopping)\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=50)  # Number of trials to perform\n","\n","# Get the best hyperparameters from the study\n","best_params = study.best_params\n","print(\"Best Hyperparameters:\", best_params)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DKLlmklQz6i","executionInfo":{"status":"ok","timestamp":1734285837879,"user_tz":-330,"elapsed":85322,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"698b39eb-c60f-4925-f862-06eb54f1de85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-12-15 17:58:24,817] A new study created in memory with name: no-name-215bd2b8-821b-4bd3-931f-9701de813adb\n","[I 2024-12-15 17:58:25,738] Trial 0 finished with value: 0.13761743470078253 and parameters: {'n_estimators': 56, 'max_samples': 0.8224782230403966, 'max_features': 0.677073945240684}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:27,029] Trial 1 finished with value: 0.13787304418533028 and parameters: {'n_estimators': 77, 'max_samples': 0.7944952166656873, 'max_features': 0.8262915208567174}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:28,858] Trial 2 finished with value: 0.13950604862949242 and parameters: {'n_estimators': 165, 'max_samples': 0.5004942568258749, 'max_features': 0.5133499241945563}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:30,066] Trial 3 finished with value: 0.1384227631787268 and parameters: {'n_estimators': 58, 'max_samples': 0.672817902678628, 'max_features': 0.9062281415668136}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:34,437] Trial 4 finished with value: 0.13774253903466818 and parameters: {'n_estimators': 188, 'max_samples': 0.9486536665284347, 'max_features': 0.7418396106918399}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:35,950] Trial 5 finished with value: 0.1380592783047125 and parameters: {'n_estimators': 98, 'max_samples': 0.7909719409984904, 'max_features': 0.7908035294220046}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:37,494] Trial 6 finished with value: 0.138713392586106 and parameters: {'n_estimators': 169, 'max_samples': 0.82846809997004, 'max_features': 0.52751041633152}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:39,191] Trial 7 finished with value: 0.1388547018743025 and parameters: {'n_estimators': 199, 'max_samples': 0.7471400175543876, 'max_features': 0.5806377202060022}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:40,063] Trial 8 finished with value: 0.13889158982901773 and parameters: {'n_estimators': 100, 'max_samples': 0.8029250869840109, 'max_features': 0.6150425487880823}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:42,519] Trial 9 finished with value: 0.13785041341597187 and parameters: {'n_estimators': 145, 'max_samples': 0.9477810862958158, 'max_features': 0.7524939898485643}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:42,943] Trial 10 finished with value: 0.13915922951102666 and parameters: {'n_estimators': 53, 'max_samples': 0.6114114194689845, 'max_features': 0.6548893262037224}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:45,821] Trial 11 finished with value: 0.1380296818729721 and parameters: {'n_estimators': 121, 'max_samples': 0.9632141669333545, 'max_features': 0.6842520761345405}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:50,305] Trial 12 finished with value: 0.1376867547224336 and parameters: {'n_estimators': 197, 'max_samples': 0.8906976898460272, 'max_features': 0.7159111018329438}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:52,312] Trial 13 finished with value: 0.13814248714975158 and parameters: {'n_estimators': 126, 'max_samples': 0.8525858698035533, 'max_features': 0.8801241236792832}. Best is trial 0 with value: 0.13761743470078253.\n","[I 2024-12-15 17:58:53,711] Trial 14 finished with value: 0.13738359436648317 and parameters: {'n_estimators': 85, 'max_samples': 0.8836508822280621, 'max_features': 0.9802264543918665}. Best is trial 14 with value: 0.13738359436648317.\n","[I 2024-12-15 17:58:55,001] Trial 15 finished with value: 0.13744278538463658 and parameters: {'n_estimators': 79, 'max_samples': 0.8843268223786758, 'max_features': 0.9967767051460097}. Best is trial 14 with value: 0.13738359436648317.\n","[I 2024-12-15 17:58:56,403] Trial 16 finished with value: 0.13738125658683825 and parameters: {'n_estimators': 85, 'max_samples': 0.8964963697256353, 'max_features': 0.9869604691548697}. Best is trial 16 with value: 0.13738125658683825.\n","[I 2024-12-15 17:58:57,971] Trial 17 finished with value: 0.13745573406315362 and parameters: {'n_estimators': 89, 'max_samples': 0.9890813260783088, 'max_features': 0.984068077137195}. Best is trial 16 with value: 0.13738125658683825.\n","[I 2024-12-15 17:58:59,789] Trial 18 finished with value: 0.13844888169180944 and parameters: {'n_estimators': 114, 'max_samples': 0.7353206048583106, 'max_features': 0.9311495923139326}. Best is trial 16 with value: 0.13738125658683825.\n","[I 2024-12-15 17:59:01,601] Trial 19 finished with value: 0.13734954827663817 and parameters: {'n_estimators': 72, 'max_samples': 0.903184485360528, 'max_features': 0.8541430892784196}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:03,138] Trial 20 finished with value: 0.13806785224992693 and parameters: {'n_estimators': 70, 'max_samples': 0.6905740781193639, 'max_features': 0.8438872373728492}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:05,780] Trial 21 finished with value: 0.13772213666149224 and parameters: {'n_estimators': 104, 'max_samples': 0.9018898168579624, 'max_features': 0.951054032363889}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:07,219] Trial 22 finished with value: 0.1375530407332921 and parameters: {'n_estimators': 86, 'max_samples': 0.9175065087949644, 'max_features': 0.888854391809544}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:08,303] Trial 23 finished with value: 0.1375206611863402 and parameters: {'n_estimators': 66, 'max_samples': 0.8605385597744625, 'max_features': 0.9614049179150649}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:10,580] Trial 24 finished with value: 0.13791079576065962 and parameters: {'n_estimators': 131, 'max_samples': 0.9975585689909219, 'max_features': 0.8310309664248463}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:12,082] Trial 25 finished with value: 0.13769312289123004 and parameters: {'n_estimators': 89, 'max_samples': 0.927323784614217, 'max_features': 0.9262457164018988}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:13,865] Trial 26 finished with value: 0.13780954285492758 and parameters: {'n_estimators': 111, 'max_samples': 0.8667021718206115, 'max_features': 0.8613359112206904}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:15,047] Trial 27 finished with value: 0.1375632686158383 and parameters: {'n_estimators': 70, 'max_samples': 0.9132016378216739, 'max_features': 0.9958541955136192}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:17,991] Trial 28 finished with value: 0.1382209938408537 and parameters: {'n_estimators': 139, 'max_samples': 0.83914045172182, 'max_features': 0.7792638897238877}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:19,402] Trial 29 finished with value: 0.13796694226124268 and parameters: {'n_estimators': 59, 'max_samples': 0.7723788139650729, 'max_features': 0.9542863155109736}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:21,259] Trial 30 finished with value: 0.13786390439542562 and parameters: {'n_estimators': 82, 'max_samples': 0.7116769738979758, 'max_features': 0.9113800174739002}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:22,684] Trial 31 finished with value: 0.1374636708255276 and parameters: {'n_estimators': 76, 'max_samples': 0.8762174019689308, 'max_features': 0.9915587680559304}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:24,169] Trial 32 finished with value: 0.1377354486954598 and parameters: {'n_estimators': 94, 'max_samples': 0.8201084524932963, 'max_features': 0.9440969477777683}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:25,521] Trial 33 finished with value: 0.13759458525258014 and parameters: {'n_estimators': 78, 'max_samples': 0.9574330509283331, 'max_features': 0.9975782523788816}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:26,244] Trial 34 finished with value: 0.1388819071483171 and parameters: {'n_estimators': 60, 'max_samples': 0.5126862840431323, 'max_features': 0.9682161967626447}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:28,077] Trial 35 finished with value: 0.13783053750517119 and parameters: {'n_estimators': 108, 'max_samples': 0.8990377736826224, 'max_features': 0.8928125076002087}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:28,970] Trial 36 finished with value: 0.1376398349606746 and parameters: {'n_estimators': 52, 'max_samples': 0.9390927416516187, 'max_features': 0.817322454605551}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:29,888] Trial 37 finished with value: 0.13837361874300483 and parameters: {'n_estimators': 66, 'max_samples': 0.6380381346609147, 'max_features': 0.9247850718773968}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:31,057] Trial 38 finished with value: 0.13781461194238975 and parameters: {'n_estimators': 76, 'max_samples': 0.7879937240346839, 'max_features': 0.8662709419455942}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:33,025] Trial 39 finished with value: 0.13773533821092243 and parameters: {'n_estimators': 97, 'max_samples': 0.8212620447895771, 'max_features': 0.9680134678394887}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:36,862] Trial 40 finished with value: 0.13773670749769046 and parameters: {'n_estimators': 156, 'max_samples': 0.880229843952302, 'max_features': 0.7991028785369241}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:38,864] Trial 41 finished with value: 0.13741733924380414 and parameters: {'n_estimators': 89, 'max_samples': 0.9939621490693611, 'max_features': 0.9840203494227888}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:40,287] Trial 42 finished with value: 0.13762614585117894 and parameters: {'n_estimators': 83, 'max_samples': 0.9574500564108314, 'max_features': 0.9773972541721268}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:41,908] Trial 43 finished with value: 0.13749272172270943 and parameters: {'n_estimators': 94, 'max_samples': 0.9776595972052536, 'max_features': 0.9085853506062991}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:43,135] Trial 44 finished with value: 0.13762409594113148 and parameters: {'n_estimators': 73, 'max_samples': 0.9308090506464448, 'max_features': 0.9988465085385025}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:44,211] Trial 45 finished with value: 0.13774698111277967 and parameters: {'n_estimators': 62, 'max_samples': 0.9743759337763593, 'max_features': 0.9412047560753624}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:45,839] Trial 46 finished with value: 0.13793775976801675 and parameters: {'n_estimators': 103, 'max_samples': 0.8382394432592619, 'max_features': 0.9646422639185612}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:46,618] Trial 47 finished with value: 0.13775147136169386 and parameters: {'n_estimators': 50, 'max_samples': 0.7681509237992795, 'max_features': 0.9244064443738338}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:47,705] Trial 48 finished with value: 0.13880970442304078 and parameters: {'n_estimators': 118, 'max_samples': 0.8913261072632939, 'max_features': 0.5465103747336294}. Best is trial 19 with value: 0.13734954827663817.\n","[I 2024-12-15 17:59:49,560] Trial 49 finished with value: 0.1375625559529035 and parameters: {'n_estimators': 81, 'max_samples': 0.9401490945426924, 'max_features': 0.7570625469822121}. Best is trial 19 with value: 0.13734954827663817.\n"]},{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'n_estimators': 72, 'max_samples': 0.903184485360528, 'max_features': 0.8541430892784196}\n"]}]},{"cell_type":"code","source":["# Retrieve the best hyperparameters\n","best_n_estimators = best_params['n_estimators']\n","best_max_samples = best_params['max_samples']\n","best_max_features = best_params['max_features']\n","\n","# Create the final Bagging Regressor model with the best hyperparameters\n","final_model = BaggingRegressor(\n","    n_estimators=best_n_estimators,\n","    max_samples=best_max_samples,\n","    max_features=best_max_features,\n","    random_state=42\n",")\n","\n","# Train the model on the full training set\n","final_model.fit(X_train, Y_train)\n","\n","# Predict on the training, validation, and test sets\n","Y_train_pred = final_model.predict(X_train)\n","Y_val_pred = final_model.predict(X_val)\n","Y_test_pred = final_model.predict(X_test)\n","\n","# Calculate performance metrics for training, validation, and test sets\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    return mae, mse, rmse, r2, mape\n","\n","# Calculate metrics for each set\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print the results\n","print(\"Training set metrics:\")\n","print(f\"MAE: {train_metrics[0]}, MSE: {train_metrics[1]}, RMSE: {train_metrics[2]}, R²: {train_metrics[3]}, MAPE: {train_metrics[4]}\")\n","\n","print(\"Validation set metrics:\")\n","print(f\"MAE: {val_metrics[0]}, MSE: {val_metrics[1]}, RMSE: {val_metrics[2]}, R²: {val_metrics[3]}, MAPE: {val_metrics[4]}\")\n","\n","print(\"Test set metrics:\")\n","print(f\"MAE: {test_metrics[0]}, MSE: {test_metrics[1]}, RMSE: {test_metrics[2]}, R²: {test_metrics[3]}, MAPE: {test_metrics[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg8A7ExXRZvU","executionInfo":{"status":"ok","timestamp":1734285872513,"user_tz":-330,"elapsed":2051,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"2eaaad4d-11d1-4dcc-ef9d-6e6f47b12a88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics:\n","MAE: 0.001221403712996892, MSE: 3.1849105593776955e-06, RMSE: 0.0017846317713684512, R²: 0.9999818026954209, MAPE: 0.003887995058994434\n","Validation set metrics:\n","MAE: 0.13734954827663817, MSE: 0.024547797875147534, RMSE: 0.15667736873954557, R²: -3.173700006484352, MAPE: 0.07687833932309676\n","Test set metrics:\n","MAE: 0.4056959040135402, MSE: 0.17062423692436177, RMSE: 0.4130668673766534, R²: -27.2721204343972, MAPE: 0.20006152860549406\n"]}]},{"cell_type":"markdown","source":["model's performance on the training set is excellent, with an R² close to 1. However, the performance on the validation and test sets shows a significant drop, especially with negative R² values and high MAE, MSE, RMSE, and MAPE values. This suggests that the model may be overfitting to the training data."],"metadata":{"id":"90wCX3uyR6dM"}},{"cell_type":"code","source":["pip install scikit-learn scikit-optimize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3UvDQjnSLY_","executionInfo":{"status":"ok","timestamp":1734285882424,"user_tz":-330,"elapsed":4978,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"89d38f36-9b70-482c-f446-38713719d3c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.12.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.ensemble import BaggingRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","from skopt import BayesSearchCV\n","from skopt.space import Integer, Real\n","\n","# Define the search space for hyperparameters\n","param_space = {\n","    'n_estimators': Integer(10, 200),  # Number of base estimators\n","    'max_samples': Real(0.1, 1.0),    # Fraction of samples to draw\n","    'max_features': Real(0.1, 1.0)    # Fraction of features to draw\n","}\n","\n","# Use BayesSearchCV for hyperparameter optimization\n","opt = BayesSearchCV(\n","    estimator=BaggingRegressor(random_state=42),\n","    search_spaces=param_space,\n","    n_iter=50,  # Number of iterations\n","    scoring='neg_mean_absolute_error',  # Use negative MAE for minimization\n","    cv=3,  # Cross-validation\n","    n_jobs=-1,  # Use all available cores\n","    random_state=42\n",")\n","\n","# Fit the optimizer\n","opt.fit(X_train, Y_train)\n","\n","# Retrieve the best hyperparameters\n","best_params = opt.best_params_\n","best_n_estimators = best_params['n_estimators']\n","best_max_samples = best_params['max_samples']\n","best_max_features = best_params['max_features']\n","\n","# Create the final Bagging Regressor model with the best hyperparameters\n","final_model = BaggingRegressor(\n","    n_estimators=best_n_estimators,\n","    max_samples=best_max_samples,\n","    max_features=best_max_features,\n","    random_state=42\n",")\n","\n","# Train the model on the full training set\n","final_model.fit(X_train, Y_train)\n","\n","# Predict on the training, validation, and test sets\n","Y_train_pred = final_model.predict(X_train)\n","Y_val_pred = final_model.predict(X_val)\n","Y_test_pred = final_model.predict(X_test)\n","\n","# Calculate performance metrics for training, validation, and test sets\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    return mae, mse, rmse, r2, mape\n","\n","# Calculate metrics for each set\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print the results\n","print(\"Training set metrics:\")\n","print(f\"MAE: {train_metrics[0]}, MSE: {train_metrics[1]}, RMSE: {train_metrics[2]}, R²: {train_metrics[3]}, MAPE: {train_metrics[4]}\")\n","\n","print(\"Validation set metrics:\")\n","print(f\"MAE: {val_metrics[0]}, MSE: {val_metrics[1]}, RMSE: {val_metrics[2]}, R²: {val_metrics[3]}, MAPE: {val_metrics[4]}\")\n","\n","print(\"Test set metrics:\")\n","print(f\"MAE: {test_metrics[0]}, MSE: {test_metrics[1]}, RMSE: {test_metrics[2]}, R²: {test_metrics[3]}, MAPE: {test_metrics[4]}\")\n"],"metadata":{"id":"onAbDFFGSc1m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734286091705,"user_tz":-330,"elapsed":189462,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"6559fcfb-06ad-4ca0-d1e2-b62eac06d3b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics:\n","MAE: 0.0010784427442547123, MSE: 3.2365316199014488e-06, RMSE: 0.0017990363031082637, R²: 0.9999815077533358, MAPE: 0.003130789312884494\n","Validation set metrics:\n","MAE: 0.13889267184207182, MSE: 0.024994687868152076, RMSE: 0.15809708368009853, R²: -3.249681761596862, MAPE: 0.07775968904325982\n","Test set metrics:\n","MAE: 0.40731487188780735, MSE: 0.171940475251979, RMSE: 0.4146570574004246, R²: -27.4902186904806, MAPE: 0.20086600075092692\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"1tQpJhwqSZN5"}},{"cell_type":"code","source":["!pip install ConfigSpace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gSaLRaebtsE0","executionInfo":{"status":"ok","timestamp":1734286149028,"user_tz":-330,"elapsed":3756,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"d80105f3-89d8-4648-d00c-647b89e8a8bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.10/dist-packages (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.26.4)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (3.2.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.13.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (10.5.0)\n"]}]},{"cell_type":"code","source":["!pip install hpbandster"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjRaXPnEt4KC","executionInfo":{"status":"ok","timestamp":1734286155918,"user_tz":-330,"elapsed":6898,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"06f98de8-e509-49bb-ba9e-99072267046a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: hpbandster in /usr/local/lib/python3.10/dist-packages (0.7.4)\n","Requirement already satisfied: Pyro4 in /usr/local/lib/python3.10/dist-packages (from hpbandster) (4.82)\n","Requirement already satisfied: serpent in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.41)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.26.4)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.13.1)\n","Requirement already satisfied: netifaces in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.11.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (3.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (10.5.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["###**BOHB**"],"metadata":{"id":"fQOitfg6Pn4d"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.ensemble import BaggingRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","from sklearn.datasets import make_regression\n","\n","\n","\n","# Define the ConfigSpace for hyperparameter optimization\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"n_estimators\", 10, 200, default_value=50))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"max_samples\", 0.1, 1.0, default_value=0.5))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"max_features\", 0.1, 1.0, default_value=0.5))\n","    return cs\n","\n","# Define the Worker for BOHB optimization\n","class BaggingWorker(Worker):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","    def compute(self, config, budget, **kwargs):\n","        model = BaggingRegressor(\n","            n_estimators=config[\"n_estimators\"],\n","            max_samples=config[\"max_samples\"],\n","            max_features=config[\"max_features\"],\n","            random_state=42\n","        )\n","        model.fit(X_train, Y_train)\n","        Y_val_pred = model.predict(X_val)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Set up BOHB\n","NS = hpns.NameServer(run_id=\"bagging_bohb\", host=\"127.0.0.1\", port=None)\n","NS.start()\n","\n","worker = BaggingWorker(nameserver=\"127.0.0.1\", run_id=\"bagging_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(\n","    configspace=get_config_space(),\n","    run_id=\"bagging_bohb\",\n","    nameserver=\"127.0.0.1\",\n","    min_budget=1,\n","    max_budget=3  # Iterative refinement\n",")\n","\n","# Perform optimization\n","res = bohb.run(n_iterations=50)\n","\n","# Shutdown\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Retrieve the best configuration\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","# Build the model with the best hyperparameters\n","best_model = BaggingRegressor(\n","    n_estimators=best_params[\"n_estimators\"],\n","    max_samples=best_params[\"max_samples\"],\n","    max_features=best_params[\"max_features\"],\n","    random_state=42\n",")\n","\n","best_model.fit(X_train, Y_train)\n","\n","# Predict and evaluate\n","Y_train_pred = best_model.predict(X_train)\n","Y_val_pred = best_model.predict(X_val)\n","Y_test_pred = best_model.predict(X_test)\n","\n","# Performance metrics calculation\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    return mae, mse, rmse, r2, mape\n","\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print the results\n","print(\"Best Parameters Found by BOHB:\")\n","print(best_params)\n","\n","print(\"\\nTraining set metrics:\")\n","print(f\"MAE: {train_metrics[0]}, MSE: {train_metrics[1]}, RMSE: {train_metrics[2]}, R²: {train_metrics[3]}, MAPE: {train_metrics[4]}\")\n","\n","print(\"\\nValidation set metrics:\")\n","print(f\"MAE: {val_metrics[0]}, MSE: {val_metrics[1]}, RMSE: {val_metrics[2]}, R²: {val_metrics[3]}, MAPE: {val_metrics[4]}\")\n","\n","print(\"\\nTest set metrics:\")\n","print(f\"MAE: {test_metrics[0]}, MSE: {test_metrics[1]}, RMSE: {test_metrics[2]}, R²: {test_metrics[3]}, MAPE: {test_metrics[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AaKRI4KEu2_Z","executionInfo":{"status":"ok","timestamp":1734286440463,"user_tz":-330,"elapsed":161753,"user":{"displayName":"Anoushka Shrivastava","userId":"00353895164281512638"}},"outputId":"a872263b-9a2f-481f-c1b1-019a55a9dd2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters Found by BOHB:\n","{'max_features': 0.8252676665154, 'max_samples': 0.9143075872047, 'n_estimators': 26}\n","\n","Training set metrics:\n","MAE: 0.001236107884023894, MSE: 3.350209806945681e-06, RMSE: 0.0018303578357648214, R²: 0.9999808582416604, MAPE: 0.0039055875965137415\n","\n","Validation set metrics:\n","MAE: 0.13727369714756762, MSE: 0.024527183413516927, RMSE: 0.15661156858136926, R²: -3.1701950656713738, MAPE: 0.07683475166984573\n","\n","Test set metrics:\n","MAE: 0.4056208488405414, MSE: 0.1705633434051194, RMSE: 0.4129931517654008, R²: -27.262030490900734, MAPE: 0.20002423336510794\n"]}]},{"cell_type":"markdown","source":["Training Set\n","\n","\n","*   The metrics indicate an almost perfect fit to the training data.\n","*   R² is extremely high (close to 1), meaning the model explains nearly all the variance in the training data.\n","\n","*  Very low MAPE confirms the model's predictions are highly accurate relative to the magnitude of the target values.\n","\n","\n","Validating Set\n","\n","\n","*   There is a significant increase in MAE, MSE, and RMSE compared to the training set, highlighting that the model is overfitting and struggles to generalize to unseen data.\n","\n","*  Negative R² indicates that the model performs worse than predicting the mean, showing very poor generalization on validation data.\n","*  Moderate MAPE suggests the predictions have some accuracy relative to target values but are still inadequate overall.\n","\n","\n","Testing Set\n","\n","\n","\n","*   Performance further deteriorates on the test set, with much higher MAE, MSE, and RMSE values.\n","*   Negative R² is extremely poor, showing that the model fails to generalize to the test set and predicts far worse than a simple baseline model.\n","\n","*   High MAPE confirms that the model's predictions are largely inaccurate, especially for certain ranges of the test data.\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"04eN_qsJnASm"}}],"metadata":{"colab":{"provenance":[{"file_id":"1CQdutdgyqbrTk1lZTfK9Vhf0m1anSoli","timestamp":1734111847141},{"file_id":"1NhOLn-oZnqGNDPvM_Gy3KWNMAh2DypGX","timestamp":1734019638652},{"file_id":"18Gu3lcn4Li66MaqYzsvOVlNEV8a_ArEE","timestamp":1733939530379}],"gpuType":"T4","collapsed_sections":["5ebGneEwoKEe","P9zGvbDMFoFA","fk2b_mq05OwC","ttCtLoLa5Jvb","7DDwcRmg6ij2","p2Hl_Qqk8lFG","EB432edpaTGc","79-DZCwjNMv_","Ti1QYI3uNmJs","6D2QO2aON20j","iElLx0jZPtOB","D_ADADVkSmP3","fQOitfg6Pn4d"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}