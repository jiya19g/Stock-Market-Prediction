{"cells":[{"cell_type":"markdown","source":["## Initial Code"],"metadata":{"id":"5ebGneEwoKEe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WY7I5C1zqFJt"},"outputs":[],"source":["# Importing necessary libraries for data analysis and manipulation\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# For handling warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21568,"status":"ok","timestamp":1734346138061,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"3RKq8vfwqVHB","outputId":"0e3b2254-e65b-4756-80ac-3690eef9f218"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4yeLMDyqd2o"},"outputs":[],"source":["df_aapl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/stocks/AAPL.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHvcgRGPruCy"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import boxcox\n","\n","df_aapl['Close_log'] = np.log(df_aapl['Close'] + 1)\n","df_aapl['Close_sqrt'] = np.sqrt(df_aapl['Close'])\n","df_aapl['Close_boxcox'], _ = boxcox(df_aapl['Close'] + 1)\n"]},{"cell_type":"markdown","metadata":{"id":"lLz5cmQlryah"},"source":["This code calculates the skewness of the 'Close' column in the `df_aapl` DataFrame before and after applying various transformations:\n","\n","1. **Original Skewness**: Calculates the skewness of the original 'Close' data.\n","2. **Log Transformation Skewness**: Calculates the skewness of the 'Close_log' column after applying the log transformation.\n","3. **Square Root Transformation Skewness**: Calculates the skewness of the 'Close_sqrt' column after applying the square root transformation.\n","4. **Box-Cox Transformation Skewness**: Calculates the skewness of the 'Close_boxcox' column after applying the Box-Cox transformation.\n","\n","The printed results help assess how each transformation affects the distribution's symmetry and the success of skewness correction.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1734346138578,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"DIPGiQydr2K0","outputId":"0e9fa519-ebbe-47ec-bb91-1201fa2cc3d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Skewness: 2.5045276102319933\n","Log Transformation Skewness: 0.8535555176510303\n","Square Root Transformation Skewness: 1.6211545809555206\n","Box-Cox Transformation Skewness: 0.43527466713563334\n"]}],"source":["\n","skew_original = df_aapl['Close'].skew()\n","skew_log = df_aapl['Close_log'].skew()\n","skew_sqrt = df_aapl['Close_sqrt'].skew()\n","skew_boxcox = pd.Series(df_aapl['Close_boxcox']).skew()\n","\n","print(f\"Original Skewness: {skew_original}\")\n","print(f\"Log Transformation Skewness: {skew_log}\")\n","print(f\"Square Root Transformation Skewness: {skew_sqrt}\")\n","print(f\"Box-Cox Transformation Skewness: {skew_boxcox}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"De4W27wEr9-p"},"outputs":[],"source":["\n","df_aapl['Open_log'] = np.log(df_aapl['Open'])\n","df_aapl['High_log'] = np.log(df_aapl['High'])\n","df_aapl['Low_log'] = np.log(df_aapl['Low'])\n","df_aapl['Adj Close_log'] = np.log(df_aapl['Adj Close'])\n","df_aapl['Volume_log'] = np.log(df_aapl['Volume'])\n","\n","\n","df_aapl['Open_sqrt'] = np.sqrt(df_aapl['Open'])\n","df_aapl['High_sqrt'] = np.sqrt(df_aapl['High'])\n","df_aapl['Low_sqrt'] = np.sqrt(df_aapl['Low'])\n","df_aapl['Adj Close_sqrt'] = np.sqrt(df_aapl['Adj Close'])\n","df_aapl['Volume_sqrt'] = np.sqrt(df_aapl['Volume'])\n","\n","from scipy.stats import boxcox\n","df_aapl['Open_boxcox'], _ = boxcox(df_aapl['Open'])\n","df_aapl['High_boxcox'], _ = boxcox(df_aapl['High'])\n","df_aapl['Low_boxcox'], _ = boxcox(df_aapl['Low'])\n","df_aapl['Adj Close_boxcox'], _ = boxcox(df_aapl['Adj Close'])"]},{"cell_type":"markdown","source":["This helps compare how the transformations reduce skewness in the data, aiming for a more normal distribution."],"metadata":{"id":"2XrZQHaDAigS"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1734346139055,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"of1KONYmsC8t","outputId":"dd23c32e-ec98-4e60-9d76-ad675b606288"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness Before Transformation:\n"," Open         2.504632\n","High         2.502208\n","Low          2.506714\n","Adj Close    2.550677\n","Volume       3.565699\n","dtype: float64\n","\n","Skewness After Transformation:\n"," Open_log            0.482872\n","High_log            0.481997\n","Low_log             0.484246\n","Adj Close_log       0.494009\n","Open_sqrt           1.620771\n","High_sqrt           1.621456\n","Low_sqrt            1.620661\n","Adj Close_sqrt      1.679402\n","Volume_sqrt         1.299776\n","Open_boxcox         0.181226\n","High_boxcox         0.179749\n","Low_boxcox          0.182882\n","Adj Close_boxcox    0.180085\n","dtype: float64\n"]}],"source":["\n","skewness_before = df_aapl[['Open', 'High', 'Low', 'Adj Close', 'Volume']].skew()\n","skewness_after = df_aapl[['Open_log', 'High_log', 'Low_log', 'Adj Close_log',\n","                          'Open_sqrt', 'High_sqrt', 'Low_sqrt', 'Adj Close_sqrt', 'Volume_sqrt',\n","                          'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox']].skew()\n","\n","print(\"Skewness Before Transformation:\\n\", skewness_before)\n","print(\"\\nSkewness After Transformation:\\n\", skewness_after)\n"]},{"cell_type":"markdown","source":["- Applied Box-Cox transformation to the 'Open', 'High', 'Low', 'Adj Close', and 'Close' columns.\n","- Recalculated skewness after the transformation to reduce skew and normalize the data for modeling."],"metadata":{"id":"zfEokf4iAmnv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1734346139055,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"s9oEP05csI66","outputId":"c8f52400-a5ea-4b29-bb55-fbc369abde5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skewness After Box-Cox Transformation:\n","Open_boxcox         0.435237\n","High_boxcox         0.433381\n","Low_boxcox          0.437331\n","Adj Close_boxcox    0.458762\n","Close_boxcox        0.435275\n","dtype: float64\n"]}],"source":["from scipy import stats\n","\n","df_aapl['Open_boxcox'], _ = stats.boxcox(df_aapl['Open'] + 1)\n","df_aapl['High_boxcox'], _ = stats.boxcox(df_aapl['High'] + 1)\n","df_aapl['Low_boxcox'], _ = stats.boxcox(df_aapl['Low'] + 1)\n","df_aapl['Adj Close_boxcox'], _ = stats.boxcox(df_aapl['Adj Close'] + 1)\n","df_aapl['Close_boxcox'], _ = stats.boxcox(df_aapl['Close'] + 1)\n","\n","skewness_after_boxcox = df_aapl[['Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox', 'Close_boxcox']].skew()\n","\n","print(\"Skewness After Box-Cox Transformation:\")\n","print(skewness_after_boxcox)\n"]},{"cell_type":"markdown","source":["Feature Selection"],"metadata":{"id":"uvZe7IzRAwHu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1734346139056,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"},"user_tz":-330},"id":"aczNHUI4rk8x","outputId":"c2d7706e-fd42-4498-aa33-d696d35c1077"},"outputs":[{"output_type":"stream","name":"stdout","text":["         Date      Open      High       Low  Adj Close     Close     Volume  \\\n","0  1980-12-12  0.128348  0.128906  0.128348   0.098943  0.128348  469033600   \n","1  1980-12-15  0.122210  0.122210  0.121652   0.093781  0.121652  175884800   \n","2  1980-12-16  0.113281  0.113281  0.112723   0.086898  0.112723  105728000   \n","3  1980-12-17  0.115513  0.116071  0.115513   0.089049  0.115513   86441600   \n","4  1980-12-18  0.118862  0.119420  0.118862   0.091630  0.118862   73449600   \n","\n","   Open_boxcox  High_boxcox  Low_boxcox  Adj Close_boxcox  Close_boxcox  \n","0     0.117689     0.118173    0.117674          0.092374      0.117689  \n","1     0.112503     0.112516    0.112016          0.087857      0.112030  \n","2     0.104886     0.104897    0.104395          0.081785      0.104407  \n","3     0.106798     0.107287    0.106786          0.083688      0.106798  \n","4     0.109657     0.110145    0.109644          0.085966      0.109657  \n"]}],"source":["\n","df_aapl_cleaned = df_aapl[['Date', 'Open', 'High', 'Low', 'Adj Close', 'Close', 'Volume',\n","                           'Open_boxcox', 'High_boxcox', 'Low_boxcox', 'Adj Close_boxcox',\n","                           'Close_boxcox']]\n","\n","print(df_aapl_cleaned.head())\n"]},{"cell_type":"markdown","source":["### Train Validation Test Split\n","\n","The code splits the data into training, validation, and test sets. The features `X` and target `Y` are split as follows:\n","\n","- 70% for training (`X_train`, `Y_train`)\n","- 15% for validation (`X_val`, `Y_val`)\n","- 15% for testing (`X_test`, `Y_test`)\n","\n","The split is done using a 30% test size, followed by splitting the remaining 70% into validation and test sets without shuffling (time series data)."],"metadata":{"id":"chw5ijVT_JRM"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df_aapl_cleaned[['Open_boxcox', 'High_boxcox', 'Low_boxcox']]\n","Y = df_aapl_cleaned['Close_boxcox']\n","\n","X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, shuffle=False)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, shuffle=False)\n","\n","print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSztwxnoy8-U","executionInfo":{"status":"ok","timestamp":1734346139056,"user_tz":-330,"elapsed":6,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"5077c1c8-d18c-4014-c949-f0af602f8f5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (7736, 3), Validation set: (1658, 3), Test set: (1658, 3)\n"]}]},{"cell_type":"code","source":["!pip install ConfigSpace\n","!pip install hpbandster"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zR-2_QoaXW7p","executionInfo":{"status":"ok","timestamp":1734346157053,"user_tz":-330,"elapsed":18002,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"74536bd9-1f7a-47a4-99e6-a78d924a70ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ConfigSpace\n","  Downloading configspace-1.2.1.tar.gz (130 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.26.4)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (3.2.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.13.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (10.5.0)\n","Building wheels for collected packages: ConfigSpace\n","  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ConfigSpace: filename=ConfigSpace-1.2.1-py3-none-any.whl size=115941 sha256=316d694f4652aec787008b9fa3746cb584f32a5e073ab260ca8d5a0c63795b30\n","  Stored in directory: /root/.cache/pip/wheels/75/e4/b7/23c23eb4a1c3b1adfeb8bd11366f48c805cbf3ba347237fea6\n","Successfully built ConfigSpace\n","Installing collected packages: ConfigSpace\n","Successfully installed ConfigSpace-1.2.1\n","Collecting hpbandster\n","  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Pyro4 (from hpbandster)\n","  Downloading Pyro4-4.82-py2.py3-none-any.whl.metadata (2.2 kB)\n","Collecting serpent (from hpbandster)\n","  Downloading serpent-1.41-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.26.4)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.13.1)\n","Collecting netifaces (from hpbandster)\n","  Downloading netifaces-0.11.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (3.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (10.5.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n","Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading serpent-1.41-py3-none-any.whl (9.6 kB)\n","Building wheels for collected packages: hpbandster, netifaces\n","  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=79986 sha256=8666def0f531fe235c0822ed0aee62544192757a545818b43939a7da38f0fa13\n","  Stored in directory: /root/.cache/pip/wheels/79/51/18/33d6ba8c55cc8401bffbccb1b87b21e0c68f40edc4ce3c1f99\n","  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for netifaces: filename=netifaces-0.11.0-cp310-cp310-linux_x86_64.whl size=35005 sha256=4c2693caa08acf3d4be2e875d4499deb7d44bc5850e34d60d8d3b4082cd5a16a\n","  Stored in directory: /root/.cache/pip/wheels/48/65/b3/4c4cc6038b81ff21cc9df69f2b6774f5f52e23d3c275ed15aa\n","Successfully built hpbandster netifaces\n","Installing collected packages: netifaces, serpent, Pyro4, hpbandster\n","Successfully installed Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n"]}]},{"cell_type":"markdown","source":["## Stacked Ensemble Learning"],"metadata":{"id":"2Cuy_rnVd0Cw"}},{"cell_type":"code","source":["!pip install hpbandster\n","!pip install ConfigSpace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXV4p2jHDIfR","executionInfo":{"status":"ok","timestamp":1734346174882,"user_tz":-330,"elapsed":14367,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"f94e5ab8-2b67-48b8-e2a0-3bdd4d702bd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: hpbandster in /usr/local/lib/python3.10/dist-packages (0.7.4)\n","Requirement already satisfied: Pyro4 in /usr/local/lib/python3.10/dist-packages (from hpbandster) (4.82)\n","Requirement already satisfied: serpent in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.41)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.26.4)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.14.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.13.1)\n","Requirement already satisfied: netifaces in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.11.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (3.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (10.5.0)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n","Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.10/dist-packages (1.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.26.4)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (3.2.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.13.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (4.12.2)\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (10.5.0)\n"]}]},{"cell_type":"markdown","source":["###**Initial**"],"metadata":{"id":"Qi0ZUWLfd4DN"}},{"cell_type":"code","source":["from sklearn.ensemble import StackingRegressor\n","from sklearn.linear_model import Ridge\n","from sklearn.svm import SVR\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","# Define base models and final estimator\n","base_learners = [\n","    ('ridge', Ridge(alpha=1.0)),\n","    ('svr', SVR(kernel='rbf', C=1.0, epsilon=0.1))\n","]\n","\n","# Define the final estimator (meta-model)\n","final_estimator = Ridge(alpha=1.0)\n","\n","# Create the Stacked Regressor\n","stacked_regressor = StackingRegressor(estimators=base_learners, final_estimator=final_estimator)\n","\n","# Train the model\n","stacked_regressor.fit(X_train, Y_train)\n","\n","# Predictions\n","train_pred = stacked_regressor.predict(X_train)\n","val_pred = stacked_regressor.predict(X_val)\n","test_pred = stacked_regressor.predict(X_test)\n","\n","# Metrics calculation function\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Train, validation, and test metrics\n","train_metrics = calculate_metrics(Y_train, train_pred)\n","val_metrics = calculate_metrics(Y_val, val_pred)\n","test_metrics = calculate_metrics(Y_test, test_pred)\n","\n","# Output results\n","print(\"Training Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*train_metrics))\n","print(\"Validation Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*val_metrics))\n","print(\"Test Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*test_metrics))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95y40d9UXkZm","executionInfo":{"status":"ok","timestamp":1734285441717,"user_tz":-330,"elapsed":969,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"dd0975b1-f4e9-4605-ec80-f41ae043e57c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Metrics: MAE: 0.0029, MSE: 0.0000, RMSE: 0.0043, R²: 0.9999, MAPE: 0.8806\n","Validation Metrics: MAE: 0.0029, MSE: 0.0000, RMSE: 0.0034, R²: 0.9980, MAPE: 0.1676\n","Test Metrics: MAE: 0.0031, MSE: 0.0000, RMSE: 0.0033, R²: 0.9982, MAPE: 0.1526\n"]}]},{"cell_type":"markdown","source":[" model is performing extremely well with very high accuracy on all sets. The R² values close to 1.0 across all splits indicate excellent fitting and generalization.\n","The MAE, RMSE, and MAPE values are very low, suggesting minimal prediction error.\n","The MSE being zero is likely due to the Box-Cox transformation and model’s performance in this specific range."],"metadata":{"id":"nmXm0YuxiarH"}},{"cell_type":"markdown","source":["###**Updated base model**"],"metadata":{"id":"9bDW-yl-jf6a"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.linear_model import Ridge\n","from sklearn.svm import SVR\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","# Define new base models\n","base_learners_new = [\n","    ('ridge', Ridge(alpha=1.0)),\n","    ('svr', SVR(kernel='rbf', C=1.0, epsilon=0.1)),\n","    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n","    ('gb', GradientBoostingRegressor(n_estimators=100, random_state=42))\n","]\n","\n","# Define the final estimator (meta-model)\n","final_estimator = Ridge(alpha=1.0)\n","\n","# Create the new Stacked Regressor with updated base models\n","stacked_regressor_new = StackingRegressor(estimators=base_learners_new, final_estimator=final_estimator)\n","\n","# Train the model\n","stacked_regressor_new.fit(X_train, Y_train)\n","\n","# Predictions\n","train_pred_new = stacked_regressor_new.predict(X_train)\n","val_pred_new = stacked_regressor_new.predict(X_val)\n","test_pred_new = stacked_regressor_new.predict(X_test)\n","\n","# Metrics calculation function\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    return mae, mse, rmse, r2, mape\n","\n","# Train, validation, and test metrics for the new model\n","train_metrics_new = calculate_metrics(Y_train, train_pred_new)\n","val_metrics_new = calculate_metrics(Y_val, val_pred_new)\n","test_metrics_new = calculate_metrics(Y_test, test_pred_new)\n","\n","# Output results for the new model\n","print(\"Updated Model Training Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*train_metrics_new))\n","print(\"Updated Model Validation Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*val_metrics_new))\n","print(\"Updated Model Test Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*test_metrics_new))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IZlMf1pd6-2","executionInfo":{"status":"ok","timestamp":1734286801266,"user_tz":-330,"elapsed":20447,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"e936c0a4-f77f-414e-8554-324e60a0280b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated Model Training Metrics: MAE: 0.0029, MSE: 0.0000, RMSE: 0.0043, R²: 0.9999, MAPE: 0.8957\n","Updated Model Validation Metrics: MAE: 0.0034, MSE: 0.0000, RMSE: 0.0039, R²: 0.9975, MAPE: 0.1944\n","Updated Model Test Metrics: MAE: 0.0063, MSE: 0.0000, RMSE: 0.0065, R²: 0.9929, MAPE: 0.3117\n"]}]},{"cell_type":"markdown","source":["###**RandomizedSearchCV**"],"metadata":{"id":"H1sZgifdMO8A"}},{"cell_type":"code","source":["from sklearn.ensemble import StackingRegressor\n","from sklearn.linear_model import Ridge\n","from sklearn.svm import SVR\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.model_selection import RandomizedSearchCV\n","import numpy as np\n","\n","# Define the base models\n","ridge = Ridge()\n","svr = SVR()\n","rf = RandomForestRegressor()\n","gb = GradientBoostingRegressor()\n","\n","# Define the stacking regressor with base models\n","stacked_regressor = StackingRegressor(\n","    estimators=[('ridge', ridge), ('svr', svr), ('rf', rf), ('gb', gb)],\n","    final_estimator=Ridge()\n",")\n","\n","# Define the parameter grid for each model (reduced for faster search)\n","param_dist = {\n","    'ridge__alpha': [0.1, 1.0],  # Ridge regularization\n","    'svr__C': [0.1, 1.0],  # SVR regularization\n","    'svr__epsilon': [0.01, 0.1],  # SVR epsilon\n","    'rf__n_estimators': [100],  # Number of trees for RandomForest\n","    'rf__max_depth': [10, 20],  # Max depth for RandomForest\n","    'gb__n_estimators': [100],  # Number of trees for GradientBoosting\n","    'gb__learning_rate': [0.1]  # Learning rate for GradientBoosting\n","}\n","\n","# RandomizedSearchCV with Stacked Regressor\n","randomized_search = RandomizedSearchCV(\n","    estimator=stacked_regressor,\n","    param_distributions=param_dist,\n","    n_iter=10,  # Number of random combinations to try\n","    cv=3,  # 3-fold cross-validation\n","    scoring='neg_mean_squared_error',  # Scoring metric\n","    n_jobs=-1,  # Use all CPU cores for parallel computation\n","    random_state=42\n",")\n","\n","# Fit the randomized search to the training data\n","randomized_search.fit(X_train, Y_train)\n","\n","# Best parameters from randomized search\n","print(f\"Best Parameters: {randomized_search.best_params_}\")\n","print(f\"Best CV Score (Negative MSE): {randomized_search.best_score_:.4f}\")\n","\n","# Retrain the stacked regressor with the best parameters\n","best_stacked_regressor = randomized_search.best_estimator_\n","\n","# Predictions with the optimized model\n","train_pred_optimized = best_stacked_regressor.predict(X_train)\n","val_pred_optimized = best_stacked_regressor.predict(X_val)\n","test_pred_optimized = best_stacked_regressor.predict(X_test)\n","\n","# Calculate metrics for the optimized model\n","train_metrics_optimized = calculate_metrics(Y_train, train_pred_optimized)\n","val_metrics_optimized = calculate_metrics(Y_val, val_pred_optimized)\n","test_metrics_optimized = calculate_metrics(Y_test, test_pred_optimized)\n","\n","# Output results for the optimized model\n","print(\"Optimized Model Training Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*train_metrics_optimized))\n","print(\"Optimized Model Validation Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*val_metrics_optimized))\n","print(\"Optimized Model Test Metrics: MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, R²: {:.4f}, MAPE: {:.4f}\".format(*test_metrics_optimized))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGYaVzFWjCbi","executionInfo":{"status":"ok","timestamp":1734294431294,"user_tz":-330,"elapsed":331779,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"dcd595e7-7c9c-49a6-a856-c9cea7c18129"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters: {'svr__epsilon': 0.01, 'svr__C': 1.0, 'ridge__alpha': 1.0, 'rf__n_estimators': 100, 'rf__max_depth': 20, 'gb__n_estimators': 100, 'gb__learning_rate': 0.1}\n","Best CV Score (Negative MSE): -0.0027\n","Optimized Model Training Metrics: MAE: 0.0029, MSE: 0.0000, RMSE: 0.0043, R²: 0.9999, MAPE: 0.8782\n","Optimized Model Validation Metrics: MAE: 0.0017, MSE: 0.0000, RMSE: 0.0023, R²: 0.9991, MAPE: 0.0987\n","Optimized Model Test Metrics: MAE: 0.0044, MSE: 0.0000, RMSE: 0.0049, R²: 0.9960, MAPE: 0.2145\n"]}]},{"cell_type":"markdown","source":["###**GridSearchCV using TimeSplit**"],"metadata":{"id":"SWjJr9kmMT4Z"}},{"cell_type":"code","source":["from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n","from sklearn.ensemble import StackingRegressor\n","from sklearn.linear_model import Ridge\n","from sklearn.svm import SVR\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import numpy as np\n","\n","# Base models\n","ridge_model = Ridge()\n","svr_model = SVR()\n","\n","# Final estimator\n","final_estimator = Ridge()\n","\n","# Stacking model\n","stacked_model = StackingRegressor(\n","    estimators=[('ridge', ridge_model), ('svr', svr_model)],\n","    final_estimator=final_estimator\n",")\n","\n","# Hyperparameter grid\n","# Updated to correctly reference the base estimators\n","param_grid = {\n","    'final_estimator__alpha': [0.1, 1, 10],\n","    'ridge__alpha': [0.1, 1, 10],  # Changed from 'estimators__ridge__alpha'\n","    'svr__C': [0.1, 1, 10],        # Changed from 'estimators__svr__C'\n","    'svr__epsilon': [0.01, 0.1, 0.5] # Changed from 'estimators__svr__epsilon'\n","}\n","\n","# TimeSeriesSplit for cross-validation\n","tscv = TimeSeriesSplit(n_splits=5)\n","\n","# GridSearchCV with TimeSeriesSplit\n","grid_search = GridSearchCV(estimator=stacked_model, param_grid=param_grid, cv=tscv, n_jobs=-1, scoring='neg_mean_squared_error')\n","\n","# Fit grid search\n","grid_search.fit(X_train, Y_train)\n","\n","# Best parameters found by grid search\n","print(\"Best parameters from GridSearchCV:\")\n","print(grid_search.best_params_)\n","\n","# Get best model from grid search\n","best_model = grid_search.best_estimator_\n","\n","# Evaluate on train, validation, and test sets\n","train_preds = best_model.predict(X_train)\n","val_preds = best_model.predict(X_val)\n","test_preds = best_model.predict(X_test)\n","\n","# Training metrics\n","train_mae = mean_absolute_error(Y_train, train_preds)\n","train_mse = mean_squared_error(Y_train, train_preds)\n","train_rmse = np.sqrt(train_mse)\n","train_r2 = r2_score(Y_train, train_preds)\n","train_mape = mean_absolute_percentage_error(Y_train, train_preds)\n","\n","# Validation metrics\n","val_mae = mean_absolute_error(Y_val, val_preds)\n","val_mse = mean_squared_error(Y_val, val_preds)\n","val_rmse = np.sqrt(val_mse)\n","val_r2 = r2_score(Y_val, val_preds)\n","val_mape = mean_absolute_percentage_error(Y_val, val_preds)\n","\n","# Test metrics\n","test_mae = mean_absolute_error(Y_test, test_preds)\n","test_mse = mean_squared_error(Y_test, test_preds)\n","test_rmse = np.sqrt(test_mse)\n","test_r2 = r2_score(Y_test, test_preds)\n","test_mape = mean_absolute_percentage_error(Y_test, test_preds)\n","\n","# Print all metrics\n","print(f\"\\nTraining Metrics: MAE: {train_mae}, MSE: {train_mse}, RMSE: {train_rmse}, R²: {train_r2}, MAPE: {train_mape}\")\n","print(f\"Validation Metrics: MAE: {val_mae}, MSE: {val_mse}, RMSE: {val_rmse}, R²: {val_r2}, MAPE: {val_mape}\")\n","print(f\"Test Metrics: MAE: {test_mae}, MSE: {test_mse}, RMSE: {test_rmse}, R²: {test_r2}, MAPE: {test_mape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qX_9g5VXjqCJ","executionInfo":{"status":"ok","timestamp":1734289040577,"user_tz":-330,"elapsed":72141,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"a605b217-4750-436c-9735-08d94fe9dfc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameters from GridSearchCV:\n","{'final_estimator__alpha': 0.1, 'ridge__alpha': 1, 'svr__C': 0.1, 'svr__epsilon': 0.5}\n","\n","Training Metrics: MAE: 0.0028836984361479035, MSE: 1.81900591871262e-05, RMSE: 0.004264980561166276, R²: 0.9998960692800729, MAPE: 0.008852864459272343\n","Validation Metrics: MAE: 0.0016145920479280437, MSE: 4.576904099131669e-06, RMSE: 0.002139370023892938, R²: 0.999221819213056, MAPE: 0.0009332366281996147\n","Test Metrics: MAE: 0.0017304033561164173, MSE: 4.298468978590048e-06, RMSE: 0.0020732749404239774, R²: 0.9992877516416375, MAPE: 0.0008580894078111664\n"]}]},{"cell_type":"markdown","source":["###**BOHB**"],"metadata":{"id":"9-1DrYE4MBzX"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.ensemble import StackingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import Ridge\n","from sklearn.svm import SVR\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","import ConfigSpace as CS\n","import ConfigSpace.hyperparameters as CSH\n","import hpbandster.core.nameserver as hpns\n","from hpbandster.optimizers import BOHB\n","from hpbandster.core.worker import Worker\n","\n","# Define configuration space for hyperparameter optimization\n","def get_config_space():\n","    cs = CS.ConfigurationSpace()\n","\n","    # Base learners (Random Forest and SVR)\n","    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter(\"rf_n_estimators\", 50, 200, default_value=100))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"rf_max_features\", 0.5, 1.0, default_value=0.8))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"svr_C\", 0.1, 10.0, default_value=1.0))\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"svr_epsilon\", 0.01, 1.0, default_value=0.1))\n","\n","    # Meta-learner (Ridge)\n","    cs.add_hyperparameter(CSH.UniformFloatHyperparameter(\"ridge_alpha\", 0.1, 10.0, default_value=1.0))\n","\n","    return cs\n","\n","# Define worker for BOHB\n","class StackingWorker(Worker):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","    def compute(self, config, budget, **kwargs):\n","        # Define base models\n","        rf = RandomForestRegressor(\n","            n_estimators=config[\"rf_n_estimators\"],\n","            max_features=config[\"rf_max_features\"],\n","            random_state=42\n","        )\n","        svr = SVR(\n","            C=config[\"svr_C\"],\n","            epsilon=config[\"svr_epsilon\"]\n","        )\n","\n","        # Define meta-learner\n","        ridge = Ridge(alpha=config[\"ridge_alpha\"])\n","\n","        # Define Stacking Regressor\n","        stack_model = StackingRegressor(\n","            estimators=[(\"rf\", rf), (\"svr\", svr)],\n","            final_estimator=ridge\n","        )\n","\n","        # Fit and evaluate on validation set\n","        stack_model.fit(X_train, Y_train)\n","        Y_val_pred = stack_model.predict(X_val)\n","        mae = mean_absolute_error(Y_val, Y_val_pred)\n","\n","        return {\"loss\": mae, \"info\": config}\n","\n","# Set up BOHB\n","NS = hpns.NameServer(run_id=\"stacking_bohb\", host=\"127.0.0.1\", port=None)\n","NS.start()\n","\n","worker = StackingWorker(nameserver=\"127.0.0.1\", run_id=\"stacking_bohb\")\n","worker.run(background=True)\n","\n","bohb = BOHB(\n","    configspace=get_config_space(),\n","    run_id=\"stacking_bohb\",\n","    nameserver=\"127.0.0.1\",\n","    min_budget=1,\n","    max_budget=3\n",")\n","\n","# Perform optimization\n","res = bohb.run(n_iterations=50)\n","\n","# Shutdown\n","bohb.shutdown()\n","NS.shutdown()\n","\n","# Retrieve the best configuration\n","best_config = res.get_incumbent_id()\n","best_params = res.get_id2config_mapping()[best_config][\"config\"]\n","\n","# Build the Stacked Ensemble model with the best hyperparameters\n","best_rf = RandomForestRegressor(\n","    n_estimators=best_params[\"rf_n_estimators\"],\n","    max_features=best_params[\"rf_max_features\"],\n","    random_state=42\n",")\n","best_svr = SVR(\n","    C=best_params[\"svr_C\"],\n","    epsilon=best_params[\"svr_epsilon\"]\n",")\n","best_ridge = Ridge(alpha=best_params[\"ridge_alpha\"])\n","\n","best_stack_model = StackingRegressor(\n","    estimators=[(\"rf\", best_rf), (\"svr\", best_svr)],\n","    final_estimator=best_ridge\n",")\n","\n","# Fit the model\n","best_stack_model.fit(X_train, Y_train)\n","\n","# Predict and evaluate\n","Y_train_pred = best_stack_model.predict(X_train)\n","Y_val_pred = best_stack_model.predict(X_val)\n","Y_test_pred = best_stack_model.predict(X_test)\n","\n","# Performance metrics calculation\n","def calculate_metrics(y_true, y_pred):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    return mae, mse, rmse, r2, mape\n","\n","train_metrics = calculate_metrics(Y_train, Y_train_pred)\n","val_metrics = calculate_metrics(Y_val, Y_val_pred)\n","test_metrics = calculate_metrics(Y_test, Y_test_pred)\n","\n","# Print the results\n","print(\"Best Parameters Found by BOHB:\")\n","print(best_params)\n","\n","print(\"\\nTraining set metrics:\")\n","print(f\"MAE: {train_metrics[0]}, MSE: {train_metrics[1]}, RMSE: {train_metrics[2]}, R²: {train_metrics[3]}, MAPE: {train_metrics[4]}\")\n","\n","print(\"\\nValidation set metrics:\")\n","print(f\"MAE: {val_metrics[0]}, MSE: {val_metrics[1]}, RMSE: {val_metrics[2]}, R²: {val_metrics[3]}, MAPE: {val_metrics[4]}\")\n","\n","print(\"\\nTest set metrics:\")\n","print(f\"MAE: {test_metrics[0]}, MSE: {test_metrics[1]}, RMSE: {test_metrics[2]}, R²: {test_metrics[3]}, MAPE: {test_metrics[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vn4N39tBDGHr","executionInfo":{"status":"ok","timestamp":1734347308041,"user_tz":-330,"elapsed":1130904,"user":{"displayName":"Jiya Gayawer","userId":"05781935709705850764"}},"outputId":"d5843873-b788-488a-ea93-41e63c351523"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters Found by BOHB:\n","{'rf_max_features': 0.8941791429983, 'rf_n_estimators': 97, 'ridge_alpha': 2.3283879384635, 'svr_C': 8.5972825698177, 'svr_epsilon': 0.1983669721719}\n","\n","Training set metrics:\n","MAE: 0.028137279044532115, MSE: 0.001654196054133705, RMSE: 0.04067180908361103, R²: 0.9905485856292088, MAPE: 0.07797523003696026\n","\n","Validation set metrics:\n","MAE: 0.013004904576298479, MSE: 0.00036750727613277327, RMSE: 0.019170479288029636, R²: 0.9375151641471147, MAPE: 0.007667490775155398\n","\n","Test set metrics:\n","MAE: 0.06814123889592388, MSE: 0.005179212819571468, RMSE: 0.07196674801303354, R²: 0.14181401640371816, MAPE: 0.033410367054186096\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1CQdutdgyqbrTk1lZTfK9Vhf0m1anSoli","timestamp":1734111847141},{"file_id":"1NhOLn-oZnqGNDPvM_Gy3KWNMAh2DypGX","timestamp":1734019638652},{"file_id":"18Gu3lcn4Li66MaqYzsvOVlNEV8a_ArEE","timestamp":1733939530379}],"gpuType":"T4","collapsed_sections":["5ebGneEwoKEe","Qi0ZUWLfd4DN","9bDW-yl-jf6a","H1sZgifdMO8A","SWjJr9kmMT4Z","9-1DrYE4MBzX"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}